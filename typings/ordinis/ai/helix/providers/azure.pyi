"""
This type stub file was generated by pyright.
"""

from collections.abc import AsyncIterator
from ordinis.ai.helix.models import ChatMessage, ChatResponse, EmbeddingResponse, ModelInfo, ProviderType
from ordinis.ai.helix.providers.base import BaseProvider

"""
Azure OpenAI provider implementation.

Integrates with Azure OpenAI Service for enterprise deployments.
"""
_logger = ...
class AzureOpenAIProvider(BaseProvider):
    """Azure OpenAI Service provider."""
    def __init__(self, api_key: str | None = ..., azure_endpoint: str | None = ..., api_version: str = ...) -> None:
        """
        Initialize Azure OpenAI provider.

        Args:
            api_key: Azure OpenAI API key. If None, uses AZURE_OPENAI_API_KEY env var.
            azure_endpoint: Azure endpoint URL. If None, uses AZURE_OPENAI_ENDPOINT env var.
            api_version: Azure OpenAI API version.
        """
        ...
    
    @property
    def provider_type(self) -> ProviderType:
        """Return provider type."""
        ...
    
    @property
    def is_available(self) -> bool:
        """Check if Azure OpenAI is available."""
        ...
    
    async def chat(self, messages: list[ChatMessage], model: ModelInfo, temperature: float | None = ..., max_tokens: int | None = ..., stop: list[str] | None = ..., **kwargs: object) -> ChatResponse:
        """Generate chat completion via Azure OpenAI."""
        ...
    
    async def chat_stream(self, messages: list[ChatMessage], model: ModelInfo, temperature: float | None = ..., max_tokens: int | None = ..., **kwargs: object) -> AsyncIterator[str]:
        """Generate streaming chat completion."""
        ...
    
    async def embed(self, texts: list[str], model: ModelInfo, **kwargs: object) -> EmbeddingResponse:
        """Generate embeddings via Azure OpenAI."""
        ...
    
    async def health_check(self) -> bool:
        """Verify Azure OpenAI connectivity."""
        ...
    


