"""
This type stub file was generated by pyright.
"""

from abc import ABC, abstractmethod
from collections.abc import AsyncIterator
from ordinis.ai.helix.models import ChatMessage, ChatResponse, EmbeddingResponse, ModelInfo, ProviderType

"""
Base provider interface.

Defines the contract that all LLM providers must implement.
"""
class BaseProvider(ABC):
    """Abstract base class for LLM providers."""
    @property
    @abstractmethod
    def provider_type(self) -> ProviderType:
        """Return the provider type identifier."""
        ...
    
    @property
    @abstractmethod
    def is_available(self) -> bool:
        """Check if provider is properly configured and available."""
        ...
    
    @abstractmethod
    async def chat(self, messages: list[ChatMessage], model: ModelInfo, temperature: float | None = ..., max_tokens: int | None = ..., stop: list[str] | None = ..., **kwargs: object) -> ChatResponse:
        """
        Generate chat completion.

        Args:
            messages: Conversation messages
            model: Model to use
            temperature: Sampling temperature (0.0-2.0)
            max_tokens: Maximum tokens to generate
            stop: Stop sequences
            **kwargs: Provider-specific options

        Returns:
            Chat completion response
        """
        ...
    
    @abstractmethod
    async def chat_stream(self, messages: list[ChatMessage], model: ModelInfo, temperature: float | None = ..., max_tokens: int | None = ..., **kwargs: object) -> AsyncIterator[str]:
        """
        Generate streaming chat completion.

        Args:
            messages: Conversation messages
            model: Model to use
            temperature: Sampling temperature
            max_tokens: Maximum tokens to generate
            **kwargs: Provider-specific options

        Yields:
            Content chunks as they're generated
        """
        ...
    
    @abstractmethod
    async def embed(self, texts: list[str], model: ModelInfo, **kwargs: object) -> EmbeddingResponse:
        """
        Generate embeddings for texts.

        Args:
            texts: Texts to embed
            model: Embedding model to use
            **kwargs: Provider-specific options

        Returns:
            Embedding vectors
        """
        ...
    
    async def health_check(self) -> bool:
        """
        Verify provider connectivity.

        Returns:
            True if provider is healthy
        """
        ...
    
    def supports_model(self, model: ModelInfo) -> bool:
        """
        Check if provider supports the given model.

        Args:
            model: Model to check

        Returns:
            True if model is supported
        """
        ...
    


