"""
This type stub file was generated by pyright.
"""

from dataclasses import dataclass
from ordinis.ai.helix.models import ModelInfo, ModelType
from ordinis.engines.base import BaseEngineConfig

"""
Helix configuration.

Defines configuration for LLM provider settings, model routing, and behavior.
"""
MISTRAL_MODELS: dict[str, ModelInfo] = ...
OPENAI_MODELS: dict[str, ModelInfo] = ...
AZURE_MODELS: dict[str, ModelInfo] = ...
NVIDIA_MODELS: dict[str, ModelInfo] = ...
@dataclass
class RetryConfig:
    """Retry behavior configuration."""
    max_retries: int = ...
    initial_delay_ms: int = ...
    max_delay_ms: int = ...
    exponential_base: float = ...
    jitter: bool = ...


@dataclass
class CacheConfig:
    """Response caching configuration."""
    enabled: bool = ...
    ttl_seconds: int = ...
    max_entries: int = ...
    cache_embeddings: bool = ...
    cache_chat: bool = ...


@dataclass
class RateLimitConfig:
    """Rate limiting configuration."""
    enabled: bool = ...
    requests_per_minute: int = ...
    tokens_per_minute: int = ...
    concurrent_requests: int = ...


@dataclass
class HelixConfig(BaseEngineConfig):
    """Main Helix configuration."""
    engine_id: str = ...
    engine_name: str = ...
    nvidia_api_key: str | None = ...
    mistral_api_key: str | None = ...
    openai_api_key: str | None = ...
    azure_openai_api_key: str | None = ...
    azure_openai_endpoint: str | None = ...
    default_chat_model: str = ...
    fallback_chat_model: str = ...
    default_code_model: str = ...
    fallback_code_model: str = ...
    default_embedding_model: str = ...
    fallback_embedding_model: str = ...
    models: dict[str, ModelInfo] = ...
    aliases: dict[str, str] = ...
    def __post_init__(self) -> None:
        """Initialize and load external config."""
        ...
    
    default_temperature: float = ...
    default_max_tokens: int = ...
    prefer_local: bool = ...
    allow_fallback: bool = ...
    retry: RetryConfig = ...
    cache: CacheConfig = ...
    rate_limit: RateLimitConfig = ...
    log_requests: bool = ...
    log_responses: bool = ...
    connect_timeout_ms: int = ...
    read_timeout_ms: int = ...
    def get_model(self, name: str) -> ModelInfo | None:
        """Get model info by name or ID."""
        ...
    
    def list_models(self, model_type: ModelType | None = ...) -> list[ModelInfo]:
        """List available models, optionally filtered by type."""
        ...
    
    def register_model(self, alias: str, model: ModelInfo) -> None:
        """Register a custom model."""
        ...
    
    def validate(self) -> list[str]:
        """Validate configuration, returning list of errors."""
        ...
    


