Current Development State (v0.2.0-dev)
Architecture & Infrastructure: The Ordinis platform is at version 0.2.0-dev, having completed a clean multi-engine architecture and core infrastructure setup[1]. The persistence layer (SQLite + Pydantic models), safety controls (kill-switch, circuit breaker), orchestration engine, and alerting system are implemented and considered production-ready[2][3]. Key trading engines (Signal, Risk, Execution, Portfolio, Analytics) are in place following a clean architecture design, with each engine exposing clear interfaces[4]. A comprehensive back-testing framework (“ProofBench”) and paper-trading simulator have been built and were recently integrated into the system[5][6]. Over 400 unit tests (≈67% coverage) are passing[7], enforcing code quality via CI, type checking, and linting.
Equities Functionality: The equities trading pipeline is largely operational. Five baseline equity strategies (Moving Average Crossover, RSI Mean Reversion, Momentum, Bollinger Bands, MACD) have been coded and run successfully in backtests[8][9]. The system can ingest historical market data (via CSV or API plugins like IEX/Polygon[10]), generate signals, apply risk filters, execute trades on a simulated broker, and record outcomes. For example, a recent full-system demo executed end-to-end with live data sources and produced realistic orders and P&L, indicating the equity trading loop is functional[11]. The paper-trading broker adapter is now complete – it simulates order fills with slippage/commission, tracks positions, manages cash, and runs in a loop with live price feeds[6][12]. This was a critical Phase 3 milestone: internal logs from a Dec 17, 2025 paper-trading session show multiple signals generated and orders executed with no critical errors (e.g. no “kill-switch” triggers or unhandled exceptions)[13][14]. In short, the platform’s core equity trading engines and safety features are in place and have been exercised in backtesting and paper trading.
Options Integration (Scaffolded): Support for options trading is present only in scaffold form. The codebase defines data models and strategy placeholders for options (e.g. an OptionsSignalModel for generating options signals[15] and example strategies like covered calls and married puts). The options signal generator can identify opportunities (covered calls, cash-secured puts, etc.) and calculate greeks and IV metrics on historical data[16][17]. However, full options trading support is not implemented – there is no live options market data feed or execution engine integration yet. The current options module serves as a framework: it demonstrates how options strategies would be modeled and evaluated, but actual trading (multi-leg order handling, margin calculations, broker API for options) remains unaddressed. In summary, the groundwork (data structures, signal logic) for options is in place, but the platform is equities-focused at present. Achieving v1.0 will require keeping the equities functionality robust and production-ready, while extending the architecture to accommodate options in the future (without committing to full options trading in v1.0).
Gaps to Address: As of now, a few components are still in development or need hardening before a 1.0 release. Real-time market data feeding for live trading is rudimentary – the system can poll data, but a high-frequency streaming feed (WebSocket) and synchronization with the trading loop are pending[18]. Live broker integration is partially done for Alpaca (paper and live) but not yet for others (Interactive Brokers, etc.)[19][20]. The RiskEngine (RiskGuard) is functional with standard rules (exposure limits, stop-loss, etc.), but some advanced risk features (dynamic position limits, portfolio VaR-based halts) and exhaustive testing are ongoing[21]. Monitoring and alerting need to be expanded beyond desktop notifications – e.g. adding email/SMS alerts and a real-time dashboard for P&L and risk metrics is on the roadmap[22][23]. Test coverage, while decent, should be increased (especially for integration tests and failure scenarios). In summary, the system’s “plumbing” and structure are solid, but final steps remain to polish features, ensure reliability at scale, and integrate all pieces for a production deployment.
Roadmap to v1.0.0 (Equities First, Options-Ready)
Goal: Achieve a production-ready v1.0.0 release focused on equities trading, while laying the groundwork for future options support. The roadmap is structured in phases, prioritizing core stability and risk management before extensions. High-level priorities include:
•    Finish Core Trading Loop & Live Capabilities: Complete all features needed for reliable live equities trading (real-time data feed, live broker connectivity, order management, etc.) – this is top priority to ensure the system can run end-to-end in production.
•    Harden Risk Management & Safety: Enforce rigorous risk controls (kill switches, limits) and governance checks for every trade. Any gaps in the RiskEngine or GovernanceEngine must be closed to protect against catastrophic losses or policy violations in production[24][25].
•    Monitoring, Alerting & Stability: Build comprehensive monitoring (performance metrics, health checks) and alerting (multi-channel notifications) to promptly detect issues in live trading[26][27]. Ensure the system can run continuously with high uptime and auto-recovery, as expected in production.
•    Scaffold Options Trading (without full rollout): Develop the necessary components to support options in the future – e.g. data ingestion for option chains, a basic OptionsEngine interface, and risk models for options – but defer full options execution support until post-1.0. In v1.0, options functionality will remain inactive or in beta (ensuring it doesn’t compromise equities performance).
•    Testing & Performance Tuning: Before release, conduct extensive testing (unit, integration, backtest simulations, paper trading) and optimize performance. The platform must hit key performance targets (latency, throughput, P&L consistency) under realistic loads to be considered production-ready[28].
Phase-Wise Roadmap:
•    Phase 4 – Risk Management & Safety Completion: Finalize the RiskGuard engine and governance policies. Implement any missing risk checks (e.g. sector exposure limits, advanced drawdown triggers) and ensure the kill-switch and circuit-breaker mechanisms are fully integrated into live trading[21]. This phase also includes exhaustive testing of risk scenarios (e.g. forced halts, extreme volatility) in simulation. Outcome: Every trade in simulation or live must pass through deterministic risk checks and satisfy pre-set limits[29] before execution, with automatic halts on rule breaches.
•    Phase 5 – Monitoring & System Integration: Develop a real-time monitoring dashboard (e.g. using Grafana/Prometheus) to visualize KPIs like equity curve, latency, Sharpe, drawdown, etc.[30][31]. Complete the alerting system: add email/SMS channels and ensure critical events (errors, risk breaches) trigger notifications with appropriate throttling[26][32]. Integrate log aggregation (centralize logs from all engines) for easier troubleshooting. This phase also involves “shadow mode” testing where the system runs live in parallel (paper trading) to validate stability over days of operation. Outcome: A fully instrumented system where operators have real-time visibility and alerts, and where all engines work seamlessly together over extended periods.
•    Phase 6 – Live Trading & Deployment Prep: Implement and verify live broker connectivity. The Alpaca Broker adapter (paper & live trading API) will be finalized and tested in a sandbox environment[19]. If needed, develop an additional broker adapter (e.g. Interactive Brokers FIX or API) to ensure broker redundancy for production[33]. Tighten deployment aspects: containerize the app or prepare cloud infrastructure, set up secure key management (API keys, secrets), and configure failover (e.g. automatic restart or secondary instance in case of crashes). Conduct a security audit focusing on data privacy (the governance module already strips PII and enforces compliance[34]) and on infrastructure (database backup integrity, access control). Finally, run a small-scale live trading pilot with limited capital to verify end-to-end performance in real market conditions. Outcome: The system is validated in a live environment with real broker execution, meeting all stability and performance criteria – ready for the v1.0.0 release.
•    Options Support (Parallel Scaffold): In parallel with the above, a small subset of development will prepare the options framework. This includes integrating an options data source (e.g. pulling option chain data and Greeks from an API), defining how option positions would be represented in the PortfolioEngine, and adding basic risk metrics for options (e.g. max loss calculations, margin requirements). Full trading of options is beyond v1.0, but by end of this phase the system should be “options-ready”: the SignalEngine can produce option trade signals and the rest of the system can theoretically accept them (even if they are just logged or paper-tested). For example, ensure that the OptionsSignalModel outputs can be stored and reviewed, and perhaps run a paper-trade simulation of an options strategy (without live execution) to validate the scaffold. Outcome: The architecture is extended to handle options data and signals gracefully, but options trades are disabled in production until thoroughly tested post-1.0. (This manages scope: equities remain the focus for 1.0, with minimal risk of an untested options feature causing issues.)
By following this phased roadmap, we first solidify the equities trading capabilities – hitting all reliability and performance targets – and simultaneously create an on-ramp for options trading in a later version. Equities get to production quality now, while options code is developed enough to not require an extensive redesign later (just activation and refinement). This staged approach ensures v1.0.0 is delivered with high confidence in its core functionality.
Tasks and Subtasks for Production Readiness
To execute the roadmap, below is a comprehensive task breakdown with subtasks:

1. Live Data Feed & Broker Integration
- Implement Real-Time Market Data Feed: Develop a robust live data ingestion loop. Subtasks: Use broker/API websocket streams (if available) or efficient polling to get tick or bar data for subscribed symbols[18]. Ensure the data feed is asynchronous and can keep up with target throughput (5,000 events/sec) without data loss[28]. Include reconnection logic for any dropped connections and sequence gap detection.
- Complete Broker Adapter for Live Trading: Finalize the Alpaca broker adapter for live orders (beyond paper trading)[19]. Subtasks: Add support for order status callbacks (fills, partial fills, cancellations), map internal Order/ExecutionReport to broker API responses, and handle errors (e.g. rejected orders, timeouts) gracefully. Implement retry logic via the CircuitBreaker for transient API issues[3][35]. If feasible, start developing a second adapter (Interactive Brokers) for future use, but Alpaca is priority for v1.0.
- Order Management & Reconciliation: Enhance the ExecutionEngine’s order tracking. Subtasks: Ensure every submitted order is recorded in the OrderRepository (with timestamp, status)[36]. Implement periodic position reconciliation between internal state and broker state[37] – e.g. compare the PortfolioEngine’s view vs. broker positions at start of day and correct discrepancies (via the PositionReconciliation component)[38]. This protects against drift between the system and broker, especially after outages.
- Graceful Shutdown & Restart: Improve orchestration for start/stop. Subtasks: On shutdown, make the Orchestrator inform all engines to finish their current cycle and persist state (open orders, last equity) in the SystemState repository. On restart, reload that state so the system can resume without losing context (important for long-running trades or multi-day sessions). Test by simulating an outage and ensuring the system continues trading correctly after reboot.
2. Risk Management & Governance Hardening
- Finalize Risk Rules Implementation: Audit the RiskGuardEngine to ensure all intended risk checks are implemented. Subtasks: Verify existing rules (max position size, max daily loss, per-trade stop-loss) and add any missing ones. For example, implement sector exposure limits if not yet done (ensuring total exposure to any sector ticker list ≤ X% of equity) and leverage limits (if margin trading is allowed)[39]. Include checks for illiquid securities (e.g. skip trades if volume < threshold to avoid slippage).
- Dynamic Risk Adjustments: Incorporate rules that adjust based on market volatility. Subtasks: Use volatility (ATR or VIX) to scale position sizes or tighten stops when volatility is high. Ensure the kill-switch triggers not just on absolute loss but on abnormal conditions (e.g. consecutive losing trades threshold) – these triggers are already designed in the KillSwitch component[40], but test them thoroughly in backtest by simulating rapid losses.
- GovernanceEngine Policies: Enforce pre-trade compliance checks. Subtasks: Update the GovernanceEngine.preflight to cover any new policies – e.g. a blacklist/whitelist of symbols (no trading banned stocks)[25]. Ensure the audit logging is immutable and comprehensive: every trade decision (allowed or blocked) should log a JSON line with timestamp, reasons, and hashes[41]. Test the system with some intentionally policy-violating trades (like a blacklisted stock) to confirm it blocks and logs them correctly.
- Integration of Risk with Execution: Tighten the coupling between RiskEngine and ExecutionEngine. Subtasks: Make sure the ExecutionEngine checks with RiskGuard right before sending any order (in case conditions changed in the milliseconds between signal generation and execution). If RiskGuard suggests adjustments (e.g. smaller size), ExecutionEngine should modify the order rather than just dropping it – implement this “risk-adjusted order” flow.
- Fail-safe Mechanisms: Implement a global kill-switch file/command that operators can use to halt trading immediately (the KillSwitch module supports a file trigger[40]). Test that flipping this switch stops new orders and closes positions as intended. Additionally, configure the CircuitBreaker around external API calls to open if too many errors occur, preventing runaway order submissions[3].
3. Performance Monitoring & Alerting
- KPIs Telemetry: Instrument the AnalyticsEngine or a new Telemetry module to compute and publish key performance indicators in real time. Subtasks: Track P&L and risk metrics per strategy (“pack”) and overall: e.g. running Sharpe ratio, win rate, max drawdown to date[42]. Compare against benchmarks (S&P 500) for alpha calculation[43]. Also track system metrics: event processing latency (time from market tick to order execution) and throughput (ticks per second)[28]. Emit these metrics to a time-series DB (Prometheus or InfluxDB).
- Real-Time Dashboard: Develop a dashboard (Grafana or custom web UI) to visualize the above metrics. Subtasks: Create charts for equity curve, drawdowns, rolling Sharpe, as well as system health (CPU, memory, latency distribution). Include risk alerts on the dashboard (e.g. red highlight if drawdown exceeds a threshold). Ensure the dashboard refreshes in near-real-time and can be accessed securely by the team.
- Alerting System Expansion: Extend the AlertManager to support multiple channels[26]. Subtasks: Configure email alerts using an SMTP or service API for critical incidents (e.g. trading halted, or daily loss > X%). Add SMS or chat notifications for high-priority alerts (perhaps via Twilio or Slack webhook). Implement alert deduplication and rate-limiting – e.g. do not spam alerts if the same error repeats rapidly[44]. Also, set up an alert escalation: e.g. INFO alerts (minor issues) only to log or email, but CRITICAL alerts (trade halts) via SMS immediately[26].
- Log Aggregation & Analysis: Deploy a centralized log solution (ELK stack or cloud logs). Subtasks: Modify logging to output structured logs (JSON) for easier parsing. Ship logs from all components (SignalEngine, RiskEngine, etc.) to a central location. Prepare query or analysis scripts (or use Kibana) to analyze trading days – e.g. the provided PowerShell script already parses daily logs for key events[45][14]. Integrate such analyses into the monitoring: for instance, end-of-day automatically compute “Signals generated vs. executed” or other stats and either display on dashboard or email a summary report.
4. Testing & Quality Assurance
- Expand Automated Test Coverage: Aim to raise test coverage to at least ~85%. Subtasks: Add unit tests for any newly added components (live feed handlers, broker adapters, etc.). Write integration tests that simulate a full trading day: feed in historical data bar by bar and assert that the system’s final P&L and metrics match expected values (regression test against known backtest results). Test edge cases: volatile market spikes, network timeouts on data fetch, database disconnects, etc., to ensure the system handles them gracefully (e.g. retries or fails safe). Leverage the backtest harness to run walk-forward tests for strategies – e.g. the ATR-Optimized RSI already underwent 10-day rolling validations[46], apply similar methodology to other top strategies to ensure robustness.
- Load & Stress Testing: Simulate high-throughput scenarios to test performance limits. Subtasks: Use the synthetic data generator to create a scenario of e.g. 10 symbols × 1-second bars and feed it in accelerated time to see if the system sustains 5k events/sec processing[28]. Measure end-to-end latency; ensure p95 latency stays under 200 ms as targeted[28]. Identify any bottlenecks (CPU hot spots or DB I/O) and optimize (e.g. tuning SQLite or allowing parallel signal processing across symbols). Also test memory usage over time to detect any leaks in long-running sessions.
- User Acceptance Testing (UAT): If applicable, have end-users (or the development team in a UAT role) run the system in a dry-run mode. Subtasks: Use the CLI and dashboard as an end-user would – execute the “demo_full_system” and some custom strategy backtests to ensure the documentation is accurate and the system behaves as documented. Test installation and deployment steps from scratch following the README to catch any gaps in instructions or environment configuration[47].
- Code Review & Static Analysis: Before release, perform a thorough code review focusing on security and reliability. Subtasks: Use static analysis (linters, MyPy) to catch any type errors or potential exceptions. Ensure secrets (API keys) are not logged or exposed. Verify that all threads/async tasks are properly awaited or closed on shutdown (to avoid orphan processes). Address any “FIXME/TODO” comments left in code for critical functionality. Consider an external review of critical algorithms (especially anything to do with money handling, e.g. position sizing calculations) to double-check correctness.
5. Security & Deployment
- Secure Credentials & Config: Implement a robust way to handle API keys and secrets needed for live trading. Subtasks: Use environment variables or an encrypted vault for API keys (Alpaca, IEX, etc.), rather than plain config files. Ensure .env files are not committed and instruct users on providing credentials securely[48]. Possibly integrate AWS/GCP secret management if deploying to cloud.
- Deployment Automation: Write deployment scripts or use Docker/CI pipelines to package the application. Subtasks: Containerize the Ordinis app with all dependencies pinned (ensuring reproducibility of the environment using the provided pyproject.toml). Set up GitHub Actions or similar CI to build/test on each commit (if not already in place), and perhaps to deploy to a staging server. Prepare a production runbook – documentation for how to start/stop the system, how to deploy updates, and rollback procedures.
- Failover and Redundancy: Plan for high availability. Subtasks: At minimum, ensure the system can recover from crashes: e.g. use a supervisor (systemd or Kubernetes pod) to automatically restart the process if it fails. Consider running a secondary hot-standby instance (paper trading mode) that can take over in case the primary fails – this is more of a stretch goal, but at least design the system to allow a quick restart without losing state (as covered in orchestration tasks). Test scenarios like network loss or DB locks – e.g. WAL mode in SQLite is enabled[49] for concurrency, but verify no data corruption if a crash occurs mid-write (perhaps simulate by killing the process).
- Final Documentation & Training: Update all documentation for v1.0. Subtasks: Revise the user guides (installation, quick start) to reflect the final state[47]. Emphasize the production run constraints (e.g. “connect your Alpaca keys and run live_trading.py for live deployment” as per ATR RSI guide[50]). Include documentation on new features like the monitoring dashboard and how to interpret alerts. If delivering to end-users or other teams, prepare a knowledge transfer or training session so that operating the system in production is well-understood.
  Each of the above tasks is directly tied to the current codebase status – for instance, we know alerting is partly implemented (desktop notifications) but email/SMS are marked “planned”[51], and our task list targets exactly those gaps. By executing these tasks, we address all known shortcomings and fortify the platform for a robust 1.0.0 release.
  Top Equity Strategies for Deployment
  The repository contains numerous strategies; based on internal test results and strategy performance data, the following 2–4 equity strategies emerge as highest-performing and are recommended for deployment priority in v1.0:
  •    ATR-Optimized RSI Mean Reversion: This enhanced RSI strategy has demonstrated exceptional out-of-sample performance after addressing the flaws of a basic RSI approach. It adapts stop-losses and take-profits to volatility (ATR) and uses regime filters. Test results show +60.1% total return in a multi-symbol portfolio test, with ~70–85% win rates across symbols[52]. Drawdowns were kept to ~26%, a huge improvement over the original RSI which was consistently losing money[53][54]. Although its raw Sharpe came out moderate (the strategy has some large swings), it achieved a high absolute return and a strong win rate. This strategy is considered production-ready (marked “✅ Production” in the strategy library)[55]. Its success across different stocks and in walk-forward tests suggests it can be a core mean-reversion strategy to deploy.
  •    Multi-Timeframe Momentum Strategy: A momentum breakout strategy that combines signals across multiple timeframes to confirm entries (e.g. using monthly momentum for direction and intraday stochastic for timing). This strategy is noted to have a high expected edge (rated 4/5) in the internal strategy index[56]. It seeks to capture sustained trends but avoids chasing false breakouts by requiring short-term confirmation. In backtesting, momentum strategies generally performed well in trending markets – for instance, in a synthetic +34% “uptrend” scenario, a pure momentum breakout was among the top performers with a high Sharpe ratio (outperforming simple mean reversion). The multi-timeframe version adds additional filtering, likely improving its risk-adjusted returns. Given its strong theoretical and tested performance, this is a top candidate for live deployment to profit from trending periods.
  •    Kalman Filter Hybrid (Trend + Mean Reversion): An advanced strategy that uses a Kalman filter to decompose price into a smooth trend and a residual; it then mean-reverts the residual only when it aligns with the broader trend[57][58]. This approach avoids the pitfall of counter-trend trades by always checking the trend direction. The strategy is marked complete with an expected edge of 4/5 in documentation[59]. Internal testing (simulated) suggests a win rate on the order of 55–65% and profit factor ~1.5–2.2, with best performance in trending markets that have short pullbacks[60]. The Kalman Hybrid’s strength is in risk management – it significantly reduces drawdowns by filtering out bad trades (those against the trend). Its sophisticated approach makes it slightly complex, but it’s implemented and ready. Deploying this strategy could provide a stable, lower-volatility return stream, complementing more aggressive strategies.
  •    MI-Weighted Ensemble of Signals: This strategy uses an ensemble of multiple indicators (RSI, momentum, volatility, etc.), weighting each by its mutual information (MI) with future returns[61]. The ensemble adaptively down-weights redundant or less predictive signals. It’s listed with a 4/5 expected edge and offers a balanced approach that can navigate different market conditions. While individual indicator strategies can have streaky performance, the MI-weighted ensemble aims for consistency, potentially yielding a higher Sharpe ratio by diversification of signals. In backtests, ensemble methods often improve risk-adjusted returns – this strategy is expected to deliver a smoother equity curve with an edge coming from information-theoretic weighting (the docs note it “captures non-linear dependencies” for an enhanced signal)[61]. Given it’s implemented and marked complete, it’s a prime candidate to include in production, likely as a “all-weather” strategy.
  These four strategies – two single-indicator strategies (one mean-reversion, one momentum) and two more sophisticated hybrids/ensembles – cover a diverse range of market regimes. They were chosen based on documented performance and internal tests:
  •    ATR-Optimized RSI had empirically the highest returns in testing[52] (turning around a previously failing strategy into a big winner). It’s valuable for range-bound or oscillating markets.
  •    Multi-timeframe Momentum is expected to excel in strong trends, which is crucial for not missing big rallies or breakdowns.
  •    Kalman Hybrid provides a controlled, low-drawdown approach, likely improving the portfolio’s Sharpe by avoiding bad trades.
  •    MI Ensemble offers robustness across conditions, as it’s not reliant on one signal – ideal for adapting to changing market dynamics.
  By deploying this set, the platform can allocate capital to a mix of uncorrelated strategies, increasing the chance that at least one strategy is performing well at any given time (and thereby improving overall portfolio stability). Each of these strategies should be vetted on the platform’s live data feed in paper mode (which is feasible given they are implemented) to double-check that their live signal generation matches backtest expectations. As the system moves to production, these strategies would be prioritized for live trading, while other lower-performing or unproven strategies are held back until further validation.
  (Note: Other strategies in the repository, such as OU Pairs Trading or HMM Regime Switching, also show promise (rated 4/5)[62]. They can be introduced later – for v1.0, we focus on the strategies above because they involve single-stock trades and have been more extensively tested. Pairs trading, for instance, requires shorting and two-asset coordination which adds complexity to initial deployment. The chosen set gives a high-performance baseline without over-complicating initial operations.)
  Performance KPIs and Current Benchmarks
  To declare v1.0.0 production-ready, the platform must meet specific Performance Key Performance Indicators (KPIs) on both trading outcomes and system operation. These KPIs are drawn from the project’s requirements and current implementation results:
  Trading Performance KPIs: Measures of strategy and portfolio outcomes – many of these have target thresholds defined in the repo’s documentation:
  •    Sharpe Ratio (Risk-Adjusted Return): A primary metric for strategy quality. Target: Sharpe ≥ 2.0 on backtested equity curve[31]. Current backtest results show some strategies (ATR-Optimized RSI, etc.) with Sharpe below this (e.g. ~0.17 in one aggressive test[54]), indicating room for improvement. As strategies are refined and combined, the aim is to push Sharpe above 1.5 in internal tests before live deployment[24], and ultimately reach ~2.0 in stable live operation. Strategies like the MI Ensemble are expected to help boost the overall Sharpe by smoothing returns.
  •    Max Drawdown: The largest peak-to-trough equity decline. Target: ≤ 15% drawdown for the live trading portfolio[31], with an absolute cap at 20% in any single strategy backtest[63]. Current status: ATR-Optimized RSI saw ~26% max DD in testing[54], which is slightly above target – risk controls (ATR-based stops, position sizing) are being adjusted to reduce this. Other strategies in simulation are closer to targets (the ensemble and Kalman strategies are designed to limit drawdowns). The system includes daily loss-limit kill switches (e.g. auto-halt if loss >2% equity in a day)[64] to enforce these limits in production.
  •    Win Rate and Profit Factor: Win rate is the percentage of trades that are profitable; profit factor is gross profit / gross loss. Targets: Win rate in the 55–60% range, Profit Factor ≥ ~2.0[65]. Current: The ATR-Optimized RSI achieved a 70–85% win rate in test (very high)[66], but that was in a strongly mean-reverting scenario. Other momentum strategies have win rates ~50–60% but make more on winners than losers (profit factor > 1.5). By deployment, each selected strategy should demonstrate Profit Factor ≥ 1.8 in backtest[63] (the pre-deployment acceptance criteria) – for example, in the multi-strategy backtest demo, the top strategies all exceeded 1.8 PF and some neared 2.0[67]. These metrics will continue to be tracked in forward testing; any strategy falling short (e.g. PF < 1.5 or persistent win rate < 50%) will likely be dropped or tweaked before live trading.
  •    Return vs. Benchmark (Alpha): The goal is to produce positive alpha over a benchmark like the S&P 500. Target: The portfolio’s excess return over S&P should be statistically significant and positive[68]. In the synthetic backtest demo, all strategies were compared to a buy-and-hold SPY return; the champion strategy outperformed SPY by a significant margin[43]. KPI tracking will include Information Ratio (excess return / tracking error, target ≥ 0.5) to quantify this[68]. Currently, since the system hasn’t been live against a benchmark, this is theoretical – but backtests on 2024 data will check that strategies combined would have beaten the market (for example, ATR-RSI and momentum both aim for absolute returns >20% annually, versus ~10% typical S&P).
  •    Other Trading KPIs: The system will also monitor Sortino Ratio (target ≥3.0)[31] for downside-risk-adjusted return, Calmar Ratio (CAGR/MaxDD, target ≥3)[31] as a measure of return vs risk, and metrics like average win vs average loss (target ≥1.5)[65]. These give a fuller picture of strategy performance. For instance, ATR-Optimized RSI’s average win was observed to be larger than its average loss due to the adaptive ATR take-profits, helping its profit factor[69]. All these will be logged by the AnalyticsEngine for live runs.
  System Performance KPIs: Metrics to ensure the trading engine operates within production-grade performance and reliability parameters:
  •    Latency (Tick-to-Trade): The time from receiving market data to executing an order. Target: p50 ≤100ms, p95 ≤200ms[28]. Current status: In single-thread backtest mode, latency is not an issue, but in live trading, the pipeline (data bus → signal → risk → broker API) needs to be optimized. Using async IO, caching of price data (the PaperBroker uses a 1s price cache to reduce API calls)[70], and fast in-memory computations should keep latency well below 200ms for modest loads. We will measure this in paper trading: e.g. with 1-min bars, our log analysis script can confirm orders are placed within a second of bar close. Early tests indicate the Python-based system can handle the required speed, but this will be continuously profiled.
  •    Throughput (Event Rate): Events (market ticks or bars) processed per second. Target: Sustain ≥5,000 events/sec at peak[28]. This implies the ability to handle fast market conditions or a moderate number of symbols. Current: the backtester can replay ~500 bars of data for multiple strategies fairly quickly, but we haven’t truly stress-tested thousands of ticks/sec yet. We plan to simulate bursts (as per task list) to ensure the event bus and engines don’t become a bottleneck. If needed, scaling measures (like parallel processing of independent signals, or moving to an even faster bus like Redis Streams) will be considered to hit this KPI.
  •    Uptime and Fault Tolerance: Target Uptime: ≥99.9% during market hours[71], meaning <1 minute of downtime per day. The infrastructure (with orchestrated startup/shutdown) and the presence of fail-safes (kill-switch, circuit-breaker) are aimed at high reliability. The system state persistence in SQLite and the restart procedures being implemented will help achieve near-continuous operation. We’ll also track Critical Error Rate (target ≤1 per 10k events)[71] – basically no critical crashes during normal operation. So far in testing, no crashes have been observed; any exceptions (like API auth issues) are handled and counted. The log analysis from Dec 17 shows, for example, some minor errors (e.g. a few “pending_new” order status quirks) but the system did not halt[45][72]. The goal is to eliminate or auto-handle such errors and reach near-zero unhandled exceptions in production.
  •    Data Quality and Freshness: Ensure market data is timely and correct. Target: Data timestamp lag ≤1s from source[71]. We will measure how fresh quotes are in the live feed and that all schema validations pass (100% schema-validation rate[71] – meaning no malformed data enters the bus). The system already includes data validators for OHLC sanity (no negative prices, etc.)[73][74]. In production, any data errors will trigger alerts and fallbacks (e.g. switch data source if one fails).
  •    Resource Utilization: The platform also leverages AI components (LLM reasoning via Cortex, etc.), though those are auxiliary. We set a target that GPU/CPU utilization for these stays ≤80% to leave headroom[29]. Also, the success rate of LLM calls should be ≥99% (no crashes in the AI subsystem)[29], though for v1.0 these AI features (Cortex, Synapse) are not critical path for trading and can be disabled if not stable. Essentially, they should not interfere with trading performance.
  •    Alert/Content Safety: As part of governance, an unusual KPI is Content-Safety Incidents: 0 – i.e., no inappropriate content from AI outputs[75]. This is relevant if we use AI for trade rationale or report generation. It’s largely ensured by using whitelisted models and filters (Helix service)[76]. We include it for completeness, though it’s peripheral to trading performance.
  Going into production, we will continuously measure these KPIs. The pre-deployment acceptance criteria mandate that all critical thresholds are met before live trading is enabled[24]. For example, if during final paper trading a strategy’s Sharpe is only 1.0 or max drawdown hits 25%, we will tune or drop that strategy before going live. Similarly, if latency p95 is above 200ms, we’ll profile and optimize until it’s under the threshold. Only when all KPIs are green (or within acceptable tolerance) will we tag the release as v1.0.0 and proceed to full live deployment[24].
  Inference from Logs: The internal logs and test outputs used in development give us confidence in some KPIs: For instance, the log snippet on equity progression[14] shows the system tracking Starting vs. Ending Equity each day, which directly yields daily P&L% (in one recent session, a modest positive gain was observed – exact % redacted, but it demonstrates profitability). Logs also count errors like “insufficient buying power” occurrences[77] – in recent runs these were zero or very low, indicating the sizing logic is working. Signals Generated vs. Approved are tracked (the RiskEngine may reject some) – on Dec 17, all signals that passed risk checks were executed, implying the RiskGuard wasn’t frequently blocking trades in normal conditions (a good sign that strategies are well within risk limits). These informal metrics from logs will be formalized into the KPI dashboard going forward.
  In summary, the platform will be judged by both trading success (returns with controlled risk) and technical performance (speed, stability). The targets above align with industry-standard expectations for a professional trading system and have been derived from the repository’s documented goals. By rigorously testing against these KPIs in the final development phase, we ensure the v1.0.0 system not only performs well historically but is statistically likely to continue doing so in live operation, all while running reliably and safely.
  Timeline to Release v1.0.0
  Given the current progress and tasks remaining, a realistic timeline to reach a production-ready v1.0.0 is on the order of 2–3 months from now (current date: Dec 20, 2025). Below is a proposed timeline with key milestones, assuming the team works in focused sprints on the outlined tasks:
  •    Late December 2025: Complete outstanding core features for live trading (Phase 4 tasks).
  •    Milestone: Risk & Broker Completion – Paper broker fully validated, Alpaca live trading tested in a sandbox. All RiskGuard rules implemented and passing simulated tests. Basic real-time data feed running (perhaps in polling mode) for a few symbols.
  •    By Dec 31: Have a stable paper-trading session running end-to-end for an entire trading day with no rule breaches or crashes (a “all green” test day).
  •    January 2026: Focus on Phase 5 – Monitoring, optimization, and extensive testing.
  •    First two weeks of Jan: Monitoring Dashboard & Alerting live. Grafana (or similar) set up displaying live paper trading metrics. Email/SMS alerts configured and tested by generating sample alerts (e.g. simulate an error to see an email fire). Begin daily paper-trading runs at market open to collect performance data. Also, start load-testing with synthetic data in off hours.
  •    Mid January: Integration Testing Sprint. Fix any issues discovered in continuous paper trading (e.g. if a certain error repeats in logs, address it). By mid-month, aim to meet all pre-deployment KPI thresholds in paper testing – e.g. if Sharpe is lagging, adjust strategy weights; if latency is too high, optimize code. This sprint also improves test coverage (writing tests for any bugs found).
  •    Late January: Beta Release (v0.3.0) – At this point, the system should be nearly ready. We can tag a beta and possibly do a limited live test: trade with minimal capital on a live Alpaca account for a few days as a dry run. Closely monitor performance and any deviations between paper and live (e.g. slippage differences, any API surprises). Freeze any new feature development; focus on stability and documentation updates.
  •    February 2026: Final hardening and security (Phase 6 and release prep).
  •    Early February: Security Audit & Failover Tests. Conduct the code audit and perhaps invite an external reviewer to pen-test the system or review critical code paths (especially if using cloud services). Practice failure recovery: intentionally kill the process during a paper trade day and see if the restart resumes correctly. Ensure backups of the SQLite DB are happening (WAL mode is on, but also take daily backup dumps) and test restoring from backup.
  •    Mid February: Final Performance Tuning. By now, we likely have a week or two of live (or realistic paper) trading metrics. Analyze these to ensure KPIs are hit. For example, if the win rate of a strategy live is much lower than expected, investigate why (market regime shift or an implementation issue?). Fine-tune strategy parameters one last time if needed. Verify that all alerts that should fire do fire (perhaps no real incidents have occurred – consider using a fire-drill approach to test alerts).
  •    Late February: Release Candidate & Documentation Complete. Prepare the v1.0.0 release candidate. Freeze code changes except critical fixes. Update all READMEs, architecture docs (mark options as partial support, etc.), and ensure the knowledge base is consistent with the released state. Also, finalize the deployment scripts so that installing and running v1.0 is plug-and-play for the operations team.
  •    Early March 2026: Launch v1.0.0 Production. Assuming the late Feb release candidate had no show-stoppers, officially roll out v1.0.0 to production at the start of March. This timing intentionally avoids major market events (if any known in late Q1) – but generally early March is fine. On launch day, have team members monitor the system closely via the new dashboard and alerts. Given all the prior dry runs, we expect a smooth start. Any minor issues that arise can be patched in a quick 1.0.1 update if needed. But the expectation is that by this point, the system will have been running in a stable configuration for several weeks in paper mode, so going live is a non-event.
  •    Post-Launch (March–April 2026): Collect live trading data and compare with expectations. Begin working on enabling options trading using the scaffolding (for a v1.1 or v2.0 release later in 2026). Also, gather feedback from the live performance – perhaps some strategies need recalibration or maybe the system can handle more symbols than initially used, etc. Use this period to validate that all KPIs continue to hold in real conditions and make any minor adjustments.
  This timeline is aggressive but achievable. It leverages the fact that most heavy development (architecture, core engines) is already done – the remaining work is about polishing, testing, and integration which can be done in a matter of weeks with focused effort. The plan slates roughly one month for internal integration and another for final polish. If any unexpected blockers arise (for example, a critical bug in the broker API), there is buffer to delay into March – but as of now, a Q1 2026 release of v1.0.0 is realistic.
  Each milestone above will only be deemed complete when quantifiable criteria are met (e.g. “X days of error-free paper trading” or “all KPIs green for 2 weeks”). By following this schedule, we ensure that when we hit the v1.0.0 tag, the Ordinis platform truly deserves the designation “production-ready” – with fully operational equities trading and a solid foundation for options to be integrated in the near future.
  Sources:
  •    Project README (v0.2.0-dev status, architecture, KPIs)[1][24][78]
  •    Ordinis “Ready to Run” and planning docs (current features vs. TODO, test stats)[79][80]
  •    Changelog and design docs (Phase 1–3 completion, PaperBroker implementation)[6][21]
  •    Strategy performance documents (ATR-Optimized RSI results, strategy suite ratings)[52][56]
  •    Logging scripts and outputs (daily log analysis, equity progression)[13][14]
  •    Architecture references (risk management, alerting, data pipeline)[3][26]

________________________________________

[1] [4] [8] [11] [24] [25] [27] [28] [29] [30] [31] [34] [39] [41] [42] [47] [63] [65] [68] [71] [75] [76] [78] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/README.md
[2] [3] [26] [32] [35] [36] [37] [38] [40] [44] [49] [51] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/CHANGELOG.md
[5] [7] [48] [79] [80] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/archive/planning/ready-to-run-20251201.md
[6] [12] [21] [22] [23] [33] [70] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/archive/planning/paper-broker-plan-20251201.md
[9] [43] [67] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/scripts/backtesting/run_backtest_demo.py
[10] [18] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/archive/planning/first-build-plan-20251201.md
[13] [14] [45] [72] [77] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/scripts/trading/analyze_trading_logs.ps1
[15] [16] [17] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/src/ordinis/engines/signalcore/models/options_signal.py
[19] [20] [46] [50] [52] [53] [54] [64] [66] [69] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/guides/atr_optimized_rsi_implementation.md
[55] [56] [59] [61] [62] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/knowledge-base/cards/STRATEGY_SUITE.md
[57] [58] [60] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/knowledge-base/cards/KALMAN_HYBRID.md
[73] [74] GitHub
https://github.com/keith-mvs/ordinis/blob/f37276fa76a1f49bc7a89747652c41c7445b34d2/docs/archive/current-status-next-steps.md
