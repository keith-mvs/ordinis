Software Requirements Specification – Ordinis Trading & AI Platform (DB1)

1. Introduction
   1.1 Purpose
   This Software Requirements Specification (SRS) describes Development Build 1 (DB1) of the Ordinis trading and AI platform. It defines the system’s architecture, components, and requirements using the IEEE 830 format. The purpose of this document is to capture all functional and non-functional requirements for the event-driven, modular trading engine and its integrated AI services in the MVP phase (DB1), while also outlining how these components will evolve through enhanced and full-feature builds. This SRS will serve as a reference for developers, architects, and stakeholders to ensure the system is implemented in compliance with the design goals of reliability, extensibility, and compliance.
   1.2 Scope
   The Ordinis platform is a modular, AI-driven algorithmic trading system built to execute trading strategies with robust risk management and integrated AI support. The scope of DB1 (Phase 1 MVP) covers the core trading loop and essential safety features, including signal generation, risk checks, order execution via a broker API, portfolio tracking, and basic analytics[1]. Additionally, it includes initial integration of AI helper engines (Cortex, Synapse, Helix, CodeGenService) in an advisory capacity to assist in development and strategy analysis[2]. This SRS details all engines and services across all development phases (MVP, enhanced, full feature set), meaning that some requirements describe components that, while designed in DB1, will be fully realized in later phases (Phase 2+). The document focuses on functional requirements for each engine/service and system-wide non-functional requirements (performance, security, etc.), ensuring the MVP build is aligned with the long-term architectural vision. Features or components outside the current roadmap (e.g. multi-tenant support, ultra-HFT capabilities) are out of scope.
   1.3 Definitions, Acronyms, Abbreviations
   •    Ordinis – Name of the trading platform under development.
   •    MVP – Minimum Viable Product, referring to Phase 1 (DB1) focusing on core functionality.
   •    Engine – A module or service responsible for a specific domain in the trading system (e.g., SignalEngine, RiskEngine).
   •    StreamingBus – The event bus that transports messages (events) between engines in a decoupled manner[3].
   •    LLM – Large Language Model (e.g., GPT-like models).
   •    RAG – Retrieval-Augmented Generation (using a knowledge base to ground LLM responses).
   •    Cortex – Internal codename for the LLM reasoning engine (e.g., used for explanations, code analysis).
   •    Synapse – Internal codename for the retrieval engine providing relevant context snippets (knowledge base).
   •    Helix – Internal codename for the LLM provider service (dispatches calls to actual models).
   •    Nemotron-49B/8B – Codenames for the primary large (49 billion parameter) and fallback small (8 billion parameter) LLMs used by Helix[4].
   •    DB1 – Development Build 1, corresponding to Phase 1 (MVP) implementation.
   •    Kafka, NATS, Redis – Message broker technologies that can back the StreamingBus event system[5].
   •    cuOpt – NVIDIA’s CUDA-based optimization library used for portfolio optimization[6].
   •    Kill Switch – A safety mechanism to halt all trading under certain conditions (manual or automatic triggers)[7].
   •    Circuit Breaker – A mechanism to stop or pause interactions with an external service if it’s failing (e.g., stop calling a broker API after repeated failures)[8].
   •    P&L – Profit and Loss.
   •    MTM – Mark-to-Market (valuing positions at current market prices).
   •    API – Application Programming Interface (e.g., broker API, data API).
   (For a full glossary of terms, see Appendix A in project documentation.)
   1.4 References
   •    Ordinis Architecture Specification (v1.1, 2025-12-14)[9]
   •    Ordinis Phase 1 Production Architecture Document (2025-12-12)[10]
   •    NVIDIA AI Blueprint Integration Plan (2025-12-08)[11]
   •    Ordinis Development Roadmap Phases 2–4[12][13]
   •    Ordinis Phase 1 API Reference (2025-12-12)[14]
   (All requirements in this SRS are derived from the above architectural documents and design discussions.)
   1.5 Overview
   This SRS is organized as follows: Section 2 provides an overall description of the system, including its architectural context, major components (engines), user characteristics, and assumptions. Section 3 details specific requirements: first the external interface requirements (data providers, broker APIs, etc.), then functional requirements for each engine/service (with interfaces and behaviors), followed by system-wide non-functional requirements (performance targets, security, etc.). Each requirement is labeled for traceability. Section 4 provides a requirements traceability matrix mapping each requirement to its source architecture component or design benchmark for verification purposes. This structured approach ensures that the DB1 implementation meets its immediate goals and lays the groundwork for phases to come, using AI engines from the start as foundational accelerators in development and strategy research[12].
2. Overall Description
   2.1 Product Perspective
   Ordinis is conceived as an event-driven, modular trading platform where independent components (engines) cooperate via a central event bus. The system operates as a pipeline that ingests market data and produces trading actions, with AI-driven analysis augmenting but not replacing deterministic logic[3]. Figure 1 (architecture diagram) illustrates how each engine fits into the overall context:
   •    All engines communicate through a unified StreamingBus (message bus). Components publish events and subscribe to relevant events, achieving loose coupling[3].
   •    An OrchestrationEngine acts as the central coordinator, triggering the sequence of operations for each trading cycle (e.g., on each new market tick or on schedule)[3]. It ensures each engine is invoked in order and with the proper context.
   •    The core trading loop consists of: SignalEngine (generating trade signals from data), RiskEngine (vetting signals against risk constraints), ExecutionEngine (placing orders for approved signals), PortfolioEngine (updating positions and balances), and AnalyticsEngine (calculating performance metrics and possibly generating reports)[15][16]. Each of these engines performs a specialized function in the pipeline.
   •    Surrounding the core loop are specialized engines: PortfolioOptEngine for advanced portfolio optimization tasks, GovernanceEngine for global policy enforcement and audit logging, LearningEngine for continuous learning (e.g., model retraining from outcomes), and an integrated AI stack (Cortex, Synapse, Helix, CodeGenService) that provides reasoning, knowledge retrieval, and development assistance[17].
   •    External interfaces include market data providers (feeding data into the system via the StreamingBus), execution venues or broker APIs (receiving orders from ExecutionEngine), and knowledge/document sources (ingested by Synapse). The system’s design treats these external entities as pluggable adapters, keeping core logic insulated from vendor-specific details.
   Overall, Ordinis is designed as a layered architecture with clear separation of concerns[18]. For example, persistence of data is handled in a repository layer (e.g., using SQLite in Phase 1 for orders, positions, etc.), safety controls like kill-switch and circuit-breaker form a safety layer, and the engines above operate in an orchestrated fashion[18][19]. This modular approach not only aids maintainability and scaling (engines can be distributed or replaced independently, as long as interfaces are respected[20]), but also aligns with compliance needs by introducing central oversight (GovernanceEngine).
   Architectural Goals: The key goals driving this architecture are reliability, extensibility, and traceability[9]. Reliability is achieved through risk checks, fail-safe mechanisms (kill-switch, circuit breakers), and persistent state to recover from failures[21]. Extensibility comes from modular engines and standardized event schemas that allow new engines or models to be added with minimal changes to existing components[22]. Traceability is supported via the GovernanceEngine logging every critical action and the use of correlation IDs to trace events end-to-end[23]. All components are versioned and auditable under governance policies[9] to facilitate compliance audits and troubleshooting.
   2.2 Product Functions
   At a high level, the Ordinis platform provides the following major functions (system features), each encapsulated by an “engine” or service:
   •    Data Ingestion and Bus Management: Ingest real-time Market Data (and alternative data) and distribute it via the StreamingBus to all interested engines[24]. This includes validating event schemas and managing subscriptions to different event types/topics.
   •    Trading Signal Generation (SignalEngine): Process incoming market data to generate trading signals (buy/sell recommendations) based on strategy models and indicators[25]. Optionally incorporate external context via AI (retrieval of relevant info through Synapse) to enrich decision-making (though final signals remain rule-based).
   •    Risk Evaluation (RiskEngine): Enforce risk management by evaluating each candidate trade signal against risk limits and policies[25]. Decide whether to allow the trade, modify it (e.g., reduce size), or reject it outright, providing justifications for audit[25].
   •    Trade Execution (ExecutionEngine): Convert approved signals into executable orders and route them to a trading venue or broker interface[26]. Simulate fills in backtesting mode or track real fills in live mode, and publish execution results (fills or order status) as events[26].
   •    Portfolio Management (PortfolioEngine): Maintain the state of the portfolio (positions, cash, margin) and ensure consistency after each trade[27]. Enforce portfolio-level constraints and perform rebalancing or allocation adjustments as needed[27].
   •    Analytics & Reporting (AnalyticsEngine): Calculate performance metrics and risk metrics over time (e.g., returns, drawdowns, Sharpe ratio)[28]. Generate reports or dashboards summarizing strategy performance. Optionally, use the Cortex LLM to produce natural-language summaries or explanations of performance[28].
   •    Optimization (PortfolioOptEngine): Provide advanced portfolio optimization capabilities, such as computing the optimal asset allocation for given objectives and constraints (using GPU acceleration for speed)[6]. This engine supports quantitative research (e.g., finding the efficient frontier or CVaR optimal portfolio).
   •    Governance & Compliance (GovernanceEngine): Act as a global policy enforcement layer that monitors and intercepts actions for compliance checks[17]. It logs an immutable audit trail for every critical action (orders placed, risk overrides, model changes)[29] and can veto or adjust actions that violate policies (e.g., prevent trades outside trading hours or unapproved model usage).
   •    Learning & Adaptation (LearningEngine): Continuously learn from new data and outcomes. It captures events from the whole system (signals, trades, P&L) and triggers retraining of models or re-indexing of knowledge bases to improve performance over time[17]. This provides a feedback loop to evolve trading strategies and AI behavior in a controlled manner.
   •    AI Reasoning Assistant (Cortex): Provide reasoning, explanation, and coding assistance through a Large Language Model interface[30]. Cortex can analyze code (e.g., strategy scripts) for issues, answer questions about strategy behavior, or produce research summaries with citations. Note: Cortex operates offline from live trading – it does not autonomously initiate trades; it’s an advisory tool[31].
   •    Retrieval Knowledge Base (Synapse): Index and retrieve relevant information to support the AI assistants[32]. Synapse ingests documentation, runbooks, past trade logs, etc., and on query returns relevant snippets. This ensures that LLM responses (from Cortex or CodeGen) can be grounded in factual context (Retrieval-Augmented Generation)[32].
   •    LLM Provider Service (Helix): Abstract the complexity of working with large language models by providing a unified generate API that selects the appropriate model (e.g., the large Nemotron-49B vs. the smaller Nemotron-8B) and handles auth, scaling, and failover[33]. Helix ensures that all AI requests use the correct models, respect rate limits, and apply content filters.
   •    AI Code Generation (CodeGenService): Assist developers by generating code diffs or prototypes for requested changes[34]. Given a prompt (feature description or bug fix) and context code, it proposes changes. All suggestions pass through governance checks (to avoid introducing insecure or non-compliant code)[34].
   These functions together form an integrated platform for data-driven trading with AI augmentation, where AI is used to enhance understanding and productivity but not to take ungoverned trading actions[12]. In Phase 1 (DB1), the primary user of the system is the quant developer/strategist who configures strategies and monitors trades. The platform in MVP is single-user, single-strategy oriented (one portfolio being managed), running on a single node (workstation or server). Future phases will expand capabilities (e.g., multiple strategies, distributed deployment, etc.) but the fundamental architecture remains as described.
   2.3 User Characteristics
   The end “user” of the core trading system is not a layperson but rather an operator or developer (quant trader, quantitative developer) who develops strategies and oversees the system. Key user characteristics and roles include:
   •    Quantitative Developer/Strategist: Develops trading models (e.g., code for SignalEngine), tunes risk parameters, and uses AI tools like Cortex and CodeGenService to assist in writing and analyzing code. This user interacts with the system through configuration files, scripts, or potentially a Jupyter notebook/REPL interface (as provided in development tools)[35]. They require understandable analytics (via AnalyticsEngine reports) and audit logs (from GovernanceEngine) to validate that the system behaves as expected and to debug issues.
   •    System Operator/DevOps: Oversees deployment and running of the system in a live or paper trading environment. This user cares about system reliability, will use the monitoring metrics (latencies, P&L, health checks) and possibly receives alerts (e.g., kill-switch triggered or connectivity issues). They may use command-line tools to start/stop components (e.g., using the Orchestrator’s controls or kill-switch triggers) and will respond to critical alerts.
   •    Compliance Officer/Auditor (future role): In later phases, a compliance or risk officer might review the audit trails produced by the GovernanceEngine to ensure the system’s trading complies with regulations. They would be interested in the traceability matrix of decisions (which is facilitated by the system’s logging of every decision with reason codes) and might use specialized queries or tools to read the immutable logs.
   •    AI Developer (internal role): Maintains the AI engines (Cortex, Helix, etc.). They would care about model updates (e.g., upgrading Nemotron models), managing secrets for AI services, and ensuring the AI components remain in an advisory role. This overlaps with the Quant Developer role but with focus on the AI side.
   It is assumed that end investors or customers are not directly using this system’s interface; rather they are indirect beneficiaries of its performance. There is currently no GUI for external users – interactions are through config files, CLI, or possibly simple dashboard views of analytics for the development team. Thus, usability concerns focus on clarity of logs, configuration simplicity, and the modularity for the dev team rather than a polished end-user UI.
   2.4 Operating Environment and Constraints
   Deployment Environment: In DB1, the system runs on a single machine (development workstation or single server) using in-process components. Production deployment (Phase 1) also runs on a single server but with more robust settings. The system is built in Python, with dependencies such as asyncio for concurrency, libraries for ML (e.g., PyTorch for LLM inference), and database (SQLite). As we progress, containerization (Docker/Kubernetes) will be used for multi-service deployment, enabling cloud or on-premise cluster setups[36]. The operating environment must support GPU acceleration if the AI/optimization features are used – e.g., an NVIDIA CUDA-compatible GPU for running the Nemotron models and cuOpt solver[11].
   Hardware Constraints: To utilize the primary AI models (49B parameters) and GPU optimizations, a high-end GPU with sufficient memory (>= 40 GB VRAM, such as NVIDIA A100 or H100) is needed[37]. In the absence of such hardware, the system will automatically switch to smaller models or CPU-based methods (with performance trade-offs). The software should detect hardware availability and configure engines (Helix, PortfolioOptEngine) accordingly (see constraints in Section 3.4 and 3.5). Disk space is needed for storing historical data (the retention policy might archive older data to manage this). Network connectivity is required for accessing external APIs (market data, broker, possibly AI model APIs if used). If used in a cloud VM, appropriate security groups and VPC setup for low-latency access to broker endpoints would be required.
   Regulatory and Compliance Constraints: The system operates in a regulated domain (financial trading). Therefore, certain constraints are imposed by compliance considerations: - All order and trade data should be retained and immutable for regulatory audit (e.g., SEC requires order records retention)[38]. - A kill-switch must be present (and is, by design) to immediately stop trading algorithms, as required by regulations (e.g., EU MiFID II mandates kill-switch capability)[38]. - Strategies and model changes should be documented and auditable; hence the system logs model version changes and rationale (facilitated by GovernanceEngine and LearningEngine logging). - Data privacy: although the system mainly deals with market data (no personal data of individuals), any API keys or account information is sensitive and must be stored securely (encrypted at rest, not exposed in logs)[39].
   Technology Constraints: The MVP uses SQLite as the database for simplicity and file-based persistence[40]. This implies single-writer concurrency limits and that for Phase 1 we accept those limits. Future phases might move to PostgreSQL for multi-threading and better HA. The event bus in Phase 1 is a placeholder (in-memory Python pub/sub)[40] due to the single-process deployment. In Phase 2, introduction of Kafka or Redis Streams is planned for a true distributed event bus[41]. The design must account for eventual consistency and at-least-once delivery semantics when that change happens. The codebase is primarily Python; heavy compute tasks (GPU ops, vector search) rely on optimized libraries (cuOpt, Faiss, PyTorch) – integrating those is subject to their version compatibility and constraints (CUDA version, etc.).
   Modularity and Interfaces: Each engine has a well-defined interface (documented in Section 3.2). Engines interact only through the event bus or via calls orchestrated by OrchestrationEngine, which imposes a constraint that all data exchanged must be serializable events or defined in shared memory structures. Circular direct dependencies between engines are disallowed by design (for instance, RiskEngine and ExecutionEngine do not call each other directly; they communicate via orchestrator or bus), in line with clean architecture principles[42]. This avoids deadlocks and makes testing engines in isolation easier.
   2.5 Assumptions and Dependencies
   Assumptions:
- Single Strategy Context: It is assumed that DB1 will run one trading strategy/portfolio at a time (one instance of the pipeline). Multi-portfolio support (parallel strategies) may be introduced later by running multiple pipelines or extending the bus topics (this is not in scope for MVP). - Data Availability: The proper functioning of the system assumes continuous availability of market data through the configured provider (e.g., Alpaca’s API for US stock market data) and connectivity to the broker (for order execution). If data is delayed or missing, the system will only trade on what it last knew. (We assume the providers meet their SLA; the system’s fault tolerance will handle short outages via circuit breakers). - Model Availability: It is assumed the required AI models (Nemotron-49B and 8B) are available either locally or via network and that the hardware is capable of running at least the smaller model. If not, AI features will degrade (the system can still trade using traditional logic without AI assistance). - Phase-wise Feature Completeness: Some components are stubbed or simplified in Phase 1. We assume that the enumerated requirements for all engines are understood as the target functionality, even if some are partially implemented in DB1. For example, the StreamingBus in DB1 may not yet use Kafka but we assume the architecture will migrate to Kafka/Redis Streams in Phase 2 and design accordingly[41]. Similarly, Cortex/Synapse/Helix exist in design and code but are not on the critical path of trading in Phase 1 (they run in a sandbox)[2] – we assume they will be integrated fully by Phase 2, but we include their requirements now. - Time Synchronization: The system clock on the host machine is assumed accurate (NTP synced) because timing is important for ordering events, timestamps in logs, etc. - Single-User Operation: We assume only trusted internal users (developers/operators) have access to the system in Phase 1, so elaborate user authentication isn’t implemented yet. However, this assumption will change if the system becomes multi-user or externally accessible; hence basic authN/Z is planned (see Security requirements).
  Dependencies:
- External Market Data API: e.g., Alpaca Markets API, Polygon.io, Alpha Vantage. These provide price feeds and historical data. The system depends on their API availability and the validity of API keys. (Alpaca is used as the primary data & execution source in Phase 1/2)[39]. - Broker API: e.g., Alpaca trading API or a paper trading simulator. The ExecutionEngine uses a BrokerAdapter interface that is implemented for a specific broker (Alpaca in Phase 1). If that broker changes (say Interactive Brokers in future), a new adapter must be supplied. The system design isolates these differences behind the adapter/protocol[14]. - Database: SQLite for Phase 1 (with Write-Ahead Logging mode). The application depends on the sqlite3 library and file system persistence. In future, migrating to PostgreSQL will add a dependency on a running Postgres service and its connection parameters. - Message Broker: None external in Phase 1 (in-memory). Phase 2 will introduce dependency on Kafka (requiring a Kafka cluster or service) or Redis (a Redis server). Design already accounts for that by abstracting the bus. - Libraries/SDKs: Various: e.g., NVIDIA CUDA toolkit and cuOpt library for optimization, PyTorch/NVIDIA NeMo for LLM hosting, FAISS or ElasticSearch for Synapse’s vector store, and possibly OpenAI API or NVIDIA API if external LLM calls are used as fallback[43]. These must be installed and configured properly. The integration plan addresses compatibility (e.g., using a slightly smaller model locally and calling an API for larger tasks to work within a single GPU limit)[44][45]. - Operating System: Linux x86_64 is assumed for deployment (due to better support for GPUs and high-performance libs). Windows is used for some development, but all production use is on Linux (this influences how certain libraries like fork or file paths are handled). - Time & Schedule: If the strategy uses scheduled actions (e.g., daily portfolio rebalance at close), it relies on the system’s scheduler or orchestrator timers. This dependency is internal but important (the OrchestrationEngine might be triggered by either data events or timed triggers). - Knowledge Documents: The Synapse engine depends on having access to documentation and code to index. We assume a knowledge base directory or repository is provided (e.g., docs/ folder, codebase access, possibly a research papers folder). Keeping this updated is a process dependency (developers must feed new docs into it).
  Any changes in these assumptions or dependencies might require revisiting the requirements and design. For example, if we were to support multiple simultaneous strategies, we would need to introduce user separation, which would heavily impact the bus schema (adding portfolio identifiers to events, etc.). Such changes are beyond DB1’s scope but the architecture is intended to be flexible to accommodate them in the future[46].
3. Specific Requirements
   This section enumerates the specific requirements for the Ordinis platform. Requirements are organized by category: External Interface Requirements (3.1) describe interactions with external systems and data sources. Functional Requirements (3.2) detail the behavior and interfaces of each engine and service in the system. Non-Functional Requirements (3.3) cover performance, security, reliability, and other quality attributes. System Constraints (3.4) summarize design constraints such as model versions, retention policies, and fallback mechanisms. Each requirement is labeled (e.g., FR- for functional requirements, NFR- for non-functional, with abbreviations of components) for traceability.
   3.1 External Interface Requirements
   This section describes the interfaces to external systems that Ordinis must support or adhere to. These are not user interfaces but software interfaces with outside data providers, broker services, external libraries, and infrastructure components.
   3.1.1 Market Data Provider Interfaces
- EX-DATA-1: The system shall connect to external market data APIs to retrieve real-time and historical pricing data. For Phase 1/DB1, the primary data source is the Alpaca Markets API (which provides both live price streams and historical bars)[47]. The interface to Alpaca is an HTTPS REST and/or WebSocket API requiring an API key. The system must provide configuration for the API endpoint and credentials, and handle request signing or headers as per provider spec.
- EX-DATA-2: The system should be flexible to support other data providers such as Polygon.io or Alpha Vantage. For instance, Alpha Vantage may be used for supplemental daily historical data, and Polygon for tick-level data[48]. The design will abstract data ingestion so that switching or adding providers (via implementing a new adapter class) does not require changes in core engines. The interface contracts include rate limit handling (e.g., the data ingestion process should throttle calls to not exceed provider limits)[39] and error handling (if the provider returns an error or times out, the system should log it and possibly use fallback data if available).
- EX-DATA-3: Data Format & Schema: The data coming from providers (e.g., JSON for REST APIs or message frames from WebSockets) shall be converted into the system’s internal schema (e.g., a MarketDataEvent with fields like symbol, timestamp, price, volume) before publication on the StreamingBus. This conversion layer ensures external data conforms to the internal schema validation on the bus[49]. Any mapping (e.g., different field names or units from the provider) must be handled here. The system should log or flag if a data message cannot be parsed or violates schema (without crashing the system).
- EX-DATA-4: Alternative Data Sources: If alternative data (news sentiment, social media, etc.) are used, those likely have their own APIs. The system should handle them similarly: an ingestion adapter fetches or receives data and publishes events. Adapters might run as separate threads or async tasks that poll APIs or subscribe to external streams. These external interfaces often require API keys as well, which should be managed via the configuration/secrets mechanism (see Security requirements for secret management).
  3.1.2 Execution Venue / Broker Interfaces
- EX-EXEC-1: The system shall interface with broker or exchange APIs to execute trades. In Phase 1, this is a paper trading API (Alpaca’s paper broker) which uses REST calls for order submission and websockets/REST for order status updates. The ExecutionEngine’s BrokerAdapter will implement methods like submit_order(order) and get_positions() against Alpaca’s API endpoints[50][51]. This interface requires the broker’s API key and secret, which are configured securely and not hard-coded.
- EX-EXEC-2: The design must support plugging in real brokers (e.g., Interactive Brokers via their TWS API, or a FIX protocol connection). To this end, the ExecutionEngine uses an abstract BrokerAdapter protocol[14]. Each concrete adapter handles specifics of that broker: e.g., AlpacaAdapter calls Alpaca REST, an IBAdapter would use IB’s Python API, a FIXAdapter might connect to a FIX gateway. The requirement is that the ExecutionEngine can call broker_adapter.submit_order() and broker_adapter.get_account()/get_positions() in a uniform way without knowing the underlying broker details.
- EX-EXEC-3: Order Formats: The orders must be translated to the broker’s format. For example, an internal Order object with fields (symbol, qty, type, etc.) might need to be serialized to JSON as per Alpaca’s API spec (including specific field names like “qty” vs “quantity”, etc.). The adapter is responsible for this mapping. The ExecutionEngine will provide sufficient info (including perhaps an order type that might be broker-specific) to the adapter. The system should enforce that only supported order types (market, limit, maybe stop) are used or else the adapter returns a clear error.
- EX-EXEC-4: Response Handling: The broker interface will return execution results – e.g., an immediate response with an order ID, and later a fill event or status update. The adapter or ExecutionEngine must handle asynchronous updates. In Phase 1, using Alpaca, after submitting an order, the system can poll or subscribe to order status. The ExecutionEngine shall incorporate those into its ExecutionReport events. If the broker provides a client order ID echo, the system should use a unique ID (like a UUID) and match it on responses.
- EX-EXEC-5: Error and Rate Limit Management: If the broker rejects an order or the API call fails (network error, etc.), the adapter should catch this and raise an exception or return an error code. The ExecutionEngine must then handle it: log the failure, mark the order as rejected, possibly activate the circuit breaker if repeated failures occur[52]. Additionally, if the broker API enforces rate limits (e.g., max orders per minute), the system should incorporate a back-off or queuing mechanism (this could be considered in Phase 3 when more aggressive trading might hit such limits).
- EX-EXEC-6: Broker State Sync: The interface to the broker also provides account data (cash, buying power, positions). On startup, the system uses get_positions() and get_account() to synchronize internal state[53][54]. This is an important interface interaction: if any discrepancy is found (the broker shows a position not in our DB, etc.), the system’s reconciliation logic (which might be in PortfolioEngine or ExecutionEngine) will take action (log discrepancy, possibly adjust internal state, or trigger a kill-switch if serious)[55]. Thus, the quality of this interface data (freshness, completeness) is critical. The system assumes the broker data is the source of truth for actual holdings in live trading, and internal state is secondary.
  3.1.3 Event Bus and Messaging Interfaces
- EX-BUS-1: The system will use Kafka or Redis Streams/NATS as the backbone of the StreamingBus in future phases[5]. Although Phase 1 uses an in-memory bus (no external service), the design is such that switching to a Kafka cluster is configuration-driven. The external interface here is the Kafka protocol (likely via a Python Kafka client library). The system shall define a set of Kafka topics (e.g., market_data, signals, orders, executions, etc.) if Kafka is used. Each event type will map to a topic, and the message schema will be serialized in JSON or another format (Avro or protobuf could be used if schema registry is desired in future). The bus interface module must handle connecting to the Kafka broker (using addresses, security if needed), creating topics (or expecting them pre-created with proper retention settings), and publishing/subscribing to them.
- EX-BUS-2: If Redis Streams or NATS is configured instead, the interface is different (e.g., Redis requires pushing to a stream and reading with consumer groups). The StreamingBus abstraction will hide these details. The requirement is that the bus supports durability and replay when using these external systems. For example, Kafka will inherently support log retention (the system should configure retention period and topic compaction if needed for idempotency)[56]. The interface to Kafka should also allow reading past events for backtesting or recovery (the system might use Kafka’s offsets to replay events to the engines if needed).
- EX-BUS-3: The bus interface must also manage back-pressure and throughput. For instance, if using Kafka, the consumer (each engine’s subscriber) should commit offsets when done processing. If an engine falls behind, Kafka will store the backlog (bounded by retention) – the system should monitor this lag. With Redis Streams, the bus uses a similar concept with pending entries. The requirement is that the bus adapter ensures no data is lost: e.g., if using Redis, the StreamingBus in system would write to Redis (as in code which sets up _redis_adapter to write events)[57][58]. If Redis write fails, the system logs and drops event (as code shows), but in a robust deployment, that should be an exceptional case.
- EX-BUS-4: Schema Registry/Validation: If using an external bus, there may be a schema registry (for Avro or similar). As of now, the system likely uses JSON schema and validates in application code[49]. For future, if Avro+Kafka Schema Registry is used, the bus interface needs to integrate with that (ensuring producers attach schema ID and consumers retrieve schema to decode). This is a potential extension, not in MVP, but design should not preclude it.
- EX-BUS-5: Security for Bus: If Kafka is deployed in a cloud environment, the interface may require SASL/SSL authentication. The system config must allow specifying Kafka user credentials or certificates. The bus adapter should use them to establish secure connection. This ensures event data in transit is encrypted, meeting security requirements (especially if trading in cloud, we do not want plain-text trade data on a network).
  3.1.4 Knowledge Base and Document Interfaces
- EX-KB-1: The Synapse engine needs access to various documents and data sources for building its knowledge index. These sources might include: Markdown/HTML documents (system docs, runbooks) in a documentation repository, code repositories (source code files), and possibly external research papers (PDFs). For internal documents and code, the interface is typically file-based (Synapse will scan files from specified directories). The system shall allow configuration of paths or repositories that Synapse will index (e.g., a docs folder path, or a git repo URL). In Phase 1, it is assumed this is a local path since all components run locally.
- EX-KB-2: If external sources are needed (for example, pulling the latest documentation from an internal Confluence or an external knowledge base), the Synapse engine (or a separate ingestion pipeline) may need to call those systems’ APIs. A requirement is that the system can ingest from a variety of sources, potentially via plugins. For MVP, simply pointing it to local files is sufficient. The file interface should handle common formats (text, Markdown; PDFs might need an OCR or text extraction step which would be an external dependency on a PDF parsing library).
- EX-KB-3: Vector Store Service: Synapse uses a vector database to store embeddings. The initial implementation might use an in-process FAISS index (no external interface, just a library call). However, if ElasticSearch is used for persistent storage of vectors, then Synapse will interface with ElasticSearch’s REST API (for indexing vectors and searching by vector similarity)[32]. The system should support both modes via configuration. For ElasticSearch: need to configure index names, and ensure the ES cluster is running. If running in cloud (Phase 3+), using a managed ElasticSearch or a cloud vector DB (like Pinecone or Chroma service) could be considered, which would similarly require API keys and endpoints configured.
- EX-KB-4: Content Update: Over time, documents will be updated or new ones added. The interface for updating the knowledge index might be manual (a re-index command run by a user) or automated (a file watcher or a CI hook). The requirement is that Synapse provides a function or script to (re)index content periodically. If integrated with version control, a trigger could be a dependency (e.g., a Git post-commit hook to call Synapse update). For now, assume manual re-indexing as needed (developer runs a command to refresh index when they add significant docs).
  3.1.5 AI Model Services Interface
- EX-AI-1: The Helix service abstracts the LLM model calls. If Helix is configured to use local models, it will interface with the local machine’s GPU via libraries (PyTorch, NeMo). That is not an external network interface, but a dependency on the model files (which must be downloaded and loaded) and GPU drivers. If Helix is configured to use an external API (for example, OpenAI’s API or a cloud-hosted model), then it will make HTTPS calls to that API. In the NVIDIA blueprint, a hybrid approach is described where certain tasks use a cloud API fallback[44][45]. The requirement is that Helix can handle both: e.g., if an API key for an external LLM service is present, it can route requests there (for tasks that are too heavy for local). Helix should parse the response and pass it back in a uniform way.
- EX-AI-2: Nemotron Model Integration: The specific models (Nemotron-49B and Nemotron-8B) might be available through NVIDIA’s NGC (NVIDIA GPU Cloud) or as local checkpoints. If using NGC, Helix might call a REST or gRPC endpoint of a deployed model (this is hypothetical – possibly using NVIDIA’s NeMo Inference Server or a microservice that wraps the model). Alternatively, Helix may load the model using a NeMo or HuggingFace API locally. In any case, Helix must supply the model ID and get back text. If running locally, ensure that model loading times are managed (likely loaded at startup and kept in memory).
- EX-AI-3: Safety and Usage Reporting: If using an external API, Helix should interpret any rate-limit or error messages from that API and act accordingly (retry with backoff, or switch to a smaller model if the large one fails). It should also extract usage data (token counts, cost if provided) and possibly log it or expose it for monitoring. This isn’t a direct external interface requirement but an aspect of dealing with external AI providers. For example, OpenAI returns a usage field – Helix could use that.
- EX-AI-4: AI Model Updates: When models update (a new version of Nemotron arrives), Helix should allow specifying the model identifier (so the interface to model providers must allow choosing version or specifying a path). The system is constrained to specific models for consistency[4], so random model switching is not expected; any upgrade would be deliberate and require config change or code update.
  3.1.6 Infrastructure and Environment Interfaces
- EX-INF-1: Database: As mentioned, in Phase 1 the database is SQLite (embedded). If/when switching to Postgres, the system will interface with Postgres via a library (e.g., asyncpg). The schema (tables for orders, fills, etc.) would be deployed externally on the Postgres instance. The requirement is that migration from SQLite to Postgres is smooth: likely accomplished by a repository pattern that can target either database. If using Postgres, credentials and connection string must be provided. The system should support basic DB auth and optionally TLS for connection if required by policy. In MVP, SQLite is file-based so backup is simply copying the file; in a multi-host scenario, a proper external DB service is assumed.
- EX-INF-2: Logging/Monitoring: By Phase 3, the system will integrate with monitoring tools (Prometheus, Grafana, ELK stack)[23]. The interface here means: the application will expose metrics (e.g., via an HTTP endpoint for Prometheus to scrape, or by pushing to a time-series DB) and send logs to a central location (e.g., by logging in JSON and letting fluentd or Logstash collect them). For DB1, logs are just console/file, but the design is mindful of using structured logs so that integration is easier later. The requirement is that metrics like latency, P&L, event throughput be captured and made accessible. This might mean providing an HTTP endpoint (like /metrics) if we include a Prometheus client library. While not strictly needed in MVP, we consider it part of readiness for production. If in a container environment, also integrate with any orchestration health check (like Kubernetes liveness probes – e.g., Orchestrator could expose a heartbeat or the application’s main process could have a health check). - EX-INF-3: Secrets Management: The system will interface with environment variables or a secret store for sensitive data (API keys, etc.). In simple deployments, environment variables (ORDINIS_API_KEY, etc.) are used[59][60]. In enterprise deployment, these might come from a Vault or cloud secrets manager. The requirement is that no secrets are stored in code or in source control – the interface for secrets is via config at runtime. If needed, the system’s config loader could be extended to fetch from a secrets API or decrypt values (but Phase 1 uses plain env or a local .env file). - EX-INF-4: Scheduler/Clock: If the system needs to schedule tasks (like a daily report or periodic optimization), it might rely on the system clock or an external scheduler. In MVP, OrchestrationEngine likely uses Python’s asyncio sleep or schedule calls. In more complex deployments, we might integrate with a scheduling service or Cron for certain tasks. This is noted but not an immediate external interface.
  3.1.7 Development and CI/CD Interfaces (Minor, but for completeness):
- EX-DEV-1: The platform will have a set of scripts or CLI entry points for development usage (as in the dev guide). For instance, a REPL interface to interact with a running system (provided by scripts/repl_dev.py)[61] and a backtesting harness CLI (proofbench.run)[62]. While not external “services,” these constitute an interface for the developer to engage with the system. Requirements are that these tools remain updated to reflect changes in internal APIs and that they provide a safe sandbox (e.g., the REPL shouldn’t accidentally connect to a live broker if we’re in dev mode). They should use the dev configuration which points to mock data, in-memory bus, and small models[63]. - EX-DEV-2: The system will likely integrate with a CI pipeline (Continuous Integration) where tests are run. There should be interfaces or scripts to run unit tests, integration tests (perhaps simulating a day’s trading), and to build documentation. This ensures future maintainability but is more a process requirement. The Phase 1 testing strategy includes dependency injection for components (so one can use a MockBroker or MockDB in tests)[64][65]. The requirement is that major interfaces (broker, database, bus) have mock or stub implementations in the codebase to facilitate testing without real external services.
  3.2 Functional Requirements
  This section details functional requirements for each engine and service in the system. Each subsection corresponds to one engine/service, describing its responsibilities and the specific requirements (behaviors and interfaces) it must satisfy. The interfaces (methods, event types) are given where applicable, including input/output and any constraints on parameters. The requirements assume the presence of all engines as in the full architecture (some engines may be partially implemented in DB1 but their interfaces are defined for future use).
  Each requirement is labeled FR-* for “Functional Requirement” with a mnemonic for the engine (e.g., FR-OE for OrchestrationEngine). These map to the traceability matrix in Section 4 for cross-reference to architecture components.
  3.2.1 OrchestrationEngine
  Role: Coordinates the end-to-end trading cycle in correct sequence[5], both for live trading (reacting to new data events) and for batch modes like backtesting.
  •    FR-OE-1: The OrchestrationEngine shall coordinate the end-to-end trading cycle by invoking each engine in the prescribed order for every new data event or scheduled tick[5]. It acts as the conductor: for example, on receiving a market data event, it triggers SignalEngine, then RiskEngine, then ExecutionEngine, then PortfolioEngine, then AnalyticsEngine in sequence[66][67]. This ensures deterministic processing of each “cycle” of decisions.
  •    FR-OE-2: The OrchestrationEngine shall initiate a trading cycle whenever a triggering event occurs. Trigger events can be market data arrivals (e.g., a new price tick) or timer events (e.g., end-of-interval signals for periodic tasks). On receiving such an event via the StreamingBus, OrchestrationEngine will start a cycle by extracting necessary context (e.g., the data tick, the current portfolio snapshot) and passing it to the first step (SignalEngine)[68]. In backtesting mode, the trigger is reading the next historical data point from a dataset.
  •    FR-OE-3: Pre-flight Governance Checks: Before invoking each major engine step, OrchestrationEngine shall perform a pre-check with GovernanceEngine[69]. This involves calling a GovernanceEngine method or event (e.g., preflight(context)) with the context of what is about to happen. For example, before generating signals, it might ask Governance if the system is allowed to trade at this time (if not, it could skip or delay). Before executing orders, it definitely asks GovernanceEngine to allow/deny the order (e.g., compliance check)[70]. GovernanceEngine will respond (likely synchronously in the current design) with an allow/deny and possibly modifications. The OrchestrationEngine must enforce the decision (abort the cycle if denied, apply modifications if given) and log any override.
  •    FR-OE-4: The OrchestrationEngine shall propagate shared context between engines during a cycle. It receives input (market event), and maintains or builds a context object (including current portfolio state, any signals produced, any decisions made). It passes relevant pieces to each engine call. For example, after RiskEngine approves a signal (possibly adjusted), Orchestrator passes the approved signal to ExecutionEngine. It also collects outputs (like ExecutionEngine returns an ExecutionReport) and passes that onward (to PortfolioEngine)[15]. This context propagation ensures each engine has the data it needs without directly querying each other (adhering to a separation of concerns).
  •    FR-OE-5: The OrchestrationEngine shall emit tracing information and performance metrics for each cycle. It will timestamp each step (e.g., how long Signal processing took, how long risk evaluation took) and either log these or emit events (like a special TraceEvent on the bus) that the AnalyticsEngine or monitoring tools can consume[5]. This requirement supports performance tuning and debugging by providing insight into pipeline timings.
  •    FR-OE-6: The OrchestrationEngine shall provide an interface for running in live mode and backtest mode. This corresponds to two primary methods: run_cycle(event) for processing a single incoming event in live operation, and run_backtest(config) for orchestrating a loop over historical data[5]. In backtest mode, it will initialize engines for backtesting (e.g., PortfolioEngine in backtest mode might reset to a start capital, ExecutionEngine might simulate fills deterministically). Orchestrator will iterate through a dataset (provided via config) and call the engines in order for each data point. It must also handle end-of-backtest summary (like telling AnalyticsEngine to do a full analysis) once all data is processed.
  •    FR-OE-7: The OrchestrationEngine shall manage the startup and shutdown sequence of the system. On system start, it initializes all engines (constructing them, injecting any dependencies like references to bus or config) and performs tasks like loading persisted state (positions, orders) from the database, and synchronizing with the broker (via ExecutionEngine or PortfolioEngine) to ensure internal state matches reality[71][51]. This may include invoking a position reconciliation component before trading begins. On shutdown, OrchestrationEngine should ensure all engines flush any pending state to the database, close connections (broker, database, bus), and possibly record a snapshot of the current state. It should coordinate so that no new cycle starts during shutdown sequence.
  •    FR-OE-8: The OrchestrationEngine shall incorporate safety checks at the global level. In particular, it should check the Kill Switch status at appropriate points (e.g., at the start of each cycle)[7][72]. If the kill switch is active, Orchestrator must immediately halt initiating new trades – essentially abort cycles early. If kill is triggered mid-cycle, Orchestrator should propagate that by not calling further engines (e.g., skip ExecutionEngine call if kill switch flips after risk step) and log that the cycle was aborted due to kill. Orchestrator also monitors Circuit Breaker states (likely via Governance or global context) – if an external dependency (like broker API) is in a failure state, Orchestrator might defer or cancel cycles that would rely on it, until things recover.
  •    FR-OE-9: The OrchestrationEngine shall produce a final audit event or summary at the end of each cycle. Once a cycle completes (or even if it’s skipped due to no action), Orchestrator calls GovernanceEngine’s audit function with a summary of what transpired (e.g., “Data event at time X yielded N signals, M orders, outcome Y”)[73]. GovernanceEngine will log this. This ensures every trigger event has a corresponding audit trail entry, even if no trade was made (which is important for proving the system was operational and decided “no action” legitimately).
  •    FR-OE-10: The OrchestrationEngine’s design should allow scaling or bypass in future – e.g., if the event bus fully manages routing, some flows might not need explicit orchestrator calls (engines could subscribe and chain events themselves). However, for consistency and ordering, DB1’s design uses Orchestrator as a single threaded (or single coroutine) manager for the pipeline. The requirement is that outcomes remain the same if we later distribute it: it might spawn parallel tasks for different symbols but still enforce order within each symbol’s events, etc. (This is more of a design note: essentially, orchestrator could eventually become a set of orchestrators per symbol or per strategy, but each would follow these rules.)
  (Interfaces summary: Orchestrator.run_cycle(event: MarketDataEvent) -> None, Orchestrator.run_backtest(config: BacktestConfig) -> Report. Both use internal calls to engines. The orchestrator also may expose methods to start/stop the live loop, e.g., start() which subscribes to bus or schedules ticks, and stop() to gracefully halt.)
  3.2.2 StreamingBus
  Role: Provides a unified publish/subscribe event fabric for the system, ensuring all components can exchange messages asynchronously and in a decoupled manner[5]. It abstracts the underlying transport (in-memory vs Kafka/Redis) and adds features like schema validation, filtering, and history.
  •    FR-SB-1: The StreamingBus shall allow any engine or service to publish an event containing a data payload to a logical topic or event type[5]. The bus will ensure the event is delivered to all subscribers interested in that topic/type. The interface for publishing is publish(event: BusEvent)[74][75]. In DB1, this is an in-memory method call (that will in turn call subscribed handlers); in future, it will produce to Kafka or similar. This publish action must be non-blocking or minimally blocking – e.g., in async context, it may queue the event and return, letting actual delivery happen concurrently.
  •    FR-SB-2: The StreamingBus shall provide a way for components to subscribe to certain events. The interface is subscribe(topic_pattern, handler_func)[74]. A subscription includes a filter (could be a topic string or a predicate on event fields) and a handler callback (which may be a coroutine or function to execute when events matching arrive). The bus must maintain a registry of subscriptions and on each publish, efficiently determine which handlers to invoke[76]. Handlers will likely run asynchronously (the bus should dispatch events in parallel if multiple subscribers). If a handler is slow, the bus either awaits it (with possible timeout) or runs it in background while tracking if it times out (to avoid one slow subscriber blocking all)[77][78].
  •    FR-SB-3: Schema Validation: Upon publish, the StreamingBus shall validate the event’s payload against a schema if a validator is configured[49]. Each event type will have an expected schema (for example, a Signal event should have fields X, Y, Z). The bus can use a schema validator function (as code suggests, possibly a Pydantic model or a custom function) to ensure data integrity. If validation fails, the bus must reject/drop the event and log a warning[49][79]. Under no circumstance should a malformed event be delivered to subscribers as that could cause runtime errors in engines. This mechanism is crucial for data integrity in the pipeline (NFR-DI category).
  •    FR-SB-4: Governance Tagging/Filtering: The bus should integrate with the GovernanceEngine such that each event published can be tagged with governance metadata (like a policy ID or a risk level)[5]. In practice, this could mean the publish call triggers a governance hook: e.g., publish_governance_hook(event) that returns whether the event is allowed to propagate[80]. The requirement is that if GovernanceEngine says an event is not allowed (maybe a certain type of event is blocked by policy), the bus shall drop it (not deliver)[81]. This is a second line of defense after the pre-flight checks at Orchestrator level – e.g., even if Orchestrator tried to publish an OrderEvent, if GovernanceEngine had changed a rule mid-cycle, it could still block via the bus. This is an extra safeguard ensuring no forbidden event flows through the system.
  •    FR-SB-5: Event Filtering: The subscription mechanism shall support filtering not only by topic name but possibly by content (e.g., only signals for a specific symbol, or only high-priority events). The BusEvent structure might include metadata like event_type, source, symbol, priority[82]. The subscribe function should allow specifying criteria (maybe subscribe to all Signal events, or all events where symbol == "AAPL"). The bus will then check these in _find_matching_subscriptions[76]. This allows efficient routing; e.g., PortfolioEngine might subscribe only to ExecutionReport events, ignoring others.
  •    FR-SB-6: Concurrency & Order Guarantees: The StreamingBus shall handle multiple events concurrently without conflict. In DB1’s in-memory bus, that means using asyncio tasks to call handlers for each event, with a semaphore or limit on concurrent handlers to avoid overload[83][84]. The bus must ensure that the same subscription’s events are processed in order (for Kafka, partitioning by symbol could ensure order per symbol; in in-memory, maybe bus processes one event at a time sequentially for simplicity). The design target is at-least-once delivery: a subscriber will get the event unless it crashes or times out. If a handler times out or raises, the bus could log error and increment a metric (like handler_errors)[85]. Optionally, the bus may implement a retry for failed handlers (the code hints at a config retry_failed_handlers to retry a few times with backoff)[86]. The requirement is to make event delivery robust – transient errors in handlers should not permanently lose an event without at least one retry attempt.
  •    FR-SB-7: The bus shall impose payload size limits to protect the system from extremely large messages. For example, if someone inadvertently tries to publish an event with a huge data payload (say, an entire day’s tick data in one event), the bus should detect if the serialized size exceeds a configured maximum (e.g., 1 MB) and drop it[87]. It will log a warning in that case. This prevents memory blow-ups or oversize Kafka messages that break brokers. The max_payload_size is configurable in BusConfig, and publish must respect it.
  •    FR-SB-8: Event History & Replay: The StreamingBus shall maintain a history log of events if enabled[88]. In DB1, this could be an in-memory list _history of recent events (with a history_max_events limit)[88]. This history can be used for debugging (replay recent events) or for backtesting (the ProofBench might simulate reading from this log). In a Kafka setup, Kafka itself is the history (via topic retention). But having a small in-memory history even with Kafka is useful for quick access or in case Kafka retention is short. The requirement: if enable_history is true, every published event is appended to history, and if history exceeds history_max_events, the oldest events are discarded to keep memory bounded. The history can be exposed via an interface (e.g., bus.get_history(n) to retrieve last n events) for admin or debugging usage.
  •    FR-SB-9: Performance Metrics: The StreamingBus shall collect metrics on events for monitoring. Specifically, it should count how many events have been published, how many delivered, how many dropped (due to validation or governance), how many handler errors, etc. The BusMetrics dataclass covers some of these[89]. For latency, the bus can timestamp events on publish and then update an avg_latency_ms as events complete delivery[89]. If using external message brokers, the bus might measure end-to-end time differently (time in queue + processing). These metrics should be accessible (maybe via a method or via a global monitoring component). The requirement is to enable observability of the event system: operators should be able to see if events are backing up or being dropped.
  •    FR-SB-10: The bus design shall support durability such that no events are lost in transit in production mode. For Phase 1, in-memory bus means if the process crashes, events are lost; but since Phase 1 is also running persistence (writing orders to DB before execution, etc.), we accept that trade-off. In Phase 2 with Kafka, durability is provided by Kafka’s log (with at-least-once semantics). The bus adapter for Kafka should create topics with an appropriate replication factor (if multi-broker cluster) and set a retention that covers at least the trading day (or what’s required for possible recovery). The system should define how it will recover if it restarts mid-day – possibly by reading recent events from Kafka (or more likely, reconstructing state from DB and broker directly). In any case, “no event lost” means if a trade signal was generated and acknowledged by bus, it should either be processed or available to reprocess after restart. This is a design requirement aligning with reliability.
  (Interfaces summary: Provided by ordinis.bus module: StreamingBus.publish(event), StreamingBus.subscribe(topic, handler), and possibly unsubscribe, get_history. The events are likely objects with fields, possibly subclassed by event type, but must at least have event_type for routing. BusConfig allows configuration of adapter type (“in_memory”, “redis”, “kafka”), schema_validator function, governance_hook, payload size, concurrency (max_concurrent_handlers), timeouts, etc.)
  3.2.3 SignalEngine
  Role: Consumes market data (and any relevant features) to produce trading signals (trade recommendations). This is the quantitative strategy logic: analyzing price patterns, indicators, etc., possibly using machine learning models, and outputting signals for potential orders[25].
  •    FR-SIG-1: The SignalEngine shall generate trading signal events from incoming market data. Specifically, upon receiving a new market data input (e.g., a tick, bar, or aggregated feature set for a time step), the SignalEngine will compute whether any trade signal (buy, sell, hold) is warranted[25]. If yes, it creates one or more Signal objects containing information such as the asset, recommended action (buy/sell), size (quantity or percentage), and perhaps a confidence or score. These signals are then published onto the StreamingBus (as Signal events) for downstream consumption[25]. If no trading action is recommended, it may either publish nothing or explicitly publish a “no-signal” event (the design likely just omits sending any signal event in that case).
  •    FR-SIG-2: The engine shall incorporate feature aggregation and technical indicators in producing signals[25]. This means the SignalEngine will maintain or compute various features from raw data: e.g., moving averages, RSI, volatility measures, order book imbalance (if available), sentiment scores (if alt data provided), etc. These features may be computed on the fly or updated incrementally. The requirement is that the engine can consume not just a single price point but the relevant context (like past N bars if needed for an indicator). In MVP, this could be achieved by the orchestrator passing a data frame or by SignalEngine keeping an internal buffer of recent data. For performance, heavy feature calc should be efficient (possibly vectorized or cached).
  •    FR-SIG-3: The SignalEngine shall support predictive modeling to generate signals[25]. It can use one or multiple machine learning models, such as gradient boosting machines (GBM), XGBoost models, LSTMs, or Transformer-based sequence models, as configured for the strategy. For example, a model might predict probability of price rise in next interval; the engine then translates that into a buy/sell signal if probability > threshold. The requirement is that integration of models is possible. In Phase 1, these models might be simplistic or even a placeholder (like a simple threshold rule), but the design should allow plugging in a trained model easily (e.g., loading from a pickle or calling a predict function). If multiple models are used (ensemble), the engine should combine their outputs (e.g., majority vote or weighted average).
  •    FR-SIG-4: The SignalEngine shall perform sanity checks on any generated signals before outputting[25]. These checks ensure that signals make sense and are actionable. Examples: if a signal suggests buying a quantity that far exceeds any reasonable volume (maybe due to model glitch), it should be capped or discarded. If a buy and a sell signal for the same asset are generated simultaneously by different internal sub-models, the engine may resolve them (maybe net them off or choose the stronger one). Also, if the engine computes a signal that is identical to an existing position (e.g., signals to buy what we already hold fully), it might decide not to trigger anything. The engine should also attach a timestamp and unique ID to each signal for traceability. Basic data quality checks like non-NaN prices, non-zero volumes in input data should be done too (though input likely validated by bus already).
  •    FR-SIG-5: Interface & Invocation: The SignalEngine interface shall include a method generate_signals(data_frame) -> List[Signal][25]. Orchestrator (or bus subscription in future) calls this for each new data input. The data_frame (or MarketDataEvent) contains the market info needed (price, volume, maybe recent window of data). The output is a list of Signal objects. Each Signal must contain details: symbol, action (Buy/Sell), quantity or size, perhaps a target price or confidence, and a timestamp. The signals should be immediately published to the bus (if orchestrator is calling, Orchestrator can publish them; if the engine is autonomous on bus subscription, it will call bus.publish itself). The engine should be able to generate multiple signals from one input if multiple instruments or multiple strategies are handled by one engine (but MVP likely one instrument or one strategy at a time).
  •    FR-SIG-6: The SignalEngine should be capable of utilizing retrieval-augmented context to inform signals. In particular, it can optionally query the Synapse engine for relevant information to the current situation[90]. For example, if the strategy is news-informed, upon a significant price move the SignalEngine might request recent news headlines from Synapse (which indexes news) to decide if the move is news-driven or random. Or if the engine is uncertain, it could ask Cortex for an explanation (though that is more advisory). The requirement is that the SignalEngine can make a call to Synapse.retrieve(query) providing some context (like “latest news for AAPL” or “similar past pattern events”) and get back snippets. This call should not block trading if it’s slow; likely it’s used in research mode or asynchronously (maybe the signal is generated and a narrative attached later via AnalyticsEngine). In any case, if used, it must incorporate any retrieved info deterministically (for example, not letting LLM directly decide trade, but maybe adjusting risk if a major news event snippet is found).
  •    FR-SIG-7: Signal Attributes: Each generated signal should have a defined schema (enforced by bus validation). It might include: signal_id (unique), timestamp, symbol, direction (buy/sell), quantity (or percentage of portfolio or number of contracts), signal_type (like entry/exit or long/short), and possibly reason or model_id that produced it (for audit). The engine shall fill these appropriately. If the strategy is based on indicators, it could set reason = “RSI oversold” for audit trail. This helps the GovernanceEngine’s audit logs to record why a trade was signaled, which is useful for later analysis and compliance.
  •    FR-SIG-8: The SignalEngine shall incorporate the current portfolio state into its decision-making when needed[91]. For instance, if it already holds maximum allowable position in a stock, it should not generate another buy signal for it (or if it does, maybe mark it as a rebalance request). The Orchestrator or PortfolioEngine can supply a snapshot (via arguments or a shared state) of current positions and exposures. The engine uses this to e.g., avoid double-buying or to decide between multiple signals (if limited capital, might prioritize one). Essentially, SignalEngine operates with awareness of what’s currently in the portfolio (especially for strategies that add to positions or exit positions). This is reflected in architecture: PortfolioEngine provides snapshots to SignalEngine[27].
  •    FR-SIG-9: No Direct Auto-Trade from AI: Ensure that if any AI (LLM) is involved in suggesting a signal, the final decision remains rule-based. (For example, if using Cortex to analyze code patterns that suggest a trade, the SignalEngine code must still turn that suggestion into a formal signal only if it meets predefined criteria.) This requirement aligns with the governance policy that AI usage remains advisory in Phase 1/2[12]. Therefore, any direct LLM-proposed signal must be confirmed by deterministic logic before being emitted (or simply not used in live trading without human review). This might not come up in MVP if AI is not actually generating trades, but stating it for completeness.
  •    FR-SIG-10: The engine should log its key decisions. For example, if it decided not to output a signal because of a sanity check or because risk of a signal was too high, it should log that event (maybe at debug level). If it did output signals, logging those details (with values of key indicators or model outputs that led to it) is useful for later analysis (maybe part of a research mode). This is more of an implementation guideline but helps with fulfilling traceability – ensuring one can reconstruct why a signal occurred by reading logs or audit.
  (Interfaces summary: SignalEngine.generate_signals(market_data) -> List[Signal]. Possibly SignalEngine.init() to load models or set parameters. It might also have methods for training/updating model (in offline mode, triggered by LearningEngine), but that is separate from runtime signal generation. For Phase 1, signals are likely simple enough not to require heavy compute, but design anticipates heavier ML usage.)
  3.2.4 RiskEngine
  Role: Enforces predefined risk management rules on proposed trade signals before they can proceed to execution[25]. This engine acts as a checkpoint to ensure strategy actions are within risk limits (position sizing, exposures, loss limits, etc.), implementing a deterministic and auditable set of policies.
  •    FR-RISK-1: The RiskEngine shall evaluate each incoming trade signal (or order request) against a set of risk policies to determine whether it can be approved as-is, needs modification (e.g., downsizing), or must be rejected[25]. It essentially performs a pre-trade risk check for every potential trade. This is triggered for each signal produced by SignalEngine (the Orchestrator will call RiskEngine for each signal, or RiskEngine may subscribe to Signal events on the bus).
  •    FR-RISK-2: The risk policies enforced shall include at least:
  •    Exposure Limits: e.g., maximum position size per asset (no single stock position > X% of portfolio or > N shares)[25], maximum sector exposure if applicable, maximum leverage (if margin used).
  •    Capital and Leverage Checks: Ensure buying power is sufficient for a buy signal (taking into account margin if allowed) – essentially if trying to buy more than available cash + margin, either restrict or reject.
  •    Stop-Loss/Take-Profit: If a signal would violate a stop-loss rule (e.g., not allowed to add to a losing position beyond certain threshold) or if an asset’s volatility is too high at the moment, risk might disallow the trade.
  •    Volatility and Liquidity Constraints: If current market volatility (e.g., VIX or asset’s ATR) is above a threshold, maybe block new positions (to avoid trading in very volatile conditions). If the asset’s recent volume is low relative to the order size (liquidity check), risk might flag that.
  •    Concentration Limits: E.g., ensure total exposure to any single sector or asset class doesn’t exceed a percentage of portfolio.
  •    Regulatory Constraints: For example, if the strategy tries short selling but that’s not allowed, RiskEngine must reject those signals. Or if a day-trading rule or “no trading certain stocks flagged as restricted” is in place, enforce it.
  (These are examples; the specific policies can be configured. The architecture mentions exposure, leverage, sector caps, stop-loss, volatility, liquidity, contract-specific rules[25] which covers most of the above.)
  •    FR-RISK-3: The RiskEngine interface shall provide a method evaluate(signal, portfolio_state) -> (approved: bool, adjusted_signal: Signal, reasons: List[Reason])[25] (the actual return might be packaged in a RiskEvaluation object). When invoked, it takes a proposed Signal and the current portfolio state (positions, cash, etc.) and applies all checks. It returns whether the trade is allowed, and if allowed possibly an adjusted signal (which could be identical to input or modified). Adjustments include resizing the quantity to meet limits (e.g., if asked to buy 1000 shares but max allowed is 500, it would output a Signal adjusted to 500 shares and mark that it was reduced)[25]. If not approved, the adjusted_signal may be null or a copy with quantity 0, and reasons will contain codes or messages for each violated rule.
  •    FR-RISK-4: The RiskEngine shall log or attach reasons for any rejection or modification of signals[25]. These reasons should be granular (e.g., “ExposureLimitExceeded: requested $50k, max $30k” or “KillSwitchActive” if applicable). At least one reason code should be provided for a reject; multiple can be provided if multiple rules were violated. This list of reasons is important for the audit trail and for developers to understand strategy behavior. The GovernanceEngine’s audit log will include these reasons when the risk decision is logged[25].
  •    FR-RISK-5: If the RiskEngine approves a signal, it effectively passes it through. If it adjusts, it should clearly mark the new parameters. If it rejects, it might still forward a “rejection event” or instruct the Orchestrator to treat it as a no-go. The design likely has Orchestrator calling RiskEngine and then branching logic (if approved, call ExecutionEngine; if rejected, skip ExecutionEngine and log the event). The requirement is the RiskEngine must ensure that no disapproved trade reaches execution. In an asynchronous bus design, RiskEngine could publish an approval event or a rejection event which ExecutionEngine listens for. But since we have orchestrator, a direct call suffices in Phase 1.
  •    FR-RISK-6: Kill Switch Integration: The RiskEngine shall always check the global kill switch status before approving any trade[92]. If the kill switch is active (which might mean trading is halted due to some condition), RiskEngine should outright reject all signals (with reason “KillSwitchActive”)[72]. In practice, Orchestrator might also check kill earlier, but RiskEngine provides a second layer of defense. This ensures that if kill is triggered by something outside orchestrator’s view (like a manual file trigger the RiskEngine monitors), it still stops trades. The RiskEngine might load kill switch status from a shared state or call a KillSwitch component (like if kill_switch.is_active: reject).
  •    FR-RISK-7: Circuit Breaker/External Dependency Checks: If a trade relies on an external service that is down (for instance, if the market data feed is known stale, or broker API is in circuit open state meaning it’s failing), RiskEngine may choose to reject or delay signals. This is a bit situational: likely if broker API is down, ExecutionEngine will fail anyway; but Risk could preemptively block new orders if it knows execution can’t happen. Alternatively, this might be more of an orchestrator or ExecutionEngine responsibility. But RiskEngine should at least be aware of any known systemic risk conditions, e.g., “market closed” (time-based rule, no trading after hours), “broker offline” (maybe comes via GovernanceEngine or CircuitBreaker alert). The requirement: incorporate environment state checks into risk evaluation so that trades are only allowed in safe conditions.
  •    FR-RISK-8: Post-Trade Risk (Optional for MVP): While primarily pre-trade, the RiskEngine or associated policies should consider if a new trade would cause any post-trade risk violations. For example, if the new position would cause the portfolio VaR (Value at Risk) to exceed a threshold, or if it would lead to crossing a drawdown limit if it went poorly. This is more advanced and probably in later phases (requires computing portfolio risk metrics in real-time). In MVP, simpler limits suffice. But the architecture is such that we can extend risk checks to more complex calculations (maybe linking with an external risk model or scenario analysis tool).
  •    FR-RISK-9: Determinism and Performance: The RiskEngine’s decisions must be fast and deterministic. Checking simple limits is O(1) or O(number of positions) which is trivial. The risk evaluation should be done in milliseconds so as not to bottleneck the trading loop. It shall not rely on any non-deterministic or extremely long process (no waiting for an external web call in risk checks, for example). Also, given the critical role, it must be thoroughly tested (likely unit tests for each policy). The results should not vary run-to-run given the same input (ensuring reproducibility for audit).
  •    FR-RISK-10: The RiskEngine shall have a mechanism to update its risk policy parameters (like position limits, max loss) without code changes, e.g., via a config file or governance interface. For instance, risk limits might be stored in a JSON/YAML config that RiskEngine reads at startup (or even can be reloaded on the fly if GovernanceEngine pushes an update). This ensures flexibility to tighten or loosen risk rules as needed (especially important as trading strategies evolve). The engine should validate any new risk settings (no nonsense values) and apply them immediately or at next signal evaluation. If integrated with GovernanceEngine, a policy version can be tracked.
  (Interfaces summary: Likely RiskEngine.evaluate(signal, portfolio) -> RiskDecision as described. The RiskDecision could be a tuple or dataclass with fields: approved (bool), new_signal (Signal or None), reasons (list of str or codes). In code, maybe implemented as RiskPolicy.evaluate_order as in Phase1 API reference[93] with a dataclass RiskEvaluation (passed, reason, action) – however, that appears to consider one policy. In our engine, it may aggregate multiple policies but conceptually similar.)
  3.2.5 ExecutionEngine
  Role: Takes approved trade signals (or orders) and handles the actual execution: creating orders, submitting them to the broker or exchange, simulating fills for backtests, and reporting execution outcomes[94]. It effectively converts “I want to trade X” into actual trade transactions.
  •    FR-EXEC-1: The ExecutionEngine shall receive approved trade signals (which specify what to buy/sell and how much) and initiate the actual order execution process[94]. For each such signal, ExecutionEngine creates an Order object capturing the necessary details for execution: symbol, side (buy/sell), quantity, order type (market/limit), price (if limit), etc. (If the signal itself already has some of these details, they are transferred; if not, defaults are chosen, e.g., all signals might be executed as market orders by default in MVP.) It shall then proceed to execute that order through the configured execution adapter or simulation.
  •    FR-EXEC-2: The ExecutionEngine must interface with the BrokerAdapter to actually send orders for live trading. In Phase 1 (paper trading via Alpaca), this means converting the Order object into the Alpaca API call and receiving a response[50]. The engine should handle this asynchronously to not block the main loop (use await on API call). It should also wrap the call in the CircuitBreaker context (meaning if the broker had recent failures, the circuit might be open and the call will throw CircuitBreakerOpen immediately)[50][95]. If the circuit is open or API call fails, ExecutionEngine should mark the order as failed (status = rejected) and record the error (perhaps in the order repository and via an alert)[52].
  •    FR-EXEC-3: Simulated Execution (Backtesting): In backtest or simulation modes, the ExecutionEngine shall simulate order fills. It should support pluggable fill models: e.g., an immediate fill model where market orders are filled at next tick’s price (or same tick’s close price), or a more complex order book simulation (maybe in later phases)[94]. For DB1, a simple immediate fill at current market price can be used for market orders (since data likely bar data). Limit orders could be simulated by checking if subsequent data hits the price, etc., but Phase 1 might not include limit orders to keep it simple (or assume they fill if price is favorable in that bar). The ExecutionEngine must ensure that the simulation is faithful and consistent (so that backtest results are comparable to live trading within reason).
  •    FR-EXEC-4: After attempting execution (live or simulated), the ExecutionEngine shall produce an ExecutionReport event detailing the outcome[94]. If the order was filled (or partially filled), the report includes fill quantity, fill price(s), timestamp of fill, any slippage or commission. If rejected or not filled, it indicates that. These ExecutionReport events are published on the StreamingBus[94] for other components to consume (PortfolioEngine will use it to update positions, AnalyticsEngine to record P&L, etc.). The interface can be a return value from the execute method in synchronous context and/or an event on the bus. In orchestrated mode, Orchestrator calls execute and gets a result which it then passes on. In an event-driven future, ExecutionEngine would subscribe to signals and publish ExecutionReports. In Phase 1, likely orchestrator handles passing it along directly.
  •    FR-EXEC-5: The ExecutionEngine must perform a governance check before finalizing the send of an order to an external venue[94]. This is a last-moment check akin to what trading firms call “pre-trade compliance”. Orchestrator might already have done a pre-check via GovernanceEngine, but since ExecutionEngine is about to actually place the trade, it should double-check with GovernanceEngine (maybe calling preflight again with context “about to execute order X”). If GovernanceEngine responds deny (for example, maybe a new rule or a constraint like “too many orders per minute” triggered), the ExecutionEngine should abort sending the order and instead treat it as rejected (with reason from governance). This double-check is explicitly mentioned[94] (“Performs governance double-check before sending to venue”).
  •    FR-EXEC-6: Order Tracking: The ExecutionEngine shall maintain an internal record of active orders and track their statuses until completion. For live trading, after submitting an order, it might not fill instantly, so we need to monitor for fills. The engine can do this by either polling the broker for order status or subscribing to broker’s updates (if any). In Phase 1, given likely immediate or near immediate fill in paper trading, this can be minimal. However, the design should have in place that every submitted order’s ID is stored, and a method track_fill(order_id) exists to query status (the code snippet suggests one)[96]. If an order remains pending for a long time, the engine might decide to cancel it or raise an alert. In simulation, this tracking is simulated by immediate result.
  •    FR-EXEC-7: The ExecutionEngine shall persist all orders and execution results to the database (through the persistence layer). In Phase 1, the engine or orchestrator uses OrderRepository to insert a new order record when created and update it when status changes (submitted -> filled, etc.)[97][98]. This ensures a permanent record of trades. The requirement is that no execution happens without a corresponding entry in the Orders table, and fills recorded in the Fills (or Trades) table as appropriate. This persistence allows analysis and parity between backtest and live (since even backtest orders go through same repository, ensuring same data structure)[99].
  •    FR-EXEC-8: Safety Mechanisms: The ExecutionEngine shall integrate with KillSwitch and CircuitBreaker to ensure safety in execution:
  •    If the kill switch is triggered while an order is in flight or before sending an order, the ExecutionEngine should refrain from placing new orders (even if Risk said OK earlier). If kill comes mid-order, perhaps the engine should attempt to cancel the order (if possible via broker API). In any case, once kill is active, ExecutionEngine stops sending further orders and marks any pending ones for cancellation or just stops.
  •    The ExecutionEngine uses the CircuitBreaker for the broker API: it's typically implemented such that any call to broker is within a context manager that automatically opens the circuit after N failures and then short-circuits further calls for a timeout period[50][95]. The ExecutionEngine must configure this (like set threshold N and timeout T via environment or config)[59][60]. If the circuit is open, engine should avoid calling broker and instead quickly mark orders as failed (with a note that broker unreachable). Additionally, if certain error conditions are encountered (like consistent timeouts), engine might trigger a kill-switch as a drastic measure if configured to do so (some firms auto-kill trading if connectivity lost to avoid ghost orders).
  •    FR-EXEC-9: Multiple Execution Paths: The engine design should allow multiple ways to execute: e.g., a “paper mode” (where it sends to a paper trading service or simulates), and a “live mode” (real broker API). Additionally, it could support an internal matching engine or direct exchange connectivity in future. The requirement is that adding a new adapter (via the BrokerAdapter interface) or switching execution mode is done via configuration, not requiring rewriting the engine. In Phase 1 dev vs prod, we see this: dev uses a PaperTrader stub, prod uses Alpaca real trading[100]. The engine just gets an adapter object and uses it, oblivious to whether it’s real or simulated beyond that.
  •    FR-EXEC-10: After execution, any alerts related to execution should be raised. For example, if an order is rejected (maybe risk compliance at broker side or technical error), the engine should notify the Alerting system. In Phase 1, a simple AlertManager logs and maybe shows a desktop notification[101]. The ExecutionEngine should call that or emit an event that AlertManager listens to (e.g., an ExecutionReport with status “rejected” might trigger an alert). Also, if slippage is high (the fill price is far worse than expected), or partial fill occurred and remainder cancelled, those might warrant warnings. The requirement: ExecutionEngine communicates such anomalies clearly, either through the ExecutionReport fields or separate alert events.
  •    FR-EXEC-11: Portfolio Update Triggers: ExecutionEngine, after fill, should notify or trigger the PortfolioEngine to update positions. In orchestrator flow, after receiving ExecutionReport, Orchestrator calls PortfolioEngine update. If bus-driven, ExecutionEngine’s publish of ExecutionReport event would naturally be consumed by PortfolioEngine. The requirement is effectively that ExecutionEngine must ensure the system knows the trade happened so that positions and P&L update – which is covered by publishing ExecutionReport. Possibly, if needed, ExecutionEngine could call PortfolioEngine directly in some synchronous cases (like in backtest, after an order fill, update positions immediately to use in next tick). But if orchestrator orchestrates, it's handled. So the main requirement is not to drop the ball on position updates: trade results must flow to portfolio.
  •    FR-EXEC-12: The ExecutionEngine shall provide functionality for position reconciliation on startup or on demand. For example, on startup, it might call broker’s get_positions and compare with internal DB (which might be from last run)[53][54]. If discrepancies found, it should report them (to Governance and Alert) and potentially adjust internal records or even trigger kill-switch if severe. In Phase 1, a separate component “Position Reconciliation” might do this (as per production architecture doc)[102][103], but ExecutionEngine is closely tied since it deals with orders. Perhaps PortfolioEngine is more responsible for positions, but the requirement stands that any mismatch between broker and internal state is detected. The ExecutionEngine (or FlowRoute engine per code) does have logic to sync account and positions on init[53][54]. So likely this requirement is implemented by FlowRoute’s initialize() calling sync_broker_state()[71][104]. It fetches broker account and positions, logs differences, and sets internal accordingly. So indeed ExecutionEngine must do that.
  •    FR-EXEC-13: Fee/Commission Accounting: If applicable, ExecutionEngine should account for trading fees or commissions in the ExecutionReport (and pass them to PortfolioEngine for P&L). Many retail APIs like Alpaca have zero commission, but others might not. Even if zero, slippage is an implicit cost. The requirement is to include a placeholder for commission or slippage calculations. In backtesting, we might configure a commission per trade or slippage model. The ExecutionEngine should deduct that from realized P&L (which PortfolioEngine will handle, but ExecutionEngine should at least output it in the report). This ensures performance metrics are realistic.
  •    FR-EXEC-14: Partial Fills and Multi-Fills: The engine must handle partial fills (order not completely filled at once) and multiple fill events (like in real markets, an order might fill in pieces). If using Alpaca or IB, they might send fill events per chunk. ExecutionEngine should accumulate these (if needed) and update the order status accordingly (e.g., after each partial fill, update filled_quantity in OrderRepository, if order still not complete keep it open). When final fill or cancel happens, then mark done and publish final ExecutionReport summarizing all fills. Possibly it could publish interim reports too (but to avoid flooding, maybe just final summary in MVP). In simulation, partial fill can be simulated if volume is limited, but MVP likely treats each order as single fill for simplicity.
  (Interfaces summary: Main one is ExecutionEngine.execute(order: Order, market_state) -> ExecutionReport[94]. Additionally, ExecutionEngine.track_fill(order_id)[96] for tracking. For initialization: maybe ExecutionEngine.initialize() to sync with broker[71]. The ExecutionReport likely contains fields: order_id, status (filled/part-filled/rejected), filled quantity, avg fill price, execution timestamp(s), maybe an error message if any, etc. The Order object it takes could be akin to the OrderRow in repository[105], or a simpler in-memory object. The engine should fill out broker_order_id if one is given by broker, and store any response message[98].)
  3.2.6 PortfolioEngine
  Role: Maintains the portfolio state (positions, cash, leverage) and applies any portfolio-level logic (like rebalancing, constraints at portfolio aggregate level). It updates the state after executions and can generate new orders for rebalancing or cash management if needed[27].
  •    FR-PORT-1: The PortfolioEngine shall maintain an up-to-date record of all open positions (holdings in various assets), the current cash balance, and any margin or leverage metrics[27]. It provides this information to other engines on request (e.g., RiskEngine gets current exposure, SignalEngine gets current position to decide trades). These records are updated whenever trades occur and as market prices move (for mark-to-market P&L). The engine might rely on Analytics or external data to mark-to-market continuously; but at minimum, after each ExecutionReport (trade), it updates positions and cash exactly.
  •    FR-PORT-2: On receiving an ExecutionReport (trade fill), the PortfolioEngine shall update the corresponding position:
  •    If it’s a buy fill, increase the position for that asset by the filled quantity (or create a new position if none existed), and decrease cash by the cost (price * qty) plus any commission[106][107]. Also adjust margin usage if applicable.
  •    If a sell fill, decrease the position (or close it if quantity goes to zero), and increase cash by proceeds minus commission.
  •    Update average cost of position if partially filled or if adding to existing position (use weighted average or FIFO as needed).
  •    Recalculate unrealized P&L for that position (difference between current market price and average cost * quantity)[108][109].
  •    Update overall portfolio value (cash + sum of positions’ market value) and other metrics like leverage ratio (if using margin).
  This ensures internal state reflects reality after each trade. Persistence: The engine should also update the database via PositionRepository/FillRepository accordingly (though the ExecutionEngine might already have logged fills, the PortfolioEngine might update positions in DB)[110][111].
  •    FR-PORT-3: The PortfolioEngine shall enforce portfolio-level constraints that complement per-trade risk checks[27]. Examples:
  •    Turnover Limit: If strategy is churning too much (e.g., number of trades per day beyond threshold), portfolio logic could decide to slow down further trades (or raise a flag).
  •    Cash Reserve: Maintain a minimum cash reserve (don’t invest 100% of cash; always keep e.g., 5% cash for flexibility or fees). If a trade would use last dollar, maybe portfolio engine triggers a slight downsize or warns risk.
  •    Sector Caps: Ensure not more than X% of portfolio is in any given sector or asset category, across all positions (some of this overlaps with risk’s exposure limits, but risk might check per trade and immediate after, whereas portfolio engine could have a more holistic view if multiple small trades accumulate).
  •    Position Limits Combined: Risk ensures each trade is small enough; portfolio ensures aggregate positions remain within overall limits (like no more than 10 open positions at a time, or no more than 50% in any single position, etc.).
  If such a constraint is violated after a trade, PortfolioEngine might take action to correct it (like flag it to risk or generate opposite signals to rebalance out). However, in MVP likely these constraints are static and just reported if broken.
  •    FR-PORT-4: The PortfolioEngine should provide a function to rebalance the portfolio based on target allocations or updated strategy signals[27]. For instance, if the strategy has a desired allocation (like 50% stock A, 50% stock B), and due to price changes it drifts, the PortfolioEngine can compute necessary trades to rebalance to target. This likely involves an interface rebalance(target_allocations, constraints) that returns a list of new trade signals or orders to execute[27]. In Phase 1, such rebalancing might be manual or not frequently used, but the architecture expects that by full feature set, the PortfolioEngine (potentially in conjunction with PortfolioOptEngine outputs) can generate orders for rebalancing (or at least inform the user of needed adjustments).
  •    FR-PORT-5: The engine shall expose get_portfolio_state() API to other components, returning a snapshot of current positions, cash, etc.[27]. This is used by RiskEngine (to see current exposures) and by Orchestrator if needed (though orchestrator might keep a reference). It should be fast (just returning internal structure) and ideally threadsafe if multi-threading (but since we use asyncio single-thread, not a big issue).
  •    FR-PORT-6: Mark-to-Market Updates: The PortfolioEngine shall update the mark-to-market value of positions (unrealized P&L) whenever new market data comes in[112]. This implies subscribing to market data events as well (or being fed price updates via orchestrator). For each price tick or bar, update each open position’s last price and recalc unrealized profit. If any position breaches a stop-loss or take-profit threshold due to price move (and risk might not catch it if between trades), the PortfolioEngine could generate a signal to exit (like a stop order). Possibly that’s handled by RiskEngine or strategy itself, but portfolio engine is well-placed to do trailing stops or such, because it continuously tracks P&L. In MVP, might not implement auto stops, but design allows it (could integrate with Governance or risk that if P&L down 5%, kill-switch triggers).
  •    FR-PORT-7: Persistent State & Parity: The PortfolioEngine must ensure that the state in memory matches the persisted state in the database for critical fields. For example, after each trade, once it updates internal position, it should also call PositionRepository.upsert to update the DB record[110]. Similarly for cash (which might be stored in a system state table or as part of account record). On startup, it should load all positions and cash from DB (especially if continuing from previous run). This ties in with reconciliation if using live broker: after loading DB and syncing with broker, the engine might have to adjust DB if they differ (or just hold differences in memory but better to fix DB too).
  •    FR-PORT-8: Corporate Actions & Other Adjustments: Not likely in MVP, but a complete portfolio engine would handle stock splits, dividends, etc. In future, we assume data feed adjusts prices and such, but if a corporate action results in position changes (like a split doubling shares), the engine should adjust position records accordingly. Also consider FX if trading multi-currency (not in MVP). Just note: portfolio engine is the place to do these adjustments or at least ingest them from external notices.
  •    FR-PORT-9: Integration with Optimization Engine: When the PortfolioOptEngine provides an optimal allocation, the PortfolioEngine may take that and generate signals to move from current allocation to optimal (this is a planned workflow for later phases). So, PortfolioEngine might call PortfolioOptEngine.optimize() with scenario data and constraints to get recommended weights, then call its own rebalance() to craft trades to achieve those weights. The requirement is to have an integration point such that if an optimized target is available (e.g., daily from an overnight batch), the portfolio engine can act on it. In MVP, maybe manual: user can feed a target. But the structure (function calls and event flows) should anticipate this, aligning with the presence of PortfolioOptEngine in architecture.
  •    FR-PORT-10: Reporting to Analytics: PortfolioEngine should provide relevant data to AnalyticsEngine, like trade logs, daily position values, etc. It likely logs all changes in positions (maybe via the database or via events like a PositionUpdate event on the bus[113]). That event includes what changed: e.g., “sold 50 of X, position now 100 shares long”. The AnalyticsEngine could subscribe to those or query DB later. The requirement: ensure Analytics has needed data to compute metrics like turnover, holding period, etc., which come from portfolio activity. Since it’s easier to compute P&L if you know positions and fills, the portfolio engine either directly computes some metrics or at least ensures all raw data is accessible.
  •    FR-PORT-11: Multiple Portfolio Support (Future): The engine currently assumes one portfolio (one set of positions, one cash bucket). If in future the system trades multiple accounts or sub-portfolios, the portfolio engine would have to maintain multiple sets (maybe by an ID). While not needed in DB1, the code can be structured with that in mind (like positions could have an account_id, etc.). Not a requirement to implement now, but a design note to not completely preclude expansion.
  (Interfaces summary: PortfolioEngine.get_portfolio_state() -> PortfolioSnapshot (including positions list, cash, maybe timestamp). PortfolioEngine.rebalance(targets, constraints) -> List[OrderIntent] (or signals). Possibly internal: PortfolioEngine.update_from_execution(report: ExecutionReport) which doesn’t need to be public as it’s triggered by orchestrator or bus. And perhaps PortfolioEngine.sync_with_broker(broker_positions) for startup reconciliation. The Position data model (e.g., PositionRow in DB) fields given in API docs[114] include side, quantity, avg_cost, current_price, realized_pnl, unrealized_pnl, timestamps – the engine manages those values. So essentially it wraps those repository calls with in-memory state updates too.)
  3.2.7 AnalyticsEngine
  Role: Calculates performance metrics, risk metrics, and generates reports or dashboards. It may also utilize AI to produce narrative insights about strategy performance[91].
  •    FR-ANA-1: The AnalyticsEngine shall compute performance metrics of the trading strategy/portfolio over time[91]. This includes standard financial metrics such as:
  •    Cumulative returns and CAGR (Compound Annual Growth Rate)[91].
  •    Volatility of returns, Sharpe ratio (excess return / volatility)[91].
  •    Sortino ratio (focus on downside deviation), Max Drawdown (the largest peak-to-valley drop in equity)[91].
  •    Profit factor (sum of profits / sum of losses)[91], win rate, average win vs average loss.
  These metrics are typically computed on realized trades and equity curve. The engine will gather the needed data from the portfolio and trade logs (which might come via ExecutionReports and position updates) to calculate these. In backtest mode, it can compute these after the whole run; in live mode, it can update them incrementally (e.g., daily or after each trade for a running view).
  •    FR-ANA-2: The AnalyticsEngine shall analyze trade-level statistics[91]. For each completed trade (a round trip of buy then sell), compute metrics like: holding period, return per trade, maximum adverse excursion (worst loss during trade), etc. Summarize these across trades: e.g., distribution of trade returns, average win, average loss, longest win streak, longest loss streak. Some of these help understand strategy behavior. In Phase 1, number of trades might be small, but framework should be ready. This might involve maintaining a list of closed trades (the TradeRepository in DB collects round trips[115][116]). The engine can read from that or update it.
  •    FR-ANA-3: The engine should provide time-series outputs like an equity curve (portfolio value over time) and drawdown curve. This involves tracking the portfolio value at each significant time (e.g., daily close or after each trade). It might subscribe to portfolio value updates (via position updates + market data) to compute equity. It should store or output this so that one can plot or examine it. Possibly it can write to a file or just keep it in memory for on-demand queries.
  •    FR-ANA-4: The AnalyticsEngine shall generate reports that aggregate the above metrics. For MVP, this could be console output or saving to a CSV/JSON or simple text/markdown summary after a backtest. In more advanced usage, it could produce an HTML or PDF report with charts and tables. The requirement is to present the results of trading in a clear format. Possibly, since we have LLM integration, it can generate a summary text.
  •    FR-ANA-5: The engine is responsible for producing a natural language narrative of performance when needed[91]. This can be done by calling the Cortex LLM engine. For example, after computing metrics, AnalyticsEngine can form a prompt like: “Summarize the trading performance: we had X% return with Y drawdown, major events were..., etc.” and send it to Cortex.synthesize_research() or a similar method to get back a paragraph explanation[91]. This summary might include reasoning like “The strategy performed well, achieving a Sharpe of 1.5, with most gains in tech stocks and a max drawdown of 5%. The win rate was 60%, suggesting edge in the strategy...” and so on. The engine should include relevant data points in the prompt so that the LLM output is accurate (optionally verifying key numbers). The result is included in the report for a human-friendly explanation.
  •    FR-ANA-6: The AnalyticsEngine shall publish an AnalyticsReport event summarizing performance metrics to the StreamingBus for any subscribers (like a UI dashboard)[91]. This could be done at certain intervals or on demand (e.g., at end of backtest, or daily). The content might be a data structure with all computed metrics and possibly the narrative text. If a real-time dashboard is used, it might update from these events.
  •    FR-ANA-7: The engine should support incremental updates vs final computation. In live trading, it will run continuously and update metrics as new data comes. It likely will maintain a rolling calculation of metrics (which is doable for some like Sharpe, but others like drawdown require looking at entire history, though can update as we go). For backtest, it might do one big pass at end to compute final results, which is fine. Requirement is to handle both use cases gracefully. Possibly have two modes: incremental (subscribe to events and update continuously) and batch (compute after the fact from logs).
  •    FR-ANA-8: The AnalyticsEngine must ensure consistency of data sources: for example, it should rely on the same source of truth for trades (the Order/Trade repository) as the rest of the system, to avoid discrepancies. If PortfolioEngine corrects or adjusts something, analytics should incorporate that. So, often easiest is to query the DB or in-memory logs rather than maintain separate counts. But since we can subscribe to events, in-memory tracking is fine as long as all events are reliable.
  •    FR-ANA-9: If the system engages in multi-strategy or multi-asset trading, the AnalyticsEngine should be able to breakdown performance by strategy or asset. In MVP single strategy, not needed, but design such as labeling trades by strategy or symbol allows grouping metrics (like how did each symbol contribute to P&L?).
  •    FR-ANA-10: The engine might incorporate risk analytics too, such as calculating a portfolio Value-at-Risk or other risk measures periodically. This could be via a Monte Carlo simulation or historical simulation. Possibly it would interface with PortfolioOptEngine or a separate risk model. Not in MVP, but for completeness: e.g., daily VaR at 95% confidence. These risk metrics could be included in reports or used by Governance to adjust limits.
  •    FR-ANA-11: The engine should generate alerts or flags if performance deviates significantly from expectations. For example, if drawdown exceeds a threshold, it might notify Governance or send an alert (though kill-switch is separate). If volatility of returns doubled, maybe flag that. This ties into monitoring – some of it could be done externally, but analytics engine can have some thresholds configured.
  (Interfaces summary: Possibly a method AnalyticsEngine.analyze(results_dataset) -> Report as in architecture doc[91], which suggests feeding it a dataset of results (like trade list or time series) and it returns a report object. In continuous mode, it might not be invoked explicitly but triggered by events: e.g., on_trade(execution_report) updates internal stats. The engine might also have AnalyticsEngine.get_metrics() to output current metrics. The narrative generation likely uses Cortex and Helix calls internally. For now, an AnalyticsReport event could be a JSON with metrics numbers.)
  3.2.8 PortfolioOptEngine
  Role: Provides advanced portfolio optimization capabilities (mean-variance, mean-CVaR, etc.), usually using heavy computation (GPU) to determine optimal allocation of capital across assets[117].
  •    FR-OPT-1: The PortfolioOptEngine shall be capable of performing quantitative portfolio optimization on a set of assets with given return scenarios or forecasts[117]. Specifically, it should implement optimization models like:
  •    Mean-Variance Optimization (MVO): maximize expected return for a given variance target or minimize variance for a given return target (Markowitz efficient frontier).
  •    Mean-CVaR Optimization: similar but replacing variance with CVaR (Conditional Value-at-Risk) as the risk measure[117].
  The engine will accept inputs such as expected returns or scenarios for asset returns and a covariance matrix or scenarios, plus constraints, and produce an optimal weight allocation.
  •    FR-OPT-2: The engine must support generating return scenarios either from historical data or Monte Carlo simulation for use in optimization[117]. This means if not provided, it can internally bootstrap or simulate returns: e.g., sample past returns (possibly via a block bootstrap for preserving correlation) or use a multivariate normal simulation given means and covariance. The architecture notes historical bootstrap or Monte Carlo as features[117]. If scenario generation is separate, at least ensure it’s easy to feed scenarios into the optimizer.
  •    FR-OPT-3: The PortfolioOptEngine shall allow constraints in the optimization problem[117]. Typical constraints include: weights sum to 1 (fully invested portfolio), each weight between 0 and 1 (no shorting) or allow negative if short allowed but then possibly sum = 0 if net zero strategy. Also sector or asset constraints (like weight of tech <= 30%), cardinality constraints (no more than N assets selected, though that’s a non-convex constraint solved via heuristics typically), turnover constraints (if optimizing incrementally, limit how much change from current portfolio). The requirement is to incorporate at least linear constraints on weights easily (as parameters to the solver).
  •    FR-OPT-4: GPU Acceleration: The engine shall utilize NVIDIA’s cuOpt library (or similar GPU solvers) to solve the optimization problem, achieving significant speed-ups[117]. This implies formulating the problem in a way that cuOpt can handle (likely as a linear/quadratic programming problem). For mean-CVaR, that can be turned into LP or QP with additional variables. The requirement: if a compatible GPU is available, offload the heavy computation to it, expecting results much faster than CPU solvers especially for large scenarios (the NVIDIA AI blueprint cited 100-160x speedup)[118].
  •    FR-OPT-5: CPU Fallback: The engine must also support a CPU-based solution path if GPU is not present or if problem size is small enough that CPU is fine[117]. For example, use SciPy’s SLSQP solver or an open-source solver like CVXPY with an appropriate backend (ECOS, CBC, etc.) to solve the optimization problem. The fallback ensures functionality on machines without powerful GPUs, albeit slower. As per design, if use_gpu is false or GPU check fails, it toggles to CPU mode[45].
  •    FR-OPT-6: The engine interface is likely optimize(returns_data, constraints) -> OptResult where OptResult contains the optimal weights for each asset and associated metrics (like expected return, risk, maybe the efficient frontier if needed)[117]. The input returns_data could be a matrix of scenario returns or vectors of expected returns and covariances, depending on mode. Possibly, we may design it to accept both: if given scenario matrix, do CVaR optimization; if given mean & covariance, do mean-variance. Could differentiate by a parameter.
  •    FR-OPT-7: The solution output should include risk metrics of the optimal portfolio[117], e.g.: expected portfolio return, portfolio volatility, CVaR at specified level, and marginal contributions to risk if possible. It should also provide info to facilitate building an efficient frontier if we sweep trade-off parameters (though building a full frontier might be outside single call – maybe multiple calls).
  •    FR-OPT-8: Integration with PortfolioEngine: The engine doesn’t act autonomously; it’s typically triggered by a user or a periodic event (like a daily optimization job). When triggered, it should fetch necessary data: either call out to a data source for historical returns or get it from PortfolioEngine (maybe PortfolioEngine passes scenario data to it). After computing optimal weights, it can either present them (if in a research context) or produce signals to move current portfolio to those weights. Likely, it would publish an event or store the result that PortfolioEngine can use. The requirement is ensure output is in a form that can be easily consumed (like list of asset weights or target positions).
  •    FR-OPT-9: The engine should consider transaction costs if possible. Real-world optimization often includes costs (which could turn the problem into quadratic with linear term or piecewise linear – making it more complex). If not in MVP, it might be ignored (assume frictionless). But design wise, leaving an extension where cost per trade can be integrated is good. At least, it should not propose completely churning the portfolio if only slight differences, as that’s not practical – maybe an optional penalty on turnover can be included.
  •    FR-OPT-10: Robustness: The engine must handle problematic cases, e.g., if no feasible solution (due to conflicting constraints), it should return a clear error or the closest feasible. If input data has issues (like covariance not PSD for mean-variance), it should handle (maybe through regularization or adjusting). Ideally, the optimization runs are deterministic given inputs (solvers might have tolerance differences but that’s fine).
  •    FR-OPT-11: Performance & Resource Constraints: Running the optimization for many scenarios or assets is heavy. The engine should check resource availability: e.g., if trying to simulate 10k scenarios on a small GPU with not enough memory, either scale down scenario count or offload to CPU or external cloud resource. Possibly integrate a config threshold (like if N scenarios * M assets is too big, automatically pivot to a different approach or warn).
  •    FR-OPT-12: Possibly, integrate with the learning pipeline: if this optimization technique is part of strategy generation, the engine might be invoked by the LearningEngine after models update to figure out new allocations.
  •    FR-OPT-13: Provide optionally not just a single optimum but the entire efficient frontier or multiple trade-off solutions (like different risk aversion parameters) for analysis. For example, if a user wants to see how risk vs return trade-off looks. Not needed for actual trading operations, but useful for research. Perhaps out-of-scope for MVP but architecture should allow repeated calls with different targets to gather that if needed.
  (Interfaces summary: optimize(scenario_data, constraints) -> OptResult as above. Possibly separate functions for different modes, e.g., optimize_mean_variance(expected_returns, cov_matrix, constraints) vs optimize_mean_cvar(scenarios, constraints). But we can unify by detecting input types. The engine will likely use an internal object that sets up optimization problem and calls either cuOpt via their Python API or CPU solver via CVXPY or SciPy. It should wrap outputs in OptResult containing weights: dict[Asset, float], maybe objective_value, and some risk metrics.)
  3.2.9 GovernanceEngine
  Role: Enforces high-level policies (compliance, version control, audit logging) across the system[29]. It acts as a guardian that can allow/deny actions and keeps an immutable log of all important events for audit and compliance.
  •    FR-GOV-1: The GovernanceEngine shall provide a pre-flight policy check function preflight(context) -> GovernanceDecision[29] that can be invoked before any critical action. The context passed in will describe the action or event (e.g., “Signal generated: buy 100 AAPL” or “Order about to be sent to broker” or “New model version being applied”). The GovernanceEngine evaluates this against a set of governance rules/policies and returns a decision: allow (possibly with modifications), or deny (with reasons)[29]. For example, a policy might be “do not trade asset XYZ because it’s on a restricted list” – then if context shows symbol=XYZ, it would deny. Or “if trade volume > $1M, require certain conditions” – could modify or flag. Governance decisions are deterministic given the policy set and context.
  •    FR-GOV-2: The engine shall implement audit logging via an audit(event) function that records an immutable log entry for every critical event that occurred[29]. This log entry should include details like timestamp, type of event, the actor (which engine or component triggered it), the decision or outcome, and references to any policies involved[29]. The log is ideally written to a append-only store (like a file or database table) with one entry per line (e.g., JSON lines). For MVP, a simple log file or DB table is fine. The key is that it cannot be retroactively altered without detection (so maybe no one has rights to edit it except append). If possible, including a cryptographic hash chain linking entries could further ensure immutability (that might be overkill for now, but possibly mentioned as a compliance idea).
  •    FR-GOV-3: The GovernanceEngine shall maintain a set of policies that it checks. These policies can be of various categories:
  •    Trading Policies: e.g., restricted assets (don’t trade sanction-listed stocks), max order size (which risk also covers, but governance might have a different threshold or an absolute cap to comply with regs like “if > $X, require manual approval” – which we may simulate by just not allowing, since no manual interface), trading hours (maybe risk covers, but governance could also enforce “no trading after 4pm” as a compliance rule to avoid market-on-close manipulation), etc.
  •    Model Governance: e.g., only allow certain model versions in production (ensuring that any AI model deployed was reviewed). If someone tries to use an unapproved model ID, governance denies.
  •    Prompt and AI usage Policies: e.g., if CodeGenService proposes a change that includes copying GPL code, governance filters should detect licensing issues and deny applying such changes[34]. Or content safety: ensure no LLM output with disallowed content (the Helix might do some filtering and governance might double-check if needed).
  •    Record-keeping Policies: ensure certain events happen (like config snapshot saved each run, etc.) – governance might not directly enforce but at least log if not.
  The engine should be able to load these policies from config (like a ruleset, possibly even a DSL or just code). Possibly for MVP it’s hardcoded code checks, but design aim can be to externalize them eventually.
  •    FR-GOV-4: Real-time Alerts on Violations: If a governance policy is violated (meaning an action was attempted that is not allowed), besides denying the action and logging it, the GovernanceEngine shall raise an alert[29]. This likely integrates with the Alerting system to notify operators that something was blocked. Example: “Order for restricted stock XYZ was blocked by governance policy.” This ensures visibility into compliance events. If multiple violations occur rapidly, governance might escalate by triggering kill-switch or such if the nature is severe (just hypothetical extension).
  •    FR-GOV-5: Versioning of Policies and Models: The engine must track version numbers for important things: e.g., each policy set might have a version identifier (so that the audit log can say “checked against TradingPolicy v2.3”). Similarly, if the system uses ML models, those model IDs and versions should be logged whenever they influence decisions[29] (for instance, if an LLM suggested something, note model name in log). The GovernanceEngine might enforce that only specific model IDs are allowed (like Nemotron-49B v1.5 and 8B v3.1 are allowed; if config tries to use something else, block it)[12].
  •    FR-GOV-6: Change Management: If any critical configuration changes (like risk limits, strategy parameters, code updates via CodeGen), GovernanceEngine should require or perform certain actions: e.g., log the change, maybe require a confirmation or a test pass. Since we likely automate everything, an approach is: the LearningEngine or CodeGenService might call Governance to say “hey I have a new model or code patch with these details”, and Governance decides if it can be applied in production or just in shadow (like allow in shadow mode only). But for MVP, such flows might not be fully active, so at least log them. Possibly integration with ADR (architecture decision record) concept – out of scope for code, but logically related.
  •    FR-GOV-7: The GovernanceEngine shall intercept requests for AI actions that could be unsafe. For example, if CodeGenService proposes a change that includes adding a plaintext secret (like an API key) to code, governance filter should catch that (maybe scanning diff for patterns) and reject it[34]. Or if an LLM attempt to execute a tool not allowed, etc. Similarly, if a user query in an AI engine might lead to revealing sensitive data, governance can block that response (some overlap with Helix’s safety filter, but governance is the overarching controller). Essentially, any cross-cutting concerns around security or compliance are enforced here.
  •    FR-GOV-8: Audit Trail Content: Each audit entry should contain: timestamp, a unique event ID, event type (SignalIssued, OrderPlaced, OrderBlocked, etc.), actor (which engine or user), details (like for an order: symbol, qty, price; for model change: old vs new model ID; etc.), decision (allowed/denied/modified), and policy references (IDs of any policies that were triggered)[29]. For allowed events, policy might be “complies with all policies vX.Y”; for denied, specify which rule. The logs should be easily readable (perhaps JSON format for structure) for future analysis or feeding to a compliance system.
  •    FR-GOV-9: The GovernanceEngine should support retrieving or querying the audit log by authorized personnel or processes. This might be as simple as reading the log file or as advanced as providing a function or interface to fetch logs in a time range or filter by type. Not strictly needed in automated setting, but for later manual audit. Perhaps an offline tool can read the JSON lines.
  •    FR-GOV-10: Authentication & Authorization (AuthN/Z): In future when multiple users or remote control is possible, GovernanceEngine would ensure only authorized actions are taken by authenticated identities. For MVP, since it’s single-user and automated, this is not fully needed. But if, for instance, some admin command comes (like an override to kill-switch), governance should verify it’s from an authorized source. If we integrate with a UI or CLI with users, governance might maintain user roles. This is planned under security considerations but ties in here: e.g., “only admin can adjust risk limits mid-run” – if a request to change a limit comes, governance checks user role. We'll note it for completeness though we have no multi-user UI yet.
  •    FR-GOV-11: Regulatory Compliance Checks: There are specific regulatory rules we might consider: e.g., US SEC Market Access Rule 15c3-5 requires broker dealers to have risk checks for orders; our risk engine covers many, but governance could represent the oversight function ensuring those are in place and log that they were applied for each order. If we were a broker, governance would ensure no user trades bypass these. Another: MiFID II requires logging all algo strategy changes – governance is doing that via audit logs of model changes. Also requires kill-switch – we have it. Possibly mention: if expanding to EU markets, governance ensures a record of any strategy parameter changes and associated rationale is kept (which our LLM narrative plus logs might serve)[38]. So essentially governance is designed to meet these compliance needs even if indirectly. So a requirement: "All controls and events required by regulatory guidelines (like kill-switch activation, strategy change, etc.) shall be logged by GovernanceEngine for future inspection”[38].
  •    FR-GOV-12: Transparency and Explainability: If an AI model is used in generating a strategy or trade, governance should capture an explanation or confirmation. E.g., if an LLM suggested a strategy change, governance could require an explanation (maybe provided by Cortex as a summary) to be logged so that later one can see the rationale behind changes. This ensures no black-box update goes unexamined.
  (Interfaces summary: Two main ones: GovernanceEngine.preflight(context) -> (bool allow, optional modifications)[29], and GovernanceEngine.audit(event) -> None[29]. Possibly also methods to load policies, and maybe an internal method like enforce_policies(context) that applies each rule. The context can be any object; likely we define context types like TradeContext, ModelContext, etc., with relevant fields. For modifications: e.g., governance might allow an action but tweak a parameter (maybe reduce an order quantity if needed; though that’s often risk domain, but could be governance if e.g. “allowed but only if you reduce frequency by half”). Implementation might be simpler just allow/deny in Phase 1. The audit can simply append to a file or call a DB writer.)
  3.2.10 LearningEngine
  Role: Continuously learns from collected data/events to improve models and strategies. It records events from all parts of the system, triggers model retraining, evaluates new models, and safely deploys improvements[119].
  •    FR-LEARN-1: The LearningEngine shall collect data from the running system by recording events through a function record_event(event)[119]. It subscribes to all relevant event streams (signals, trades, analytics, etc.) or is called by orchestrator after each cycle, in order to build a dataset of outcomes. For example, every time a signal is generated and later the actual result of trade is known, it has (state, signal -> outcome) pair to learn from. It may also ingest new market data that comes in labelled with whether the strategy would have done differently. Essentially, it populates a knowledge base for learning: e.g., adding to a training dataset for the SignalEngine’s predictive model or logging differences between expected and actual performance.
  •    FR-LEARN-2: The engine shall support retraining of models based on the recorded data[119]. This could include the predictive model in SignalEngine (like retraining an XGBoost on more recent data or fine-tuning an LSTM), or the LLM prompts in Cortex (like adjusting prompt templates based on user feedback). The LearningEngine should orchestrate this process, likely offline or in a separate thread to not slow live trading. For example, at end of day or when enough new data has accumulated, it triggers a training job. The training could be done using frameworks like scikit-learn, PyTorch, etc., depending on model. If GPU is needed, it might schedule it for an off-hours time. The requirement is that the pipeline for updating models is integrated – not just manual.
  •    FR-LEARN-3: The engine shall also update the Synapse knowledge index over time[119]. If new internal documentation is created (like new strategy runbooks or decision logs), LearningEngine can feed that to Synapse to re-index. Similarly, if new code is added, Synapse's index of the codebase should be updated. Perhaps not on every commit in MVP, but conceptually, LearningEngine can call Synapse.index(document) for new docs. Additionally, if the code knowledge base includes Q&A, maybe update it.
  •    FR-LEARN-4: The LearningEngine shall maintain a benchmark test suite for any new model or strategy changes, and run it to evaluate performance before fully deploying a change[119]. For example, if a new Signal model is trained, the engine runs it on a historical period (backtest) or a reserved validation set and computes metrics (Sharpe, etc.) and compares to old model. Only if metrics are as good or better (and no new risk issues) would it propose promotion. This is like continuous integration testing but for models. The requirement is to avoid blindly deploying a worse model. The architecture says "Runs benchmark suite before promotion"[119] indicating exactly that.
  •    FR-LEARN-5: The engine shall support a controlled rollout of new models using approaches like shadow mode or gradual ramp-up[119]. In practice, this means when a new model is ready, it could first run in parallel in shadow mode (it generates signals but those are not executed, just logged) to see how it would have done in live conditions vs the active model. The LearningEngine would compare results. If it shows improvement and no issues, then maybe switch a portion of live trades to it (gradual ramp, say 10% of trades use new model signals, rest use old, or alternate days). Over time increase to 100% if all goes well. This reduces risk of a bad model harming the portfolio. The requirement implies the infrastructure to run two models concurrently and tag which signals came from which (so we can track their performance separately). This is complex but at least documenting that approach. Possibly Phase 2/3 feature but listed in architecture so mention it.
  •    FR-LEARN-6: Integration with CodeGenService: If CodeGenService proposes code changes (like a new strategy code or a bug fix), LearningEngine should treat that as an "improvement" candidate and run tests on it. For instance, if CodeGen offers a patch to SignalEngine logic, then LearningEngine would run backtests with that patch in a sandbox environment (maybe using ProofBench) to ensure it doesn’t break things and improves metrics. Only after passing tests would it allow the patch to be merged/applied (which could tie back to Governance for approval). So requirement: any AI-generated code is validated by testing pipeline. MVP may not have automatic patch applying, but if we did, this gate is needed.
  •    FR-LEARN-7: Continual Knowledge Base Improvement: Over time, the LearningEngine should incorporate external new knowledge: e.g., new research papers or market regime changes. Possibly beyond MVP scope, but it could monitor sources for new information (like if connected to an RSS feed of relevant papers, and update Synapse or prompt templates accordingly). Another angle: it fine-tunes the LLM (Cortex’s underlying model) with data specific to our domain to improve its code suggestions or explanations. Actually, architecture mentions "fine-tunes LLM prompts" which suggests adjusting the prompt templates or maybe fine-tuning a smaller model for specific tasks as more data arrives[119]. The requirement is that LearningEngine not only updates the predictive trade model but also the AI assistance as needed.
  •    FR-LEARN-8: The engine shall log all learning activities. For example: when it triggers a retraining, log the dataset size, features used, hyperparameters, and resulting model version hash. When it runs benchmark, log the results. When it promotes a model, log old vs new details. This is crucial for traceability (so you know later why a model was changed and that it passed tests) – likely these logs go to GovernanceEngine as well or at least in an internal log.
  •    FR-LEARN-9: If the LearningEngine finds a serious issue (like model performance drastically dropping or a bug in logic), it could potentially trigger mitigations: e.g., instruct Governance or Risk to be extra cautious or pause trading. This might be advanced, but consider scenario: model started failing on new regime, performance is very bad relative to benchmark, maybe raise an alert or cut position sizes automatically until a fix is found. While risk control would eventually catch P&L dropping, a proactive measure by learning engine is interesting. Possibly outside MVP, but conceptually within "learning and adapting".
  •    FR-LEARN-10: Resource Management: Model training can be resource intensive (especially on GPU). The LearningEngine should schedule such tasks at appropriate times or when resources free. For instance, if using the same GPU that Helix uses for inference, maybe not train at trading peak times to avoid conflict (or use lower priority). Possibly integrated with CI jobs or separate servers for heavy training (the architecture suggests “CI jobs” for learning in production vs local trainer in dev)[120]. The requirement is ensure training processes don’t interfere with live trading tasks (like cause latency spikes).
  •    FR-LEARN-11: In MVP, the LearningEngine might not be fully autonomous. It could run in a “report-only” mode where it suggests improvements and a human then approves applying them. However, as per documentation, they did not defer integrating AI components, implying these engines (Cortex, CodeGen, etc.) are being used from Phase 2 for development acceleration[12]. So perhaps the LearningEngine is partly manual at first (developers see its analysis and then manually retrain model, etc.). Over time, more automation is added. This path is fine; requirement wise, ensure that at least the hooks are there to capture outcomes and feed them to improvement processes (even if actual retraining is triggered manually via a script that uses data collected by LearningEngine).
  (Interfaces summary: key ones: LearningEngine.record_event(event) to ingest any event[119]. Possibly LearningEngine.train(models=...) to trigger training certain models (as architecture lists record_event, train, evaluate functions)[119]. LearningEngine.evaluate(new_model, benchmark) to test a new model’s performance[119]. Also it might have config or schedule (like an internal timer daily to do train). The actual implementation might call out to model-specific training functions (like a script or library). Because orchestrating a training pipeline might involve preparing data, calling SKLearn or PyTorch and saving model artifact, then testing. Could use external frameworks or custom code. For MVP, maybe it's simpler, but the blueprint indicates hooking up with NVIDIA’s model distillation blueprint which is heavy[121], but likely beyond MVP scope. We’ll focus on conceptual.)
  3.2.11 Cortex (LLM Engine)
  Role: Provides language model reasoning and assistance capabilities, such as code analysis and research summarization for the development team[31]. It leverages LLM(s) via Helix to output helpful insights.
  •    FR-CTX-1: The Cortex engine shall allow analysis of code through a function like analyze_code(code_snippet, analysis_type) -> AnalysisReport[31]. This can be used to review strategy code or system code and identify potential issues, complexity, or improvements. For example, if analysis_type = “security”, it might check the code for vulnerabilities or secrets (with the help of the LLM), or if type = “refactor”, ask the LLM for suggestions to simplify the code. The output (AnalysisReport) should be structured, e.g., listing found issues and suggestions[31]. This helps developers maintain high code quality.
  •    FR-CTX-2: Cortex shall also offer a synthesize_research(query, sources) -> Summary function[31]. This takes a natural language query (like “What are effective methods for volatility forecasting?” or “Summarize how the kill-switch is implemented in our system”) and uses the LLM to generate an answer, with citations to sources. It likely uses Synapse to retrieve relevant snippets from the documentation or code (if sources parameter is provided or known) to ground the answer[31]. The output should contain a coherent summary and references to documents (like linking to lines in architecture docs) – essentially the LLM does retrieval-augmented generation. This helps the team get quick answers from the knowledge base.
  •    FR-CTX-3: The Cortex engine’s operations (like analyze_code or synthesize_research) should go through the Helix service to generate the LLM response[31]. It should formulate a prompt instructing the LLM what to do: e.g., “You are an expert code reviewer. Review the following code for complexity and issues: <code>...” and then call Helix.generate with that prompt to get a response. Then it may parse the response if needed to structure it. If multiple tasks are needed (like retrieve context first, feed with query), it coordinates those by calling Synapse then Helix.
  •    FR-CTX-4: Cortex must ensure it does not directly feed untrusted or sensitive data to an external model without oversight (if Helix uses external). In Phase 2, the design is such that models are internal (Nemotron on local GPU), but if fallback uses external API, maybe restrict what is sent (e.g., maybe not sending proprietary code to a third-party API unless allowed by user config). Governance can enforce this too, but here mention caution. Possibly allow developer to mark something “don’t share” and then code or doc with secrets isn't embedded or goes to LLM.
  •    FR-CTX-5: Advisory Role: The Cortex engine is explicitly not in the live trading loop (does not drive trading decisions)[31]. Requirements wise, ensure any suggestion it gives that could affect the system (like “you should really change risk limit to X”) is treated as a suggestion for human or goes through the proper development/test workflow. It should not, for example, spontaneously generate trade signals or call ExecutionEngine. This is enforced by design; just state that it is sandboxed to analysis tasks.
  •    FR-CTX-6: Logging and traceability: All queries to Cortex and their responses should be logged, especially if they're used to make any decisions. If developer uses it to generate code, that code later goes into system, we want trace that “This code was AI-suggested at <time> using model <id>”. So, saving the prompt and response (maybe sanitized) in a log or attaching to commit messages helps accountability. At least keep ephemeral logs during dev for reference.
  •    FR-CTX-7: Performance: LLM calls can be slow (especially a 49B model on not-high-end GPU or if using smaller one on CPU). So, consider that analysis tasks are not time-critical. But if used interactively by dev, we want say code analysis to return in a reasonable time (a few seconds to maybe 1-2 minutes for large code). The requirement is to optimize prompt and context so that it's not too large (embedding entire codebase isn't feasible; likely it will retrieve relevant parts via Synapse). If a request is too broad (like “analyze entire project”), maybe break it or refuse with suggestion to narrow scope.
  •    FR-CTX-8: Provide different modes or personas for analysis. Perhaps analysis_type values: “security audit”, “performance review”, “style compliance”, etc., each might have a slightly different prompt style. Or for research: differentiate between summarizing internal docs vs external research. The engine should handle these via either parameter or separate functions if needed.
  •    FR-CTX-9: Use of fallback models: If a big model (49B) is too slow or not available (say memory constraints), Helix might pick the 8B model. The Cortex should be aware that smaller model may give less accurate answers, so maybe if using fallback, could more heavily rely on retrieved facts (ensuring to not hallucinate as much). It's more like an implementation detail: perhaps send more context or phrase queries differently if using smaller model. But at least test both and ensure output quality is acceptable or warn user if the answer might be lower confidence.
  •    FR-CTX-10: The engine should allow developers to refine or iterate queries. For example, if a summary is too high level, user can ask a follow-up through the system (some interactive conversation memory might be beneficial). However, maintaining conversation state might be out-of-scope initially (we can treat each query separately). But potentially, a short-term memory if multiple related queries in one session (like a chat interface) could be an extended feature.
  •    FR-CTX-11: If the LLM yields an answer with citations (like "source[122]"), ensure that the reference is valid and accessible (like it should map to actual doc lines). This means the pipeline combining Synapse’s retrieved snippet and Helix’s answer must format references clearly. Might need to enforce that LLM includes them or insert them after via some matching. In MVP, maybe simpler: might paste the snippet with link and LLM can paraphrase around it. As long as final output has them.
  •    FR-CTX-12: If multiple tasks simultaneously call Cortex (like two devs or processes), Helix can handle multi calls but if local model, likely one at a time. So maybe queue or restrict usage. Not an immediate issue with single user, but good to note concurrency management - Helix might queue internally based on requests.
  (Interfaces summary: Already given as analyze_code and synthesize_research in architecture[31]. Each returns something presumably text or structured. The actual usage: a developer might call them via a CLI or REPL interface or maybe triggered by some events (like daily run of code analysis? Possibly not, mostly on demand). So these could be invoked manually by developer or integrated in dev workflows (like pre-commit hook runs analyze_code on changed files to catch issues automatically).
  3.2.12 Synapse (Retrieval Engine)
  Role: Acts as a retrieval engine that indexes various knowledge sources (docs, code, data) and provides relevant snippets for queries by AI engines or users[31]. Essentially the vector store and search component for RAG.
  •    FR-SYN-1: The Synapse engine shall ingest and index documents and data sources relevant to the project[31]. This includes: system documentation (design docs, runbooks), internal knowledge base articles, code files, configuration files, possibly historical trade logs or research notes, and external research papers if provided. On initialization or when triggered, it will process these documents by generating embeddings using an embedding model and storing them in a vector index (FAISS or ElasticSearch with vector support)[31]. Each document snippet (could break large docs into chunks of a few paragraphs) is associated with its embedding vector and metadata (like source name, section, line numbers)[31].
  •    FR-SYN-2: Synapse shall maintain an efficient vector search capability. Upon receiving a query (and optional context, e.g., "type: code" or similar), it will embed the query using the same or compatible embedding model and perform a similarity search in the vector index[31]. It should retrieve the top-K most relevant snippets (where K can be configured or requested) along with their metadata. The search should be fast (sub-second for typical sizes) and return results with a similarity score or rank.
  •    FR-SYN-3: The retrieve(query, context) -> List[Snippet] method must return not just the raw snippet content but also metadata needed to cite or locate it[31]. For example, the file name or document title, and maybe a pointer like line number or section that can be used to reference it (like the citations format uses [doc†Lx-Ly]). This allows the Cortex or other engines to include citations. Also include the similarity score or confidence if needed to filter out borderline irrelevant hits.
  •    FR-SYN-4: Synapse should allow filtering by context or source type if provided[31]. For instance, if the query is specifically for code context, it might restrict search to code embeddings (one could even use separate indices per domain for efficiency). The architecture hint is that it indexes various sources (docs, code, runbooks, research) – those could be tagged. So the context parameter could be a tag or type to filter (e.g., context="code" uses code index). Implementation: maybe it has multiple indices or a single combined with tags. But requirement is support domain-specific queries when needed.
  •    FR-SYN-5: Index updating: The engine should provide the ability to update its index when source documents change. Ideally, if a doc file is edited or new one added, Synapse can either auto-detect changes (perhaps by timestamp) or be told (like via LearningEngine or a manual trigger) to re-index that file. When re-indexing, it should remove or update old entries for that document to avoid duplicates/outdated info. Possibly it can run a periodic refresh (like re-index all sources daily) to catch changes.
  •    FR-SYN-6: The embedding model used should be appropriate to content: e.g., for code, a code-specific embedding model might yield better results; for general text, a general model is fine. The architecture mentions using a "dedicated embedding model" and storing vectors in FAISS or ElasticSearch[31]. Possibly, they might use a model like "EmbedLM-300M" for text[123] and maybe a separate for code (there's mention of "nv-embedcode-7b for code" in blueprint doc snippet[124] where code embeddings fallback to API). The requirement: Synapse should ideally handle both code and text with suitable models. If only one model is available in MVP (maybe a smaller text model), that’s fine, but design is to allow multiple. If two separate models, might have two indexes.
  •    FR-SYN-7: The engine will integrate with Helix (since Helix will be the one providing the embedding model too). Possibly Helix has a generate for text and could also have an embed function or model route. But architecture specifically calls Synapse out for embedding usage, likely meaning Synapse might use a smaller local model for embedding (like 300M param one that fits on GPU)[44], in order not to call a giant model for that. The blueprint hybrid plan suggests local embedding is feasible even on consumer GPU (like a 300M model fits in ~11GB)[125]. The requirement is that Synapse’s embedding model be loaded at startup and reused for queries and indexing, for efficiency. If it can’t run locally, it might use an API for embedding (like OpenAI embeddings), but prefer local if possible to keep data internal.
  •    FR-SYN-8: Quality of Results: The engine should chunk documents in a way that relevant info is captured but not too large to be irrelevant. For example, splitting by paragraphs or sections. Overlap chunks maybe to catch cross-boundary info. Also, store some text in metadata like document title for weighting (some vector search allow combining keyword and vector search, e.g., Elastic Hybrid search). Possibly out-of-scope for now (we can rely on pure vector). But ensure important pieces like code comments or headings are included to give context in snippet.
  •    FR-SYN-9: Provide an interface for manual query. Not just via Cortex; maybe developers can directly call Synapse (like a CLI or small UI) to search the knowledge base. This is more of a nice-to-have. The API is already there (retrieve), so one could integrate that easily. But emphasize that the knowledge base is accessible beyond just feeding the LLM; it’s a general support tool.
  •    FR-SYN-10: Security and Privacy: The content of the knowledge base might include sensitive info (like config with secrets if erroneously added, or internal strategies). The vector index potentially could be exploited to retrieve info by cleverly crafted queries (though within our system only devs and LLM we control have access). But if Helix uses an external model, we must ensure that retrieving doesn't send actual content to external, only query embeddings. Actually, in RAG, what happens is: we embed the query and find docs locally. Then we may feed the found text to the LLM to answer. That second part could leak info if the LLM is external. So one policy might be: only use fully internal LLM when using internal doc context, or ensure the external provider is trusted (like maybe using Azure OpenAI with our data if NDA, but complicated). Governance likely covers this, but Synapse should label content sensitivity. For MVP, assume local. But mention that Synapse should mark any content that should not be exposed externally and maybe skip it if external call would happen. (e.g., it might categorize which sources can be used with external LLM – code might not be allowed to go out, maybe only documentation is fine, etc., and then either restrict usage or require a user confirmation).
  (Interfaces summary: Synapse.index_all() possibly to build index (maybe run on startup or when triggered by LearningEngine or script). Synapse.retrieve(query, context=None) -> List[Snippet][31] is key. Possibly also Synapse.add_document(doc) and Synapse.remove_document(doc_id) if dynamic management needed. The data classes might be like Snippet with fields: text, source, line_start, line_end, etc. And an internal embedding function (like could call Helix or local model). Also config specifying which directories to index (like docs/, src/ for code excluding certain file types maybe). Perhaps also filter out extremely large files (like huge log files not meant to be in KB).)
  3.2.13 Helix (LLM Provider Layer)
  Role: A unified interface to generative models, handling model selection (large vs small), API calls, and general LLM management for the platform[33].
  •    FR-HEL-1: The Helix service shall expose a single primary method generate(messages, model_id=None, **options) -> text that other engines use to get LLM completions[33]. The input follows a messaging format (like an array of role+content for chat models, or a prompt string for raw completion). The caller can specify a model_id if a particular model is desired, otherwise Helix chooses a default appropriate model. It returns the generated text along with possibly metadata (like which model was used and token usage)[33]. This abstracts away whether the model is local or an external API.
  •    FR-HEL-2: Helix shall manage multiple model backends and decide which to use based on configuration and context[33]. The default scenario: we have a large model (Nemotron-49B) which is high-quality but slower/costly, and a smaller model (Nemotron-8B) which is faster/cheaper[33]. Helix should pick the 49B for tasks where quality is paramount and latency is less critical (like offline analysis), and the 8B for quick tasks or if running on limited hardware (like development mode)[126]. The selection criteria come from config (perhaps something like profile: "dev_small" vs "prod_large" as in config snippet[127], or a runtime flag). Helix should also have logic like: if model_id param is provided (like "nemotron-8b"), use that explicitly.
  •    FR-HEL-3: Helix shall handle authentication and API details if it uses external providers[33]. For instance, if Nemotron-49B is running on a cloud endpoint requiring an API key, or if fallback goes to OpenAI API, Helix stores the keys in its config (securely via env vars) and attaches them to requests. It should also handle retries if the API fails or rate-limit responses (perhaps exponential backoff or try a different model if one fails)[33]. The calling engines should not have to implement that logic; they just call Helix.
  •    FR-HEL-4: Helix should enforce some safety filtering on outputs and maybe inputs[33]. This could include checking the LLM output for disallowed content (e.g., harassment, privacy leaks) and either removing or warning. Possibly using an open-source content filter model or rules. Since these LLM uses are internal, the main worry might be accidental inclusion of secrets in code outputs or similar (which CodeGen’s governance also filters). But Helix being general, maybe have a moderate filter if needed. For now, just note: Helix "handles ... safety filtering" as per architecture[33], likely meaning it could incorporate either the provider's safety (like OpenAI’s moderation endpoint) or a custom one.
  •    FR-HEL-5: Helix shall track usage statistics for each request and accumulate them[33]. For example, count tokens used (prompt vs completion), time taken, etc. Many APIs return token counts; if local, Helix might have to compute length. Helix should then possibly log these or make them available (maybe an internal endpoint or metric that MonitoringEngine can scrape). This is important for cost tracking if using paid APIs or just understanding load.
  •    FR-HEL-6: Model Configuration: Helix must allow specifying which model to treat as “default large” and “default small” (like linking the names to actual model endpoints). According to model mapping table: Helix (generic) uses Nemotron-49B, Helix (lightweight) uses Nemotron-8B by default[4]. So in config, likely something like default_model_id = nemotron-super-49b-v1.5, fallback_model_id = nemotron-8b-v3.1[4]. Helix should ensure these are available (if local, check model files; if cloud, check connectivity). Possibly load the local model at startup to avoid load latency on first request. If not loaded, do so on first use but that can be slow. Ideally pre-load especially if using large model on GPU. The requirement: if environment allows, load the primary model into memory at service start (maybe concurrently to rest of system launching) so first call isn’t super slow.
  •    FR-HEL-7: Helix should implement fallback logic: If a request to the primary model fails (e.g., out of memory, model not responding), automatically try the fallback smaller model (or an external one if configured)[33]. It should log that this happened. Similarly, if the default is too slow and times out, maybe attempt a simpler response via small model. Blueprint mention: api_fallback and vram_threshold for automatic fallback when VRAM is insufficient[128], meaning Helix could detect GPU OOM and then route to an API. Helix config should have such toggles (like use_local=True, api_fallback=True etc.). If fallback is used, record that in output metadata so the calling engine knows quality might differ (maybe not needed to propagate, but definitely for logs).
  •    FR-HEL-8: Options passthrough: The generate call should accept extra options like temperature, max tokens, stop sequences, etc. The calling engine might specify these for different use-cases (e.g., CodeGen might want deterministic output with low temperature, research summary might allow more creativity). Helix can take those and apply them either to local generation or to API parameters. If some options are unsupported by a given model or API, Helix can ignore or approximate (document which it supports). Basic ones like temperature, max tokens likely supported widely.
  •    FR-HEL-9: Testing and Stub: Provide a mode for Helix that doesn't require actual model (for dev without GPU or API keys). Possibly a stub that returns a canned answer or uses a very small model. For instance, in dev config, Helix profile could be "dev_dummy" which maybe calls a local 8B (as dev uses smaller) or even a random small LLM. Or always returns "Lorem ipsum" to let system flow test. This ensures devs can run the pipeline without full model overhead if needed. In the development guide, Helix uses Nemotron-8B for dev to reduce resource usage[126], that covers this (they had smaller but real model presumably). But maybe an even lighter stub could be helpful.
  •    FR-HEL-10: Helix should be robust to misuse. If an engine passes a very large message or ill-formed structure, Helix should handle gracefully (maybe error out with message rather than crash). E.g., if someone accidentally tries to feed an entire huge log file to LLM via Helix, Helix could refuse or truncate input as per token limit. So maybe enforce a max prompt length or something, possibly configured per model. Usually model context length is known (like 2048 or 4096 tokens for many), Helix can count and trim or warn.
  •    FR-HEL-11: Over time, integration of new models: Helix should allow adding new model endpoints (like if a better model or domain-specific model becomes available). That could just mean updating config with a new model_id and accordingly Helix picks it for certain tasks. Or if auto selection grows to more than binary (maybe have 3 sizes: small, medium, large). The engine design should not be limited to exactly two, even if initial config is two. Possibly something like a mapping of profiles to model IDs. For now, two is fine.
  •    FR-HEL-12: Helix is an internal service; there is no direct user interface. But one might imagine a diagnostic interface to test it (like an API or CLI to send a prompt and get output for debugging). The requirement could be just to ensure logs and perhaps a debug mode (where it prints the full prompt and raw output for developers to see, useful when adjusting prompts, albeit this might show sensitive info from Synapse context in logs, so careful with that). Possibly only enable that in dev mode.
  (Interfaces summary: Helix.generate(messages, model_id=None, temperature=..., max_tokens=..., etc) -> {text, model_used, usage_stats}[33]. Possibly Helix.embed(text, model_id=None) if Synapse would call Helix to embed. But they might keep embedding in Synapse with a separate model instance, not via Helix. If Helix is meant to unify all model use, it could also handle embedding requests (maybe behind scenes it loads the embed model too). The architecture separated them (Synapse uses embedding model directly). Helix focusing on generation is fine. Also likely internal initializations in Helix for local models: e.g., Helix.load_model(model_id) if local. If multiple local models (49B & 8B) maybe loaded concurrently or sequentially depending on memory (some frameworks allow multiple on one GPU if it fits, else might run on CPU for small etc.). Could also spawn separate processes for each to not overload memory. For now, maybe assume one model loaded at a time (the dev chooses which via config). But fallback idea suggests might need both available. Possibly if on one GPU, maybe cannot hold both 49B and 8B simultaneously (49B likely uses entire GPU memory alone). So fallback might require unloading big model to load small, which is slow. Alternatively, have the small always loaded on CPU for backup. This is advanced to orchestrate; if we had multi-GPU or allow swapping. The blueprint suggested using API fallback for the large tasks to avoid local heavy load in a consumer GPU scenario[44]. But anyway, Helix should manage resources along with such config. It's an interplay with hardware constraints and is covered partly in constraints section.)
  3.2.14 CodeGenService
  Role: Provides AI-assisted code generation and refactoring suggestions, taking natural language requests and producing code patches or new code[34]. It uses Cortex/LLM plus context from Synapse to propose changes, which are filtered by governance.
  •    FR-CG-1: The CodeGenService shall accept a prompt describing a desired code change or feature (for example, “Implement a stop-loss check in RiskEngine” or “Refactor the PortfolioEngine update logic for clarity”) along with relevant code context (could be specific files or snippets), and produce a proposed code diff or patch as output[34]. The interface could be propose_change(description, files_context) -> CodeDiff. The CodeDiff might be in unified diff format or a structured object listing modified files and changes. This makes it easy for a developer to review and apply if acceptable.
  •    FR-CG-2: The service shall utilize the Cortex and Synapse engines internally to generate these code changes[34]. Specifically, it likely will do: retrieve relevant code from Synapse if not provided (like if the prompt says “add X feature”, CodeGen might search for where in code that feature should be added or similar code exists), then formulate a detailed instruction for the LLM (via Cortex/Helix) including the relevant code context and the change description. The LLM then outputs suggested new code. CodeGenService may need to do some post-processing: e.g., ensure it's properly formatted as a diff. It might even run tests (if specified by user or config) to verify the change doesn't break anything, as architecture suggests “optional test results” with the diff[34]. If we have an automated test suite, CodeGenService could run it after generating patch, then attach results (like all tests passed or these 2 tests failed) to help developer gauge quality.
  •    FR-CG-3: The CodeGen outputs must be filtered by GovernanceEngine to avoid introducing problematic code[34]. This includes scanning the diff for secrets (like a large blob of base64 which could be an API key, or code that goes out to the internet unexpectedly), licensing issues (like if the code looks copied from an open-source project with incompatible license), or unsafe functions (like disabling security checks). The GovernanceEngine likely has a set of regex or patterns and perhaps uses an LLM content filter to scan the diff. If a violation is found, CodeGenService should either redact those parts or reject the suggestion entirely. Possibly, it could attempt a second pass with a prompt to LLM “please avoid including X” to see if it can fix it. But initial requirement: do not output code that violates known policies (and at least clearly warn if partial issues).
  •    FR-CG-4: The service should produce code that adheres to the project’s style and structure as much as possible. If there are coding guidelines or consistent naming, the prompt or fine-tuning of the LLM should incorporate that (e.g., “Follow PEP8 style for Python” or “Use our logger instead of print”). Possibly, if a style guide doc is indexed in Synapse, it can retrieve and supply it. The goal is to minimize the manual adjustments a developer has to do for style.
  •    FR-CG-5: Scope control: CodeGenService should try to limit changes to the intended scope. For instance, if asked to implement something in RiskEngine, it shouldn’t propose unrelated changes in ExecutionEngine unless necessary. It should likely confine modifications to relevant files. If the user’s request is broad (“Improve performance”), maybe break it down or ask clarifying questions (depending on interactive capability). Possibly in MVP, assume clear tasks.
  •    FR-CG-6: There should be an audit trail of what CodeGenService is used for. E.g., log the input description and a summary of output or at least a hash of it, so that one can later tie a code change to the AI suggestion. In a multi-dev environment, this is important for accountability (like to know which changes were machine-suggested). It could even embed in commit message a note “Co-authored by AI CodeGenService at [timestamp]” or similar.
  •    FR-CG-7: This service presumably will be used offline (not automatically committing changes to production code without human review). So by design, it's a developer tool. It should present output in an easily reviewable format. Possibly integrate with git directly: maybe it could output a patch file that can be applied, or even open a PR (phase 3+ maybe tie into GitHub API to open a draft PR for review, which a dev then reviews and merges if okay). For MVP, just printing diff to screen or writing to file is fine.
  •    FR-CG-8: Testing integration: As mentioned, ideally CodeGenService can also run relevant tests on the proposed changes. It can detect which components touched (e.g., changed RiskEngine file, so run RiskEngine’s tests). It would require some test harness or knowledge of how to run tests (maybe via a command like pytest riskengine_tests.py). If successful, including “all tests passed” is a strong endorsement; if fails, either iterate (maybe ask LLM to fix failing test?) or at least tell developer tests failed. The architecture note “optional test results” implies at least capturing that info[34]. MVP might skip this due to complexity, but it’s a goal. Possibly integrate with CI – like CodeGen outputs diff, then a CI job runs tests and reports back to developer separately. If fully local, it can run if environment is set up.
  •    FR-CG-9: If the LLM output is too large or complex (like rewriting many files), the service should either break it down or caution the user. Large diffs are hard to review and likely to have issues. Perhaps set an internal threshold of lines changed and if exceeded, maybe indicate “This is a big change touching multiple parts, consider smaller steps.”
  •    FR-CG-10: Refinement: Possibly allow the developer to give feedback or further instructions to refine the diff. For example, the developer might say “looks good but change variable names to be clearer” or “the function doesn't cover X case, fix it”. CodeGenService could then incorporate that feedback and regenerate a refined diff. This implies maintaining context of what it already suggested (like original code and first diff) – maybe treat original code + diff as new context and prompt to modify accordingly. This starts to become like an interactive code assistant (like GitHub Copilot Chat or ChatGPT’s code mode). Might be beyond initial SRS need, but at least mention interactive refinement as a potential feature.
  (Interfaces summary: Provided as CodeGenService.propose_change(prompt, files_context) -> diff in architecture[34]. Possibly there’s also the ability to run tests, maybe hidden. The interplay: it uses Cortex’s LLM for reasoning and Synapse for context. Possibly multiple calls: one to figure out which files to open (maybe by searching codebase for keywords), then feed the relevant code into final prompt. It should use Helix for actual generation. So CodeGen is a coordinator of those pieces to deliver a final result.
  3.3 Non-Functional Requirements
  This section outlines the non-functional requirements – system performance targets, reliability, security, maintainability, etc. – that the Ordinis platform must meet. These are critical for ensuring the system’s quality and compliance.
  3.3.1 Performance Requirements
  •    NFR-P-1 (Latency): The system’s end-to-end trading pipeline (from receiving a market tick to publishing the resulting order) shall exhibit low latency. For the intended use-case (intraday/swing trading, not HFT), the target is under 200 milliseconds end-to-end for 99% of events[129]. This includes data ingestion, signal generation, risk check, execution order creation (but not waiting for broker execution). In Phase 1 on a single machine, measured pipeline latencies ~100–200ms are acceptable[129]. If in future components are distributed, network hops should still keep within this envelope by parallelizing where possible.
  •    NFR-P-2 (Throughput): The system shall handle an incoming market data rate of at least several hundred events per second without backlog, and scale to higher rates by adding resources if needed. Given that the strategy focus is not ultra high-frequency, a realistic scenario might be 50 ticks/sec (for a handful of assets or aggregated bars) which is trivial. But we set a requirement e.g., 100 events/sec sustained as a baseline target so that even on volatile days or if tracking many symbols, the system remains responsive. The StreamingBus and engines must support this throughput; our architecture choice (Kafka/Redis Streams if needed) can handle thousands/sec easily, and internal processing can be parallel if needed.
  •    NFR-P-3 (Execution Speed): The system’s overhead in order execution (after risk approval to sending to broker) should be minimal – target under 50ms. Actual end-to-end execution will depend on broker/API latency, but our system adds negligible delay. In simulation/backtest, the execution engine should process all orders for e.g., a full day’s backtest (thousands of orders) in minutes at most.
  •    NFR-P-4 (Analytics & Reporting Frequency): Generating analytics and reports (which may involve heavy computation like recalculating Sharpe) should not interfere with trading. Therefore, such tasks will be done either asynchronously or at low frequency (e.g., end of day). The system should be able to compute daily metrics and produce a report within a few seconds after market close. Backtest analytics on e.g., several years of data (tens of thousands of trades) should complete in under a minute. These are guidelines to ensure analysis is efficient for user feedback.
  •    NFR-P-5 (Scalability): The design is such that adding more assets or strategies primarily increases load linearly, and the system can scale by deploying additional engine instances or threads. For example, if running 5 strategies in parallel, one could run 5 sets of engines or partition the bus topics by strategy. The requirement: no hard bottlenecks in architecture that would prevent scaling to, say, 10x throughput with 10x resources. Specifically, the event bus and database should handle increased volume by scaling out (Kafka with more partitions, move from SQLite to distributed DB if needed in Phase 3). The current target scenario is relatively modest (single strategy, moderate data), but planning ensures we can grow to more intensive scenarios without redesign.
  3.3.2 Reliability, Availability, Maintainability
  •    NFR-R-1 (High Availability): The system shall be designed to be highly available during trading hours, targeting 99.9% uptime for critical components (which corresponds to ~8 hours downtime per year, though in practice we aim for zero downtime during market hours)[129]. In Phase 1, a single instance has no redundancy (if it crashes, trading stops). By Phase 3, as noted in the roadmap, we will introduce redundancy for critical components (e.g., backup broker connections, database replication, the ability to restart quickly or failover to a secondary system)[129]. The system shall support at least daily off-hours restarts (for deployment or maintenance) without issues by properly saving state, but during market hours it should not require restarts.
  •    NFR-R-2 (Fault Tolerance): The system shall handle faults gracefully. If a non-critical component fails (e.g., AnalyticsEngine crashes), it should not stop trading; the OrchestrationEngine and core loop continue, and an alert is raised to fix analytics later. If a core engine fails, the Orchestrator (or an external supervisor in production) should detect it and attempt restart or switch to a fallback (this is a Phase 3+ feature, e.g., processes monitored by a supervisor). The StreamingBus in Phase 2 with Kafka provides durability such that if an engine restarts, it could replay missed events from the log[41]. The requirement is that no single transient failure causes a cascade of failures: for example, if broker API times out (ExecutionEngine), the circuit breaker kicks in and system halts new trades but doesn’t crash; if RiskEngine throws an exception for a weird input, Orchestrator catches it and maybe rejects that trade but continues next tick. We will implement robust error handling around each engine call (e.g., try/except around generate_signals, evaluate, etc.) so that an exception is logged and contained, not bringing down the entire pipeline.
  •    NFR-R-3 (Data Integrity & Consistency): The system must maintain consistent state between components. After any sequence of events, the positions recorded by PortfolioEngine should match the sum of all executed trades (persisted in DB), the cash should match initial cash +/– trades ± P&L. We will implement consistency checks (e.g., a reconciliation at startup, periodic sanity checks during runtime possibly via Governance) to ensure no drift[130][131]. The use of a single source of truth (the SQLite/DB for orders, positions) helps maintain consistency. The requirement is effectively zero tolerance for silent data corruption: any inconsistency detected (like a position count negative or not matching sum of fills) should raise an alert for investigation.
  •    NFR-R-4 (Audit Trail & Traceability): As required by compliance, every decision and action in the system is traceable through logs or audit records[29]. This means the system must generate logs at appropriate levels: e.g., at INFO level for key events (signals produced, orders placed, governance decisions) and DEBUG level for more granular steps (like input values to RiskEngine, latencies). These logs should include unique identifiers (correlation IDs) to trace an event across components[23], like a market tick that resulted in signal ID 123 that became order ID 789, etc. We will use correlation IDs (perhaps the Orchestrator assigns an ID per cycle and includes it in events, or use Kafka message keys) to link logs across engines[23]. The audit trail in GovernanceEngine also ensures traceability by recording each critical action with context[29]. Maintainability of logs: they should be structured (JSON logs) to allow easy querying in ELK or similar systems by phase 3.
  •    NFR-R-5 (Maintainability & Modularity): The codebase and system architecture should be structured such that each engine is modular and can be updated or replaced with minimal impact on others[22]. For example, if we develop a new improved SignalEngine model, we should be able to plug it in without changing Risk or Execution. Clean interfaces (as specified in Functional requirements) ensure this. We also strive for code clarity and documentation: each engine’s logic will be documented (docstrings, maybe an internal wiki) and configuration managed centrally. Use of a configuration management system (Pydantic BaseSettings or similar) will help adjust parameters without code changes[132]. Additionally, comprehensive unit tests and integration tests for each engine are required (some testing strategy is planned in documentation). The requirement is that developers can maintain and extend the system efficiently: introducing a new data feed or engine should follow a clear pattern and not require months of refactoring.
  •    NFR-R-6 (Deployment & DevOps): The system shall be containerized (Docker) and deployable on both cloud and on-prem environments by Phase 2-3[36]. This means all components should run on Linux, and any environment-specific configuration is abstracted. Also, it should support CI/CD pipelines: automated tests run on each commit, and maybe automated deployment to a staging environment. While this is more process than system requirement, we include it because it ensures reliability of releases. For DB1, a simple Docker compose may run the main service + possibly a separate process for LLM if needed. The system should start up cleanly via one command and not require fragile manual steps.
  •    NFR-R-7 (Disaster Recovery): The system shall have provisions for disaster recovery. For Phase 1, this is primarily making sure backups of the SQLite database are taken (the Phase 1 implementation mentions automatic backup on each run)[133]. So if the server crashes, we can restore order/position data from backup file with minimal loss (perhaps losing at most the current day’s ephemeral data which can be reconciled from broker records). By Phase 3, using a more robust database with replication and scheduled offsite backups will be implemented[129]. The DR plan will also include infrastructure-as-code to recreate the environment in cloud if needed, and procedures for failover to a backup machine within e.g., 15 minutes if primary goes down. The requirement is that even in worst case (server failure), trading can be resumed (or at least positions safely managed manually) quickly, with no loss of critical data or compliance records.
  3.3.3 Security Requirements
  •    NFR-SEC-1 (Authentication & Authorization): All interfaces that allow control of the trading system shall be secured. In Phase 1, there's no public interface (only developers with code access), but as soon as any remote control or UI exists, it must require authentication (e.g., a web dashboard login). The system will integrate an authentication mechanism (like OAuth or at least basic auth for internal tools). Every action that can modify strategy or send orders must be authorized to specific roles. For example, viewing logs vs triggering kill-switch vs deploying a new model might have different permissions. The planning notes mention implementing auth and secrets management in future[134]. For now, this means things like CodeGenService or any console REPL have safeguards (maybe a confirmation prompt) to avoid accidental execution of dangerous commands.
  •    NFR-SEC-2 (Secrets Management): All sensitive information (API keys for broker/data, credentials, etc.) must be stored and handled securely[39]. They will never be hard-coded in code or logged in plaintext. We use environment variables or a configuration file that is encrypted or at least not committed to VCS. At runtime, secrets in memory are only passed to the modules that need them (e.g., Helix uses model API key, BrokerAdapter uses broker key). The repository does not contain actual secrets (we use placeholders in config examples). In cloud deployment, this would integrate with a secrets vault service. If we write these to disk (like a config file), it should be access-restricted and ideally encrypted at rest. Also, when passing to LLMs (like if someone wrote an API key in code and CodeGenService tries to show that code), GovernanceEngine/filters should redact it.
  •    NFR-SEC-3 (Encryption): Communication between components, if distributed (like Orchestrator to Kafka, or Helix to an external model API), should use encryption. For instance, if using Kafka on cloud, enable TLS for broker connections so that trading data (which might contain PII like account IDs or strategy logic which is sensitive IP) is not sniffable. Similarly, any remote API calls (broker, data, LLM) should be over HTTPS or equivalent secure channel[39]. Data at rest: database file or logs could be encrypted especially if on a laptop or in cloud storage, to prevent compromise in case of theft. Not yet implemented likely in Phase 1, but it's recommended (e.g., using disk encryption or encrypting sensitive fields like API keys even in DB).
  •    NFR-SEC-4 (Access Control to Models & Data): Only authorized code paths should be able to use certain AI models or trading functions. For example, perhaps usage of the large model Nemotron-49B is costly, so only certain events or user requests should call it (others default to 8B). Also, if multi-user scenario, a user might not be allowed to run CodeGen or see certain knowledge base docs if they contain secrets. We note these for future: an internal ACL system could tag resources and require a token. For now, it's single-user so not needed, but the architecture is mindful: e.g., the knowledge base might contain secrets; Synapse/Helix should not allow them to be exposed to someone without proper clearance (no multi-user now, but consider in design).
  •    NFR-SEC-5 (Operational Security & Audit): All administrative actions (like using the kill-switch, changing a risk limit, deploying new model) shall be logged (which we have via Governance audit)[135]. This is both for compliance and detecting misuse. If an unauthorized change occurred, we want to know immediately. Possibly implement alert on suspicious events (like if code is changed not via usual pipeline, or if kill-switch toggled off outside trading hours, etc.). This also helps forensic analysis if any incident happens.
  •    NFR-SEC-6 (Regulatory Compliance - Data): Ensure compliance with any data handling regulations. While trading data is not personal, if we had user data or PII (maybe in a multi-user scenario or if collecting personal trade logs), we would need to protect it per GDPR etc. Our logs and data currently only contain system and market data (no PII). So mainly ensure we handle any API usage terms properly: e.g., Alpha Vantage has rate limits and usage terms; we must not violate them (like using free API beyond allowed rates or redistributing data illegally). If storing market data, ensure license compliance (some providers forbid storing beyond X days without fee, etc.). We should mark any such constraints in documentation and abide by them (though e.g., Polygon/Alpaca allow use for personal trading).
  •    NFR-SEC-7 (Resilience to Attacks): Although this system is not exposed publicly, eventually if there's any connectivity (like if running on a cloud VM, or providing a web interface), it must be secure against common attacks. Kafka should be firewalled to only our processes, etc. If a UI is built, guard against injection attacks in forms (though likely internal only). Basic hygiene: use latest versions of dependencies to avoid known vulnerabilities; apply system updates timely; and isolate the trading environment from general internet (other than allowed APIs) as much as possible. For instance, if an LLM tries to call some external URL (some advanced LLM might if connected to tools), we should disallow that to prevent data exfiltration or unintended actions. Essentially, principle of least privilege in what each component can do.
  •    NFR-SEC-8 (Model Safety): The AI models should be used in a safe manner. This includes not only filtering outputs but also ensuring they cannot be tricked into breaking system rules. For example, if someone prompts CodeGenService with "write a function to disable the kill-switch", the LLM might comply. Governance should catch that and block it as an unsafe suggestion. Similarly, if an LLM is asked to produce content that violates compliance (like insider trading strategy?), it should refuse. These require careful prompt design and possibly content filters. We'll integrate known best practices (like an initial system prompt for LLMs with rules: "Don't produce disallowed code", etc.). This is an evolving area; we'll keep models updated (e.g., if a model version is found to output sensitive data from training, upgrade to a version with better alignment).
  3.3.4 Scalability and Resource Constraints
  •    NFR-SC-1 (GPU & Compute Resources): The system’s design explicitly acknowledges limited hardware and provides fallbacks. For example, running the Nemotron-49B model requires a top-tier GPU (A100/H100)[37], which we may not have in dev environment. The system uses Nemotron-8B as default in development mode to operate within smaller GPU/CPU limits[126]. It also can use remote resources if needed (as per hybrid blueprint, heavy tasks can go to cloud)[44]. The requirement is that all AI features degrade gracefully when resources are constrained: e.g., if GPU memory is insufficient for 49B, Helix automatically uses 8B or routes to an API without crashing[128]. If no GPU at all, perhaps all LLM queries go to an external API (with cost trade-off). Similarly, portfolio optimization: if no GPU, use CPU solver (which might be slower but fine for moderate asset count)[117].
  •    NFR-SC-2 (Memory and Storage): The system should operate within memory constraints of typical servers. E.g., if running all components on one machine with 64 GB RAM, even the largest model (49B) plus system overhead should fit (49B might use ~40GB vRAM and also system RAM). We assume a machine with at least 64GB RAM for full features; dev can work on 16GB (just using smaller models). Data storage: market data can accumulate; we must implement retention to avoid unbounded growth. Per the planning, we will keep only recent X months tick data in fast storage and archive older to disk or cloud[39]. The DB for trades and logs should not grow uncontrollably: logs will be rotated or archived after Y days (keeping maybe indefinitely but moved out of hot storage)[39]. So requirement: the system defines a data retention policy (e.g., keep last 6 months of minute-level data in DB, older purge to Parquet files; maintain trade logs indefinitely but possibly compress them). This ensures storage usage remains manageable.
  •    NFR-SC-3 (Cloud Deployment): The software must be deployable on cloud infrastructure (AWS, GCP, etc.) as well as on-prem. This means avoiding assumptions of local state that can’t be replicated. For instance, don’t rely on local filesystem for critical state (use DB or cloud storage). Use containerization and make sure we can connect to managed services if needed (e.g., if using AWS MSK Kafka or RDS Postgres in future). The code should allow configurable endpoints for things (so we can point to cloud Kafka vs local). Also consider network latency if splitting components: but likely we keep engines co-located for low latency. In cloud scenario, maybe all run in one region on a VM or in Kubernetes cluster. The requirement is essentially that nothing in code prevents running in cloud (like no GUI pop-ups, etc.), and the system can leverage scaling options provided by cloud (like if need to handle more throughput, one could increase instance size or number of instances for message bus, etc.).
  •    NFR-SC-4 (Parallelism and Multi-threading): The system should utilize concurrency appropriately. For instance, the StreamingBus in memory uses asyncio to handle events concurrently up to configured limit[83]. The LLM calls could be IO-bound (if calling an API) or heavy compute (if local GPU). We should ensure that while an LLM call is running, other tasks (like handling next tick maybe) can proceed if they are independent, so as not to block entire event loop. Possibly offload long compute (like training or big optimization) to background threads or separate processes so they don’t block the main loop. The requirement: ensure the main trading loop (Orchestrator and core engines) remains single-threaded (for determinism) but allow external heavy tasks to run outside it (via background jobs or executed after trading hours).
  •    NFR-SC-5 (Monitoring and Auto-Scaling): By Phase 3, incorporate monitoring of system load (CPU, memory, GPU usage, queue lengths)[23]. If we see, for example, that Kafka queues are building up or event processing is lagging behind realtime, that indicates the system might need scaling (vertical or horizontal). The system should be instrumented to expose such metrics (via Prometheus as planned)[23]. With that, an admin could manually scale up, or if we containerize, potentially an orchestrator (like Kubernetes HPA) could spawn more replicas of certain stateless components. For now, the architecture supports splitting engines, but Phase 1 won’t have dynamic scaling. The requirement is to pave the path: e.g., avoid state that can’t be replicated (like one instance only in memory). Use of Kafka in Phase 2 means we could run multiple consumer instances for parallel processing if needed. So design each engine with stateless processing of events in mind to facilitate that.
  •    NFR-SC-6 (Capacity Planning): Document the capacity of the system clearly so that we know when to add resources. For example, "with Nemotron-49B local, we require an NVIDIA A100 80GB, which can handle ~1 request per second at temperature 0.7 with response length 500 tokens" – such info should be known (maybe from testing). If a user tries to do more, either queue or degrade to smaller model. Similarly, "the backtesting engine can simulate ~100k trades per hour on a single CPU core" – if we want to test a million trades strategy, we may parallelize or move to GPU if possible. This planning doesn’t appear in UI, but as maintainers we ensure we keep these in mind.
  •    NFR-SC-7 (Backward Compatibility & Upgradability): As models and libs evolve (say a new version of Nemotron or a new major Kafka version), the system should be easy to upgrade. This means isolating version-specific code (like Helix being the adapter means if we switch to a different LLM provider, rest of system unaffected). It also means having data migration plans (if we upgrade database from SQLite to Postgres, have migration scripts for schema). Ensuring container images specify exact versions so deployments are reproducible, but also allowing bumping those in a controlled way. This is for long-term maintainability but ties to scaling in that as we upgrade to bigger, better tech, the system should accommodate.
  3.4 System Constraints
  This section enumerates specific constraints on the system’s design and operation, including those arising from technology choices, external requirements, and design decisions.
  •    SC-1: Model Version Constraints – The platform is currently standardized on two primary LLM models: Nemotron-49B v1.5 as the default large model, and Nemotron-8B v3.1 as the lightweight model[4]. All LLM-driven components (Cortex, Helix) shall use these model versions unless explicitly configured otherwise. This ensures consistency in AI behavior and facilitates validation – using unvetted models is not allowed without updating the spec. The system must be able to retrieve the exact model IDs (e.g., nemotron-super-49b-v1.5) and include them in audit logs for any AI-generated content[4]. If a model is updated (v1.6, etc.), that constitutes a planned change with testing. No automatic “latest model” usage should occur – versions are pinned to maintain reproducibility of advice and code generation.
  •    SC-2: Hardware & Environment Constraints – The system is designed under the assumption of access to at least one high-memory NVIDIA GPU for full functionality. Specifically, training or running the 49B model effectively requires an NVIDIA A100 80GB or similar (compute capability >= 8.0) with appropriate drivers and CUDA version[37]. If this is not available, the system will automatically restrict itself to smaller models and possibly offload heavy tasks to cloud as configured. The software must detect available GPU resources at startup (and possibly during runtime for fallback decisions)[136][128]. Additionally, the code is written for Linux; running on Windows is not tested (though dev use on Windows with WSL2 is acceptable). Containerization scripts assume a Linux base image with required CUDA drivers if using GPU. Another constraint: some components (FAISS, cuOpt) require specific CPU instructions (e.g., AVX) and OS libraries; the deployment environment must satisfy these (for Docker images, ensure base image has these libs). If deployed on on-prem servers, those servers must meet minimum specs (e.g., 32 CPU cores, 64GB RAM as per NVIDIA blueprint for full blueprint tasks)[37].
  •    SC-3: Data Retention Policies – The system shall adhere to the following retention rules for stored data, balancing compliance needs and storage constraints[137][39]:
  •    Trading Records (Orders, Fills, Positions): Retained indefinitely (or at least 7 years to satisfy financial regulations) in the database or archived storage. These records are relatively small in volume and are critical for audit (SEC and FINRA require order records retention)[38]. If the primary database is pruned, older records must be archived to a secure location (e.g., moved to a separate archive table or exported to files) before deletion. Current plan: since Phase 1 uses SQLite, we will not delete any trading records; if file grows large, we’ll offload older entries to a CSV or separate DB file with proper backups.
  •    Market Data History: Due to potential large volume, maintain at least 6 months of recent data (tick or minute level) readily accessible in the system’s storage for backtesting and analysis[39]. Older historical data will be archived to cheaper storage (e.g., compressed Parquet files on disk or cloud). The system may implement an archiver process that, for example, each month moves data older than 6 months from the fast database to an archive file. Archived data should remain accessible for manual backtesting or compliance queries, but not load into memory unless explicitly requested. This prevents the database from growing without bound.
  •    Logs and Telemetry: Detailed logs will be kept locally for a shorter period (say, 30 days) and then rotated[39]. However, because compliance may require logs of decisions, the immutable audit log (governance JSON-line log) is part of trading records retention and kept indefinitely. Other system logs (debug/trace logs) can be archived or discarded after 30 days unless needed for an investigation, to save space. We plan to integrate log rotation (e.g., compress and move older logs to an archive folder daily).
  •    These policies are designed to ensure the system does not run out of storage and that we comply with rules like MiFID II which require certain algorithmic trading data retention (some jurisdictions require storing order event data for 5+ years)[38]. A note: if expanding to EU, we might need to store strategy parameter changes and kill-switch events similarly long – which we do via audit logs.
  •    SC-4: LLM Fallback and Offline Strategies – The system is constrained to operate even in scenarios where the main AI model or internet access is unavailable. Specifically, if Nemotron-49B cannot be loaded or is too slow for a request, Helix will use Nemotron-8B automatically[33]. If neither local model is available (say, running on a CPU-only machine), Helix can be configured to call an external API (OpenAI or NVIDIA cloud) to process requests[43]. This fallback behavior is built-in: a configuration flag api_fallback=True will trigger Helix to attempt a cloud endpoint when local generation fails or is too resource-intensive[128]. Similarly, for Synapse (retrieval) – if the vector search fails (maybe index not built yet or engine down), as a crude fallback the system might do a simple keyword search in the documents as a backup (this is not currently implemented, but a conceptual fallback).
  •    Fallback must be transparent to the user of the engine (the engines will still get an answer, just maybe lower quality or slower) and logged (so we know when fallback occurred)[128]. The constraint is that at no point should the absence of the preferred AI model stop core trading operations. In worst case, if all AI engines are down, the trading system still runs with deterministic logic (signals might be more basic or not as optimal, but risk and execution continue). Therefore, the trading strategy should not critically depend on LLM output for live decisions. Indeed, by design, Cortex is advisory and not in the critical path[12].
  •    For PortfolioOptEngine, if the GPU solver (cuOpt) is not present, the CPU solver is invoked automatically[117]. The constraint here is that optimization might then take longer (seconds instead of milliseconds for large problems) so one might not run it as frequently. But the system will still produce a solution albeit slower.
  •    SC-5: Regulatory Constraints – The system must enforce certain specific constraints derived from financial regulations:
  •    No unapproved algorithms in live trading: Any strategy or model deployed must go through governance approval (we implement this by only using models defined in our configuration and by logging changes)[12]. We effectively disallow an AI from autonomously deploying new trading logic without human oversight (so LearningEngine cannot automatically push a new model live; it can shadow it and recommend).
  •    Kill-switch requirement: The system includes a kill-switch and circuit breaker by design, which is a direct response to regulatory expectations (e.g., SEC Rule 15c3-5 and EU MiFID II require controls to immediately disable algorithmic trading)[38]. The constraint is that this kill-switch must be easily accessible (for the operator) and reliably halt all trading actions when activated. For compliance, its activation/deactivation events are logged with timestamp and require manual reset[72]. Additionally, in live deployment, it might be required to have a physical or separate channel kill command (some firms require a separate system to send kill signals). For now, a software flag suffices since single-user.
  •    Audit trail immutability: As noted, regulatory bodies may audit our trading records and logs. Thus, the audit logs and order database are effectively write-once (append-only for logs, new orders/inserts for trades). There’s a constraint that we do not allow editing these records after the fact. In SQLite, we can ensure immutability by design (not deleting or updating audit lines; if using a stronger system, maybe store audit in a log system or append-only table). This is more a procedural constraint: if a correction is needed, we add a new audit entry stating a correction, rather than altering history.
  •    Time synchronization: For audit accuracy, all system components should use a synchronized clock (NTP) and log times in a consistent timezone (preferably UTC) with high resolution. Regulatory logs often require timestamps to the millisecond for event sequencing. Our constraint: all logs and audit entries are in UTC by default (or if local time, clearly labeled with offset).
  •    Compliance Mode: If required to run in a restricted environment (like a sandbox for regulatory testing), the system may need to operate with certain features off (e.g., no external data calls except what sandbox provides). The architecture must be flexible to such configuration. For instance, if regulators want to test the system, we should be able to feed it historical data from a file rather than calling Alpaca. We’ve allowed for that by designing the MarketData adapter to be interchangeable (as we have a mock CSV adapter in dev)[138]. So, the constraint is that all external dependencies can be stubbed for a self-contained run (makes testing and compliance checks easier).
  •    SC-6: Dependencies and Compatibility – The system is built on specific frameworks (e.g., Python 3.9+, TensorFlow/PyTorch for models, FAISS for vector store, cuOpt for optimization). It is constrained to those versions that are mutually compatible and tested. For instance, the NVIDIA cuOpt library might require a certain CUDA version and driver (as listed: CUDA 13.0+, drivers 580.65.06+)[37] – we must ensure the deployment environment meets this, else PortfolioOptEngine falls back. Similarly, using FAISS might tie us to a particular version of Python or GLIBC; using Pydantic might tie to Python >=3.7. We document these dependencies and require that the system be deployed on an environment that satisfies them. In case a dependency is not available, the system should not crash but disable that functionality with a warning. E.g., if cuOpt is not installed, PortfolioOptEngine could raise a config error or automatically switch to CPU solver (which we plan as fallback). This is essentially fault tolerance at feature level.
  •    We also ensure not to use any libraries that have license conflicts. Many libraries are MIT/BSD which is fine; if we were to use any GPL library, we’d need to open source our code which is not intended. We avoid such dependencies (for example, we use FAISS (BSD-licensed) not something GPL for vector search). This is a design constraint driven by wanting to keep the option of proprietary distribution.
  •    SC-7: Development Phase Alignment – This SRS covers engines planned for the full system, but not all engines are fully implemented in DB1 (MVP). Where an engine or feature is mentioned that is scheduled for Phase 2 or later (like StreamingBus with Kafka, full AI integration in trading loop, advanced portfolio optimization), it is included here for completeness and design alignment. The constraint is that Phase 1 (DB1) deliverables focus on core trading functionality (Signal, Risk, Execution, Portfolio, basic Governance, etc.) with placeholders for others. For example, in DB1:
  •    The StreamingBus is a simplified in-memory implementation (no distributed broker yet)[40].
  •    Cortex, Synapse, Helix, CodeGen exist in code but are used in a sandbox manner, not affecting live trades[2].
  •    PortfolioOptEngine may not be active at all in MVP (no continuous portfolio rebalancing yet), but its design is present for Phase 2.
  •    LearningEngine is partially implemented to log data but not auto-tuning models in Phase 1.
  The system must be explicitly configured in Phase 1 to reflect these: e.g., use in_memory bus, use_gpu=False (if no suitable GPU, which is likely in dev) so Helix chooses small model, etc. We align configuration with Phase goals to avoid unfulfilled dependencies. The MVP is thus constrained to a subset of full capabilities but with architecture ready to expand. This SRS serves as a foundation; any requirements that cannot be met in DB1 are not ignored but rather marked as “in design, to be fulfilled in Phase 2+”. We ensure this separation is clear in planning docs, so stakeholders know what to expect in the MVP vs later[12].
  •    SC-8: Use of AI from the Start – A planning directive is that we do not defer key AI components; they are integrated early (Phase 2) to accelerate development and strategy discovery[12]. The constraint that results is: even though AI engines (Cortex, CodeGen, etc.) are not mission-critical for trading, we still build and include them in the system design and code from early on. They must function sufficiently in development to aid building the rest of system. For example, CodeGenService might be used to generate some unit test code or stub modules (and indeed, might have been used to help write parts of this SRS!). Thus, their presence is a constraint on architecture – we run an LLM infrastructure alongside trading engines from the beginning, which means dealing with GPU allocation between trading vs LLM tasks, potential interference, etc. We mitigate this by profiling and using the fallback smaller models during development (so that AI usage doesn’t starve trading loop)[126]. Also, by decoupling them (they’re separate engines), we can disable them easily if needed for stability. The overall guidance is: AI is not an afterthought add-on but a core part of the platform’s vision, so all design decisions consider how AI components fit in. This influences, for instance, logging (including AI outputs in audit logs), config (profiles for AI usage), and testing (needing deterministic behavior or at least known behavior for LLM in test mode).
  3.5 Traceability Matrix
  The following matrix maps each requirement in this SRS to its source in the architecture or design (which component or design decision justifies it, or which external benchmark it addresses). This ensures each requirement is grounded in the system architecture or project goals and helps track fulfillment through development and testing.
  Requirement ID    Origin / Justification
  FR-OE-1 to FR-OE-6    OrchestrationEngine – Central coordinating component ensures sequence & context[5].

FR-SB-1 to FR-SB-8    StreamingBus – Event bus design for decoupling, schema validation, back-pressure[5].

FR-SIG-1 to FR-SIG-8    SignalEngine (SignalCore) – Strategy logic generating signals from data[25].

FR-RISK-1 to FR-RISK-8    RiskEngine (RiskGuard) – Pre-trade risk checks enforcing limits[25].

FR-EXEC-1 to FR-EXEC-12    ExecutionEngine (FlowRoute) – Order management and broker interfacing[139][94].

FR-PORT-1 to FR-PORT-10    PortfolioEngine – Portfolio state tracking and rebalancing logic[27].

FR-ANA-1 to FR-ANA-6    AnalyticsEngine – Performance metrics and reporting component[28].

FR-OPT-1 to FR-OPT-9    PortfolioOptEngine – GPU-accelerated optimization per design spec[117][140].

FR-GOV-1 to FR-GOV-9    GovernanceEngine – Policy enforcement & audit trail as cross-cutting control[29].

FR-LEARN-1 to FR-LEARN-8    LearningEngine – Continuous learning pipeline for model improvement[119].

FR-CTX-1 to FR-CTX-7    Cortex (LLM Engine) – AI reasoning assistant, per integrated AI blueprint[31].

FR-SYN-1 to FR-SYN-4    Synapse (RAG Engine) – Document retrieval system for context injection[32].

FR-HEL-1 to FR-HEL-8    Helix (LLM Provider) – Model provisioning layer (Nemotron models dispatch)[33].

FR-CG-1 to FR-CG-4    CodeGenService – AI-assisted code generation tool, per design for dev acceleration[34].

NFR-P-1 to NFR-P-5    Performance Goals: Derived from architecture note (not HFT, acceptable latency ~100-200ms)[129] and typical intraday trading needs.
NFR-R-1 to NFR-R-4    Reliability & HA: Driven by Phase 3 roadmap emphasis on observability & DR[23][129] and regulatory compliance for stability.

NFR-SEC-1 to NFR-SEC-8    Security & Compliance: Mapped to planned security doc (auth, secrets)[134] and regulatory guidelines (SEC, FINRA, MiFID II)[38].

NFR-SC-1 to NFR-SC-4    Scalability & Resources: Aligned with NVIDIA blueprint for hardware use[11][44] and design for phased scaling (Kafka, containerization)[36].

SC-1 to SC-4 (Constraints)    Model & Tech Constraints: Ensuring use of specific model versions[4], GPU requirements[37], retention rules[39], and fallback strategies[43] as per architecture and planning.

SC-5 to SC-8 (Constraints)    Regulatory & Phase Constraints: Enforcing kill-switch, audit immutability[7][29], acknowledging phased feature rollout (AI in Phase 2)[12] as per roadmap.

(Each requirement is thus traceable either to a specific architecture component in Section 2 (for functional reqs) or to project benchmarks/constraints in Section 1 and external references. This matrix will also guide testing: e.g., test cases will verify each FR against its engine’s expected behavior, and each NFR against the stated target or rule.)

________________________________________

[1] [2] [12] [13] [23] [36] [38] [39] [40] [41] [42] [47] [48] [56] [129] [132] [134] [135] [137] roadmap-phases-2-4.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/planning/roadmap-phases-2-4.md
[3] [17] component-overview.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/diagrams/component-overview.md
[4] [5] [6] [9] [20] [22] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] [46] [91] [94] [117] [119] [122] [123] [140] ARCHITECTURE.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/ARCHITECTURE.md
[7] [8] [10] [18] [19] [21] [72] [92] [99] [101] [102] [103] [112] [130] [131] [133] production-architecture.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/architecture/production-architecture.md
[11] [37] [43] [44] [45] [118] [121] [124] [125] [128] [136] nvidia-blueprint-integration.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/architecture/nvidia-blueprint-integration.md
[14] [50] [52] [59] [60] [64] [65] [93] [95] [96] [97] [98] [105] [106] [107] [108] [109] [110] [111] [114] [115] [116] phase1-api-reference.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/planning/phase1-api-reference.md
[15] [16] [24] [113] data-flow.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/diagrams/data-flow.md
[35] [61] [62] [63] [100] [120] [126] [127] [138] DEVELOPMENT.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/DEVELOPMENT.md
[49] [57] [58] [74] [75] [76] [77] [78] [79] [80] [81] [82] [83] [84] [85] [86] [87] [88] [89] engine.py
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/src/ordinis/bus/engine.py
[51] [53] [54] [55] [71] [104] [139] engine.py
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/src/ordinis/engines/flowroute/core/engine.py
[66] [67] [68] [69] [70] [73] [90] sequence-diagram.md
https://github.com/keith-mvs/ordinis/blob/1f96efac8b28f329a7ee050fa201266945d8aa43/docs/diagrams/sequence-diagram.md
